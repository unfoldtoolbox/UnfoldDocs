var documenterSearchIndex = {"docs":
[{"location":"generated/reference/type1_troendle/","page":"Troendle FWER","title":"Troendle FWER","text":"using ClusterDepth\nusing Random\nusing CairoMakie\nusing UnfoldSim\nusing StatsBase\nusing ProgressMeter\nusing Distributions","category":"section"},{"location":"generated/reference/type1_troendle/#Family-Wise-Error-of-Troendle","page":"Troendle FWER","title":"Family Wise Error of Troendle","text":"Here we calculate the Family Wise Error of doing ntests at the same time. That is, we want to check that Troendle indeed returns us a type-1 of 5% for a set of tests.\n\nThe point being, that if you do 30 tests, the chance that one is significant is not 5% but actually\n\n(1 - (1 - 0.05)^30) * 100 ##%\n\nLet's setup some simulation parameters\n\nreps = 1000\nperms = 1000\nntests = 30;\nnothing #hide\n\nwe will use the student-t in it's 2-sided variant (abs of it)\n\nfun = x -> abs.(ClusterDepth.studentt(x));\nnothing #hide\n\nthis function simulates data without any effect (H0), then the permutations, and finally calls troendle\n\nfunction run_fun(r, perms, fun, ntests)\n    rng = MersenneTwister(r)\n    data = randn(rng, ntests, 50)\n    perm = Matrix{Float64}(undef, size(data, 1), perms)\n    stat = fun(data)\n    for p = 1:perms\n        ClusterDepth.sign_permute!(rng, data)\n        perm[:, p] = fun(data)\n    end\n    return data, stat, troendle(perm, stat)\nend;\nnothing #hide\n\nlet's test it once\n\ndata, stats_t, pvals = run_fun(1, perms, fun, ntests);\nprintln(\"data:\", size(data), \" t-stats:\", size(stats_t), \" pvals:\", size(pvals))\n\nrun the above function reps=1000` times - we also save the uncorrected t-based pvalue\n\npvals_all = fill(NaN, reps, 2, ntests)\nThreads.@threads for r = 1:reps\n    data, stat, pvals = run_fun(r, perms, fun, ntests)\n    pvals_all[r, 1, :] = pvals\n    pvals_all[r, 2, :] = (1 .- cdf.(TDist(size(data, 2)), abs.(stat))) .* 2 # * 2 becaue of twosided. Troendle takes this into account already\nend;\nnothing #hide\n\nLet's check in how many of our simlations we have a significant p-value =<0.05\n\nres = any(pvals_all[:, :, :] .<= 0.05, dims=3)[:, :, 1]\nmean(res .> 0, dims=1) |> x -> (:troendle => x[1], :uncorrected => x[2])\n\nNice. Troendle corrects the data and we are below 0.05. The  uncorrected simulations are close to what we calculated above!\n\nFinally we end this with a short figure to get a better idea of how this data looks like and a histogram of the p-values\n\nf = Figure()\nax = f[1, 1] = Axis(f, title=\"t-values\")\n\n\n\nlines!(ax, abs.(ClusterDepth.studentt(data)))\nheatmap!(Axis(f[1, 2], title=\"heatmap of data\"), data)\nseries!(Axis(f[2, 2], title=\"data: subset of left plot\"), data[:, 1:7]')\nh1 = scatter!(Axis(f[2, 1]; yscale=log10, title=\"troendle pvals\"), pvals, label=\"troendle\")\n\nhlines!([0.05, 0.01])\n\nhist!(Axis(f[3, 1], title=\"troendle corrected\"), pvals_all[:, 1, :][:], bins=0:0.01:1.1)\nhist!(Axis(f[3, 2], title=\"uncorrected\"), pvals_all[:, 2, :][:], bins=0:0.01:1.1)\nf\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/reference/type1/","page":"Clusterdepth FWER","title":"Clusterdepth FWER","text":"using ClusterDepth\nusing Random\nusing CairoMakie\nusing UnfoldSim\nusing StatsBase\nusing Distributions\nusing DataFrames","category":"section"},{"location":"generated/reference/type1/#Family-Wise-Error-of-ClusterDepth","page":"Clusterdepth FWER","title":"Family Wise Error of ClusterDepth","text":"Here we calculate the Family Wise Error the ClusterDepth Correct That is, we want to check that pvalues we get, indeed return us a type-1 of 5% for all time-points The point being, that if you do tests on 113 timepoints, the chance that one is significant is not 5% but\n\n(1 - (1 - 0.05)^113) * 100 ##%","category":"section"},{"location":"generated/reference/type1/#Setup-Simulation","page":"Clusterdepth FWER","title":"Setup Simulation","text":"Let's setup a simulation using UnfoldSim.jl. We simulate a simple 1x2 design with 20 subjects\n\nn_subjects = 20\ndesign = MultiSubjectDesign(\n    n_subjects=n_subjects,\n    n_items=2,\n    items_between=Dict(:condition => [\"small\", \"large\"]),\n)\nfirst(generate_events(design), 5)\n\nNext we define a ground-truth signal + relation to events/design with Wilkinson Formulas. we want no condition effect, therefore β for the condition should be 0. We further add some inter-subject variability with the mixed models. We will use a simulated P300 signal, which at 250Hz has 113 samples.\n\nsignal = MixedModelComponent(;\n    basis=UnfoldSim.p300(; sfreq=250),\n    formula=@formula(0 ~ 1 + condition + (1 | subject)),\n    β=[1.0, 0.0],\n    σs=Dict(:subject => [1]),\n);\nnothing #hide\n\nLet's move the actual simulation into a function, so we can call it many times. Note that we use (RedNoise)[https://unfoldtoolbox.github.io/UnfoldSim.jl/dev/literate/reference/noisetypes/] which has lot's of Autocorrelation between timepoints. nice!\n\nfunction run_fun(r)\n    data, evts = simulate(\n        MersenneTwister(r),\n        design,\n        signal,\n        NoOnset(),\n        RedNoise(noiselevel=1);\n        return_epoched=true,\n    )\n    data = reshape(data, size(data, 1), :)\n    data_diff = data[:, evts.condition.==\"small\"] .- data[:, evts.condition.==\"large\"]\n\n    return data,\n    clusterdepth(data_diff; τ=quantile(TDist(n_subjects - 1), 0.975), nperm=4000, show_warnings=false)\nend;\nnothing #hide","category":"section"},{"location":"generated/reference/type1/#Understanding-the-simulation","page":"Clusterdepth FWER","title":"Understanding the simulation","text":"let's have a look at the actual data by running it once, plotting condition wise trials, the ERP and histograms of uncorrected and corrected p-values\n\ndata, pval = run_fun(1)\nconditionSmall = data[:, 1:2:end]\nconditionLarge = data[:, 2:2:end]\npval_uncorrected =\n    1 .-\n    cdf.(\n        TDist(n_subjects - 1),\n        abs.(ClusterDepth.studentt(conditionSmall .- conditionLarge)),\n    )\nsig = pval_uncorrected .<= 0.025;\nnothing #hide\n\nFor the uncorrected p-values based on the t-distribution, we get a type1 error over \"time\":\n\nmean(sig)\n\nnote: Note\nType-I error is not the FWER (family wise error rate). FWER is the property of a set of tests (in this case tests per time-point), we can calculate it by repeating such tests,   and checking for each repetition whether any sample of a repetition is significant (e.g. any(sig) followed by a mean(repetitions_anysig)).\n\nf = Figure();\nseries!(Axis(f[1, 1], title=\"condition==small\"), conditionSmall', solid_color=:red)\nseries!(Axis(f[1, 2], title=\"condition==large\"), conditionLarge', solid_color=:blue)\nax = Axis(f[2, 1:2], title=\"ERP (mean over trials)\")\n\nsig = allowmissing(sig)\nsig[sig.==0] .= missing\n@show sum(skipmissing(sig))\nlines!(sig, color=:gray, linewidth=4)\nlines!(ax, mean(conditionSmall, dims=2)[:, 1], color=:red)\nlines!(ax, mean(conditionLarge, dims=2)[:, 1], color=:blue)\n\nhist!(Axis(f[3, 1], title=\"uncorrected pvalues\"), pval_uncorrected, bins=0:0.01:1.1)\nhist!(Axis(f[3, 2], title=\"clusterdepth corrected pvalues\"), pval, bins=0:0.01:1.1)\nf","category":"section"},{"location":"generated/reference/type1/#Run-simulations","page":"Clusterdepth FWER","title":"Run simulations","text":"This takes some seconds (depending on your infrastructure)\n\nreps = 500\nres = fill(NaN, reps, 2)\nThreads.@threads for r = 1:reps\n    data, pvals = run_fun(r)\n    res[r, 1] = mean(pvals .<= 0.05)\n    res[r, 2] =\n        mean(abs.(ClusterDepth.studentt(data)) .>= quantile(TDist(n_subjects - 1), 0.975))\nend;\nnothing #hide\n\nFinally, let's calculate the percentage of simulations where we find a significant effect somewhere\n\nmean(res .> 0, dims=1) |> x -> (:clusterdepth => x[1], :uncorrected => x[2])\n\nNice, correction seems to work in principle :) Clusterdepth is not necessarily exactly 5%, but with more repetitions we should get there (e.g. with 5000 repetitions, we got 0.051%).\n\ninfo: Info\nif you look closely, the :uncorrected value (can be around 60%) is not as bad as the 99% promised in the introduction. This is due to the correlation between the tests introduced by the noise. Indeed, a good exercise is to repeat everything, but put RedNoise to WhiteNoise\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/demo/","page":"-","title":"-","text":"using ClusterDepth\nusing Random\nusing CairoMakie\n\n\nn_t = 40 # timepoints\nn_sub = 50\nn_perm = 5000\n\nsnr = 0.5 # signal to nois\n\n# add a signal to the middle\nsignal = vcat(zeros(n_t ÷ 4), sin.(range(0, π, length = n_t ÷ 2)), zeros(n_t ÷ 4))\n\n# same signal for all subs\nsignal = repeat(signal, 1, n_sub)\n\n\n# add noise\ndata = randn(MersenneTwister(123), n_t, n_sub) .+ snr .* signal\n\n# by default assumes τ=2.3 (~alpha=0.05), and one-sample ttest\n@time pvals = clusterdepth(data);\n\nf = Figure()\nax = f[1, 1] = Axis(f)\n\n\nlines!(abs.(ClusterDepth.studentt(data)))\nh1 = scatter(f[1, 2], pvals; axis = (; yscale = log10), label = \"troendle\")\n\npvals2 = clusterdepth(data; pval_type = :naive)\nh2 = scatter!(1.2:40.2, pvals2, color = \"red\", label = \"naive\")\n#hlines!(([0.05]))\naxislegend()\nf\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"howto/R_betweengroups/","page":"R: Between groups","title":"R: Between groups","text":"I got asked by a collaborator on how to call ClusterDepth from R for a between groups design.\n\nYou should first install JuliaCall+ClusterDepth\n\ninstall.packages(\"JuliaCall\")\nlibrary(\"JuliaCall\")\ninstall_julia() # installs Julia\n\nThen make a reproducible environment\n\nlibrary(\"JuliaCall\")\n\njulia <- julia_setup() # setup julia\npath_to_env = '/tmp/my_julia_env' # could be any path to a Julia Project.toml\njulia_eval(paste('import Pkg;','Pkg.activate(\"',path_to_env,'\");Pkg.instantiate()'))\n\n# if Unfold is not yet installed\njulia_eval('Pkg.add(\"Unfold\");')\n\nNow load the packages we need in julia\n\nlibrary(\"JuliaCall\")\njulia_install_package_if_needed(\"ClusterDepth\")\njulia_library(\"ClusterDepth\")\njulia_library(\"Random\")\n\nwe create some random data and a group indicator\n\nR_data <- array(matrix(rnorm(90), nrow = 10, ncol = 9),dim=c(1,10,9)) # 1 channel 10 timepoints, 9 subjects\ngrp_indicator = c(\"A\",\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"B\") == \"B\" # should be boolean\n\n... push the data to julia ...\n\njulia_assign(\"jl_data\",R_data) \njulia_assign(\"grp\",grp_indicator)\n\n(for now) we need to create our own permutation function - given we simulated 3D data, it needs to be 3D (I plan to move this function to ClusterDepth at a later point).\n\njulia_eval(\"permute_fun(rng,x) = @view x[:,:,randperm(rng,size(x,3))]\")\n\nFinally, there is no good interface yet to tell ClusterDepth who belongs to what group for the stats test, so we have to \"bake\" it into the function.\n\njulia_eval(\"mystat = (x) -> ClusterDepth.studentt_unpaired(x,grp)\")\n\nThe last thing to do is to actually call the algorithm with our defined statfun and permfun. Note the fixed cluster-forming-threshold, this should be adapted to your study, e.g. popular is to use α = 0.05 in the two-sided t-distribution: quantile(TDist(n_subjects - 1), 0.985) which requires the Distributions.jl package (apparently qt(0.975, df = n_subjects - 1) should do the trick in R as well).\n\njulia_eval(\"pvals = clusterdepth(jl_data;statfun=mystat,permfun = permute_fun,nperm=200,τ=2.3)\")","category":"section"},{"location":"generated/tutorials/eeg-multichannel/","page":"EEG Example - Multichannel data","title":"EEG Example - Multichannel data","text":"using ClusterDepth\nusing Random\nusing CairoMakie\nusing UnfoldSim\nusing Unfold\nusing UnfoldMakie\nusing Statistics","category":"section"},{"location":"generated/tutorials/eeg-multichannel/#How-to-use-the-ClusterDepth-multiple-comparison-correction-on-multichannel-data","page":"EEG Example - Multichannel data","title":"How to use the ClusterDepth multiple comparison correction on multichannel data","text":"This tutorial is adapted from the single-channel EEG example, and complements it with the HArtMuT NYhead model (https://github.com/harmening/HArtMuT) to simulate multiple channels.\n\nFirst set up the EEG simulation as before, with one subject and 40 trials:\n\ndesign =\n    SingleSubjectDesign(conditions=Dict(:condition => [\"car\", \"face\"])) |>\n    x -> RepeatDesign(x, 40);\np1 = LinearModelComponent(;\n    basis=p100(; sfreq=250),\n    formula=@formula(0 ~ 1),\n    β=[1.0],\n);\n\nn170 = LinearModelComponent(;\n    basis=UnfoldSim.n170(; sfreq=250),\n    formula=@formula(0 ~ 1 + condition),\n    β=[1.0, 0.5], # condition effect - faces are more negative than cars\n);\np300 = LinearModelComponent(;\n    basis=UnfoldSim.p300(; sfreq=250),\n    formula=@formula(0 ~ 1 + condition),\n    β=[1.0, 0], # no p300 condition effect\n);\nnothing #hide\n\nNow choose some source coordinates for each of the p100, n170, p300 that we want to simulate, and use the helper function closest_srcs to get the HArtMuT sources that are closest to these coordinates:\n\nsrc_coords = [\n    [20, -78, -10], #p100\n    [-20, -78, -10], #p100\n    [50, -40, -25], #n170\n    [0, -50, 40], #p300\n    [0, 5, 20], #p300\n];\n\nheadmodel_HArtMuT = headmodel()\nget_closest =\n    coord ->\n        UnfoldSim.closest_src(coord, headmodel_HArtMuT.cortical[\"pos\"]) |>\n        pi -> magnitude(headmodel_HArtMuT)[:, pi]\n\np1_l = p1 |> c -> MultichannelComponent(c, get_closest([-20, -78, -10]))\np1_r = p1 |> c -> MultichannelComponent(c, get_closest([20, -78, -10]))\nn170_r = n170 |> c -> MultichannelComponent(c, get_closest([50, -40, -25]))\np300_do = p300 |> c -> MultichannelComponent(c, get_closest([0, -50, -40]))\np300_up = p300 |> c -> MultichannelComponent(c, get_closest([0, 5, 20]))\n\ndata, evts = simulate(\n    MersenneTwister(1),\n    design,\n    [p1_l, p1_r, n170_r, p300_do, p300_up],\n    UniformOnset(; offset=0.5 * 250, width=100),\n    RedNoise(noiselevel=1);\n    return_epoched=true,\n);\nnothing #hide","category":"section"},{"location":"generated/tutorials/eeg-multichannel/#Plotting","page":"EEG Example - Multichannel data","title":"Plotting","text":"This is what the data looks like, for one channel/trial respectively:\n\nf = Figure()\nAxis(f[1, 1], title=\"Single channel, all trials\", xlabel=\"time\", ylabel=\"y\")\nseries!(data[1, :, :]', solid_color=(:black, 0.1))\nlines!(mean(data[1, :, :], dims=2)[:, 1], color=:red)\nhlines!([0], color=:gray)\n\nAxis(f[2, 1], title=\"All channels, average over trials\", xlabel=\"time\", ylabel=\"y\")\nseries!(mean(data, dims=3)[:, :, 1], solid_color=(:black, 0.1))\nhlines!([0], color=:gray)\nf\n\nAnd some topoplots:\n\npositions = [\n    Point2f(p[1] + 0.5, p[2] + 0.5) for\n    p in to_positions(headmodel_HArtMuT.electrodes[\"pos\"]')\n]\n\ndf = UnfoldMakie.eeg_array_to_dataframe(\n    mean(data, dims=3)[:, :, 1],\n    string.(1:length(positions)),\n);\nΔbin = 20 # 20 samples / bin\nplot_topoplotseries(\n    df,\n    bin_width=20,\n    positions=positions,\n    visual=(; enlarge=1, label_scatter=false),\n)","category":"section"},{"location":"generated/tutorials/eeg-multichannel/#ClusterDepth","page":"EEG Example - Multichannel data","title":"ClusterDepth","text":"Now that the simulation is done, let's try out ClusterDepth and plot our results Note that this is a simple test of \"activity\" vs. 0\n\npvals = clusterdepth(data; τ=1.6, nperm=200);\nfig, ax, hm = heatmap(transpose(pvals), colorscale=log10)\nax.title = \"pvals\";\nax.xlabel = \"time\";\nax.ylabel = \"channel\";\nColorbar(fig[:, end+1], hm);\nfig\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/eeg/","page":"An EEG Example","title":"An EEG Example","text":"using ClusterDepth\nusing Random\nusing CairoMakie\nusing UnfoldSim\nusing StatsBase\nusing Distributions\nusing DataFrames\nusing Unfold\nusing UnfoldMakie","category":"section"},{"location":"generated/tutorials/eeg/#How-to-use-the-ClusterDepth-multiple-comparison-correction","page":"An EEG Example","title":"How to use the ClusterDepth multiple comparison correction","text":"info: Info\nThis tutorial focuses on single-channel data. For multichannel data, see the tutorial \"Further EEG Example\".","category":"section"},{"location":"generated/tutorials/eeg/#Simulating-test-data","page":"An EEG Example","title":"Simulating test-data","text":"Let's setup an EEG simulation using UnfoldSim.jl. We simulate a one factor 1x2 design with 20 subjects, each with 40 trials\n\nn_subjects = 20\ndesign = MultiSubjectDesign(\n    n_subjects=n_subjects,\n    n_items=40,\n    items_between=Dict(:condition => [\"car\", \"face\"]),\n)\nfirst(generate_events(design), 3)\n\nNext we define a ground-truth signal based on a Linear Mixed Model.\n\nWe simulate a P100, a N170 and a P300 - but an effect only on the N170\n\np1 = MixedModelComponent(;\n    basis=UnfoldSim.p100(; sfreq=250),\n    formula=@formula(0 ~ 1 + (1 | subject)),\n    β=[1.0],\n    σs=Dict(:subject => [1]),\n);\nn170 = MixedModelComponent(;\n    basis=UnfoldSim.n170(; sfreq=250),\n    formula=@formula(0 ~ 1 + condition + (1 + condition | subject)),\n    β=[1.0, -0.5], # condition effect - faces are more negative than cars\n    σs=Dict(:subject => [1, 0.2]), # random slope yes please!\n);\n\np300 = MixedModelComponent(;\n    basis=UnfoldSim.p300(; sfreq=250),\n    formula=@formula(0 ~ 1 + condition + (1 + condition | subject)),\n    β=[1.0, 0], ## no p300 condition effect\n    σs=Dict(:subject => [1, 1.0]), # but a random slope for condition\n);\n\ndata, events = simulate(\n    MersenneTwister(1),\n    design,\n    [p1, n170, p300],\n    UniformOnset(; offset=500, width=100),\n    RedNoise(noiselevel=1);\n    return_epoched=true,\n)\ntimes = range(0, stop=size(data, 1) / 250, length=size(data, 1));\nnothing #hide","category":"section"},{"location":"generated/tutorials/eeg/#Fit-a-model-to-each-subject","page":"An EEG Example","title":"Fit a model to each subject","text":"We now have data, but no multiple comparison problem yet - we have to fit one analysis regression model to each time-point of each subject. Thereby, we perform 113 tests and would (without multiple testing correction) expect 5-6 samples to be significant, even if there is no true effect (but there is one ;)).\n\nnote: Note\nIn principle, we do not need Unfold here - we could simply calculate (subjectwise) means of the conditions, and their time-resolved difference. Using Unfold.jl here simply generalizes it to more complex design, e.g. with continuous predictors etc.\n\nmodels = map(\n    (d, ev) -> (\n        fit(UnfoldModel, @formula(0 ~ 1 + condition), DataFrame(ev), d, times),\n        ev.subject[1],\n    ),\n    eachslice(data; dims=3),\n    groupby(events, :subject),\n);\nnothing #hide\n\nnow we can inspect the data easily, and extract the face-effect\n\nfunction add_subject!(df, s)\n    df[!, :subject] .= s\n    return df\nend\nallEffects =\n    map(\n        (x) ->\n            (effects(Dict(:condition => [\"car\", \"face\"]), x[1]), x[2]) |>\n            (x) -> add_subject!(x[1], x[2]),\n        models,\n    ) |> e -> reduce(vcat, e)\n\nplot_erp(allEffects; mapping=(color=:condition, group=:subject))\n\nEvery line is from one subject, the color indicates our two conditions.\n\nIt is easier to see potential differences if we would plot the difference:\n\nFirst we extract all coefficients in a nice, tidy DataFrame\n\nallCoefs =\n    map(m -> (coeftable(m[1]), m[2]) |>\n             (x) -> add_subject!(x[1], x[2]), models) |>\n    e -> reduce(vcat, e)\nplot_erp(allCoefs; mapping=(group=:subject, col=:coefname))\n\nThis plot now shows the intercept (in our contrast-case the condition:\"car\" ERP), and the difference curve.\n\nNext we unstack the tidy-coef table into a matrix and put it to clusterdepth for clusterpermutation testing\n\nfaceCoefs = allCoefs |> x -> subset(x, :coefname => x -> x .== \"condition: face\")\nerpMatrix =\n    unstack(faceCoefs, :subject, :time, :estimate) |> x -> Matrix(x[:, 2:end])' |> collect\nsummary(erpMatrix)","category":"section"},{"location":"generated/tutorials/eeg/#Clusterdepth","page":"An EEG Example","title":"Clusterdepth","text":"pvals = clusterdepth(erpMatrix; τ=quantile(TDist(n_subjects - 1), 0.95), nperm=5000);\nnothing #hide\n\nwell - that was fast, less than a second for a cluster permutation test. not bad at all!","category":"section"},{"location":"generated/tutorials/eeg/#Plotting","page":"An EEG Example","title":"Plotting","text":"Some plotting, and we add the identified cluster\n\nfirst calculate the ERP\n\nfaceERP =\n    groupby(faceCoefs, [:time, :coefname]) |>\n    x -> combine(x, :estimate => mean => :estimate, :estimate => (x -> std(x) / sqrt(length(x))) => :stderror);\nnothing #hide\n\nput the pvalues into a nicer format\n\npvalDF =\n    ClusterDepth.cluster(pvals .<= 0.05) |>\n    x -> DataFrame(\n        :from => x[1] ./ 250,\n        :to => (x[1] .+ x[2]) ./ 250,\n        :coefname => \"condition: face\",\n    )\nplot_erp(faceERP; stderror=true, significance=pvalDF)\nhlines!([0])\ncurrent_figure()\n\nLooks good! We identified the cluster :-)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"#ClusterDepth","page":"Home","title":"ClusterDepth","text":"","category":"section"},{"location":"#Comparison-to-permuco-R-implementation","page":"Home","title":"Comparison to permuco R implementation","text":"The implementation to Permuco is similar, but ClusterDepth.jl is more barebone - that is, we dont offer many permutation schemes, focus on the ClusterDepth Algorithm, and don't provide the nice wrappers like clusterLM.\n\nTiming wise, a simple test on 50 subjects, 100 repetitions, 5000 permutations shows the following results:\n\ntimepoints ClusterDepth.jl permuco julia-speedup\n40 0.03s 2.9s ~100x\n400 0.14s 22s ~160x\n4000 1.88s 240s ~120x\n\n","category":"section"},{"location":"#ClusterDepth.calc_clusterdepth-Tuple{AbstractMatrix{<:Real}, Any}","page":"Home","title":"ClusterDepth.calc_clusterdepth","text":"calc_clusterdepth(data,τ)\n\nreturns tuple with three entries: 1:maxLength, maximal clustervalue per clusterdepth head, same for tail\n\nWe assume data and τ have already been transformed for one/two sided testing, so that we can do d0.>τ for finding clusters\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.cluster-Tuple{BitVector}","page":"Home","title":"ClusterDepth.cluster","text":"finds neighbouring clusters in the vector and returns start + length vectors\n\nif the first and last cluster start on the first/last sample, we dont know their real depth\n\nInput is assumed to be a thresholded Array with only 0/1\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.clusterdepth-Tuple{AbstractArray, Vararg{Any}}","page":"Home","title":"ClusterDepth.clusterdepth","text":"using Base: Stateful clusterdepth(rng,data::AbstractArray;τ=2.3, statfun=x->abs.(studentt(x)),permfun=signpermute!,nperm=5000,pvaltype=:troendle)\n\ncalculate clusterdepth of given datamatrix. \n\ndata: statfun will be applied on last dimension of data (typically this will be subjects)\n\nOptional\n\nτ: Cluster-forming threshold \nnperm: number of permutations, default 5000\nstat_type: default  the one-sample t-test, custom function can be specified (see statfun! and statfun)\nside_type: default: :abs - what function should be applied after the statfun? could be :abs, :square, :positive to test positive clusters, :negative to test negative clusters. Custom function can be provided, see sidefun`\nperm_type: default :sign for one-sample data (e.g. differences), performs sign flips. custom function can be provided, see  permfun\npval_type: how to calculate pvalues within each cluster, default :troendle, see ?pvals\nstatfun / statfun! a function that either takes one or two arguments and aggregates over last dimension. in the two argument case we expect the first argument to be modified inplace and provide a suitable Vector/Matrix.\nsidefun: default abs. Provide a function to be applied on each element of the output of  statfun. \npermfun function to permute the data, should accept an RNG-object and the data. can be inplace, the data is copied, but the same array is shared between permutations\nshow_warnings: default true - function to suppress warnings, useful for simulations\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.ix_sortUnique-Tuple{Any}","page":"Home","title":"ClusterDepth.ix_sortUnique","text":"in some sense: argsort(argunique(x)), returns the indices to get a sorted unique of x\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.multicol_minimum-Tuple{AbstractMatrix, AbstractVector}","page":"Home","title":"ClusterDepth.multicol_minimum","text":"calculates the minimum in `X` along `dims=2` in the columns specified by àrrayOfIndicearrays` which could be e.g. `[[1,2],[5,6],[3,4,7]]`\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.pvals-Tuple{Any}","page":"Home","title":"ClusterDepth.pvals","text":"pvals(data;kwargs...) = pvals(data[2:end],data[1];kwargs...)\n\npvals(data::AbstractVector,stat::Real;type=:twosided)\n\ncalculates pvalues based on permutation results\n\nif called with stat, first entry is assumed to be the observation \n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.pvals-Tuple{Matrix, Vararg{Any}}","page":"Home","title":"ClusterDepth.pvals","text":"Calculate pvals from cluster-depth permutation matrices\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.sign_permute!-Tuple{Any, AbstractArray}","page":"Home","title":"ClusterDepth.sign_permute!","text":"Permutation via random sign-flip Flips signs along the last dimension\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.studentt_test!-Tuple{Any, AbstractMatrix}","page":"Home","title":"ClusterDepth.studentt_test!","text":"studentt_test!(out,x;type=:abs)\n\nstrongly optimized one-sample t-test function.\n\nImplements: t =  mean(x) / ( sqrt(var(x))) / sqrt(size(x,2)-1)\n\nAccepts 2D or 3D matrices, always aggregates over the last dimension\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.studentt_unpaired-Tuple{Any, Any}","page":"Home","title":"ClusterDepth.studentt_unpaired","text":"studentt_unpaired(x::AbstractArray, group)\n\nImplements a unpaired two groups t-test with unequal variances. 10x as fast as HypothesisTests because we don't allocate that much Use like this:\n\nstudentt_unpaired([1,2,1,1,4,5,4],[false,false,false,false,true,true,true])\n\nTo use with ClusterDepth, you have to \"bake-in\" the group membership by defining your own method:\n\ngrp = [\"bla\",\"bla\",\"bla\",\"bla\",\"blub\",\"blub\",\"blub\"] .== \"blub\"\nmy_statfun = x->studentt_unpaired(x,grp)\n\n\n\n\n\n","category":"method"},{"location":"#ClusterDepth.troendle-Tuple{AbstractMatrix, AbstractVector}","page":"Home","title":"ClusterDepth.troendle","text":"function troendle(perm::AbstractMatrix,stat::AbstractVector;type=:twosided)\n\nMultiple Comparison Correction as in Troendle 1995\n\nperm with size  ntests x nperms\n\nstat with size ntests\n\ntype can be :twosided (default), :lesser, :greater\n\nHeavily inspired by the R implementation in permuco from Jaromil Frossard\n\nNote: While permuco is released under BSD, the author Jaromil Frossard gave us an MIT license for the troendle and the clusterdepth R-functions.\n\n\n\n\n\n","category":"method"}]
}
