[{"id":3,"pagetitle":"Unfold Documentation","title":"Unfold Documentation","ref":"/UnfoldDocs/Unfold.jl/stable/#Unfold-Documentation","content":" Unfold Documentation If you want to follow the  tutorials , best to start with the  mass-univariate approach , which should be familiar to you if you did ERPs before. Then the  overlap-correction tutorial ,  mixed mass univariate ,  mixed overlap (tricky!) . If you are then not satisfied, check out more advanced topics:  effects-interface (aka what to do after fitting) , or non-linear effects. In case you want to understand the tools better, check out our  explanations . Once you are familiar with the tools, check out further  how-to guides  for specific applications. In case you want to understand the toolbox better, we plan to offer  technical references . This includes Benchmarks & Explorations."},{"id":4,"pagetitle":"Unfold Documentation","title":"Quick start","ref":"/UnfoldDocs/Unfold.jl/stable/#Quick-start","content":" Quick start There are four main model types  Timeexpansion  No , Mixed  No   :  fit(UnfoldModel, [Any=>(f, -0.1:0.01:0.5)], evts, data_epoch) Timeexpansion  Yes , Mixed  No  :  fit(UnfoldModel, [Any=>(f, basisfunction)], evts, data) Timeexpansion  No , Mixed  Yes  :  fit(UnfoldModel, [Any=>(fLMM, -0.1:0.01:0.5)], evts, data_epoch) Timeexpansion  Yes , Mixed  Yes :  fit(UnfoldModel, [Any=>(fLMM, basisfunction)], evts, data) f = @formula 0 ~ 1 + condition\nfLMM = @formula 0 ~ 1 + condition + (1|subject) + (1|item)\nbasisfunction = firbasis(τ = (-0.1,0.5), sfreq = 100))"},{"id":7,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Alternative Solvers","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#custom_solvers","content":" Alternative Solvers A solver takes an Unfold-specified DesignMatrix and the data, and typically solves the equation system  y = Xb  (in the case of Linear Models). There are many different ways how one can approach this problem, depending if the matrix is sparse, if it is 2D or 3D, if one wants to use GPU etc. Most implemented solvers ultimately make use of  solver_main  for their main loop. See the  reference  tutorial for more information if that is interesting to you."},{"id":8,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Setup some data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#Setup-some-data","content":" Setup some data using Unfold\nusing UnfoldMakie, CairoMakie\nusing UnfoldSim\ndat, evts = UnfoldSim.predef_eeg(; noiselevel = 10, return_epoched = true)\n\nf = @formula 0 ~ 1 + condition + continuous\ndesignDict = Dict(Any => (f, range(0, 1, length = size(dat, 1))))"},{"id":9,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"GPU Solvers","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#GPU-Solvers","content":" GPU Solvers GPU solvers can significantly speed up your model fitting, with observed improvements of up to a factor of 30-100!"},{"id":10,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"fastest GPU solver","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#fastest-GPU-solver","content":" fastest GPU solver Empirically we found that solving  X'Xb = X'y  is the fastest way to solve for  b . To achieve this, you can run: using CUDA\ngpu_solver =(x, y) -> Unfold.solver_predefined(x, y; solver=:qr)\nm = Unfold.fit(UnfoldModel, designDict, evts, cu(dat), solver = gpu_solver) Where the  cu  is the magic that moves the data to the GPU. Internatlly, the solver function will move the matrix as well and pre-calculate some matrices (especially  X'X ,  X'  and allocate  X'y ). "},{"id":11,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"lsmr GPU solver","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#lsmr-GPU-solver","content":" lsmr GPU solver the  Krylov.lsmr  implementation directly solves  y = Xb , but allows for running on the GPU. using Krylov, CUDA # necessary to load the right package extension\ngpu_solver =(x, y) -> Unfold.solver_krylov(x, y; GPU = true)\nm = Unfold.fit(UnfoldModel, designDict, evts, dat, solver = gpu_solver) To test it, you will need to run it yourself as we cannot run it on the docs. If you require a different graphicscard vendor than NVIDA/CUDA, please create an issue. Currently, we are unable to test it due to lack of hardware."},{"id":12,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Robust Solvers","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#Robust-Solvers","content":" Robust Solvers Robust solvers automatically adjust for outlier trials, but they come at a significant computational cost. using RobustModels # necessary to load the Unfold package extension\nse_solver = (x, y) -> Unfold.solver_robust(x, y)\nm = Unfold.fit(UnfoldModel, designDict, evts, dat, solver = se_solver)\nresults = coeftable(m)\nplot_erp(results; stderror = true)"},{"id":13,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Back2Back regression","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#Back2Back-regression","content":" Back2Back regression b2b_solver = (x, y) -> Unfold.solver_b2b(x, y; ross_val_reps = 5)\ndat_3d = permutedims(repeat(dat, 1, 1, 20), [3 1 2])\nm = Unfold.fit(UnfoldModel, designDict, evts, dat_3d; solver = b2b_solver)\nresults = coeftable(m)\n\nplot_erp(results) These are the decoding results for  conditionA  while considering  conditionB , and vice versa. "},{"id":16,"pagetitle":"P-values for mixedModels","title":"How To get P-Values for Mass-Univariate LMM","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#lmm_pvalues","content":" How To get P-Values for Mass-Univariate LMM There are currently two ways to obtain p-values for LMMs: Wald's t-test and likelihood ratio tests (mass univariate only)."},{"id":17,"pagetitle":"P-values for mixedModels","title":"Setup","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Setup","content":" Setup using MixedModels, Unfold # we require to load MixedModels to load the PackageExtension\nusing DataFrames\nusing UnfoldSim\nusing CairoMakie\ndata_epoch, evts =\n    UnfoldSim.predef_2x2(; n_items = 52, n_subjects = 40, return_epoched = true)\ndata_epoch = reshape(data_epoch, size(data_epoch, 1), :) #\ntimes = range(0, 1, length = size(data_epoch, 1)) 0.0:0.010101010101010102:1.0"},{"id":18,"pagetitle":"P-values for mixedModels","title":"Define f0 & f1 and fit!","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Define-f0-and-f1-and-fit!","content":" Define f0 & f1 and fit! f0 = @formula 0 ~ 1 + A + (1 + A | subject);\nf1 = @formula 0 ~ 1 + A + B + (1 + A | subject); # could also differ in random effects\n\nm0 = fit(UnfoldModel,[Any=>(f0,times)],evts,data_epoch);\nm1 = fit(UnfoldModel,[Any=>(f1,times)],evts,data_epoch);"},{"id":19,"pagetitle":"P-values for mixedModels","title":"Likelihood ratio","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Likelihood-ratio","content":" Likelihood ratio uf_lrt = likelihoodratiotest(data_epoch, m0, m1)\nuf_lrt[1] model-dof deviance χ² χ²-dof P(>χ²) �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 6 8012 �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m B �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 7 8011 1 1 0.3996 As you can see, we have some likelihood ratio outcomes, exciting!"},{"id":20,"pagetitle":"P-values for mixedModels","title":"Extract p-values","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Extract-p-values","content":" Extract p-values pvalues(uf_lrt) 100-element Vector{Vector{Float64}}:\n [0.39964251754876706]\n [0.4019640858609401]\n [0.4074237173863722]\n [0.4070454519554564]\n [0.42228971014118033]\n [0.483155056260971]\n [0.6339437552710293]\n [NaN]\n [NaN]\n [NaN]\n ⋮\n [0.34292883003473407]\n [0.33515969561309156]\n [0.33325396532570495]\n [0.3428036624385943]\n [0.3567742512609538]\n [0.37049189795207205]\n [0.38051461402659575]\n [0.3883891630406846]\n [0.39851721772119286] We have extracted the p-values and now need to make them usable.     The solution can be found in the documentation under  ?pvalues . pvals_lrt = vcat(pvalues(uf_lrt)...)\nnchan = 1\nntime = length(times)\nreshape(pvals_lrt, ntime, nchan)' # note the last transpose via ' ! 1×100 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.399643  0.401964  0.407424  0.407045  …  0.380515  0.388389  0.398517 Perfecto, these are the LRT p-values of a model  condA  vs.  condA+condB  with same random effect structure."},{"id":21,"pagetitle":"P-values for mixedModels","title":"Walds T-Test","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Walds-T-Test","content":" Walds T-Test This method is easier to calculate but has limitations in accuracy and scope. It may also be less accurate due to the liberal estimation of degrees of freedom. Testing is limited in this case, as random effects cannot be tested and only single predictors can be used, which may not be appropriate for spline effects. It is important to note that this discussion is beyond the scope of this LMM package.  res = coeftable(m1)\n# only fixed effects: what is not in a ranef group is a fixef.\nres = res[isnothing.(res.group), :]\n# calculate t-value\nres[:, :tvalue] = res.estimate ./ res.stderror 300-element Vector{Float64}:\n  4.446708326696426\n  4.437580860011641\n  4.446435058073349\n  4.492672997803976\n  4.494599457419684\n  4.4880483252027075\n  4.439652303422133\n  4.45518635490581\n  4.623068236549389\n  4.663764726700654\n  ⋮\n  0.5870708293447756\n  0.43759939804174963\n  0.2172917074185397\n  0.025591530320948425\n -0.11195974844949615\n -0.28040792854804225\n -0.22668554132390997\n -0.2646530795209725\n -0.3492299276363734 We obtained Walds t, but how to translate them to a p-value? Determining the necessary degrees of freedom for the t-distribution is a complex issue with much debate surrounding it.  One approach is to use the number of subjects as an upper bound for the p-value (your df will be between  $n_{subject}$  and  $\\sum{n_{trials}}$ ). df = length(unique(evts.subject)) 40 Plug it into the t-distribution.  using Distributions\nres.pvalue = pdf.(TDist(df),res.tvalue) 300-element Vector{Float64}:\n 0.00010520592926163251\n 0.00010817494439425095\n 0.00010529365405567558\n 9.142141916777313e-5\n 9.088393516836884e-5\n 9.272440215982806e-5\n 0.00010749405443829126\n 0.00010251943544603832\n 6.122445474960627e-5\n 5.398423858898151e-5\n ⋮\n 0.33251660178615255\n 0.3594809847897533\n 0.38698410798874533\n 0.39632387743397085\n 0.39391857391788004\n 0.38081351375847516\n 0.38615884540577883\n 0.3824900521283194\n 0.37247026276880874"},{"id":22,"pagetitle":"P-values for mixedModels","title":"Comparison of methods","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Comparison-of-methods","content":" Comparison of methods Cool! Let's compare both methods of p-value calculation! df = DataFrame(:walds => res[res.coefname.==\"B: b_tiny\", :pvalue], :lrt => pvals_lrt)\nf = Figure()\n\nscatter(f[1,1],times,res[res.coefname .== \"B: b_tiny\",:estimate],axis=(;xlabel=\"time\",title=\"coef: B:b_tiny\"))\nscatter(f[1,2],df.walds,df.lrt,axis=(;title=\"walds-t pvalue\",ylabel=\"LRT pvalue\"))\nscatter(f[2,1],times,df.walds,axis=(;title=\"walds-t pvalue\",xlabel=\"time\"))\nscatter(f[2,2],times,df.lrt,axis=(;title=\"lrt pvalue\",xlabel=\"time\"))\n\nf Look pretty similar! Note that the Walds-T is typically too liberal (LRT also, but to a lesser exted). Best is to use the forthcoming MixedModelsPermutations.jl or go the route via R and use KenwardRoger (data not yet published)"},{"id":25,"pagetitle":"Overlap: Multiple events","title":"How to model multiple events","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/multiple_events/#How-to-model-multiple-events","content":" How to model multiple events When dealing with overlapping data, it is often necessary to model multiple eventtypes (e.g. fixations, stimuli, responses)."},{"id":26,"pagetitle":"Overlap: Multiple events","title":"Load Example Data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/multiple_events/#Load-Example-Data","content":" Load Example Data using Unfold\nusing UnfoldMakie, CairoMakie\nusing DataFrames\nusing StatsModels\nusing MixedModels\n\ninclude(joinpath(dirname(pathof(Unfold)), \"../test/test_utilities.jl\")) # to load data\ndat, evts = loadtestdata(\"test_case_4b\");\n\nevts[1:5,:] 5×3 DataFrame Row latency type intercept Int64 String7 Int64 1 38 eventA 1 2 50 eventB 1 3 89 eventA 1 4 102 eventB 1 5 144 eventA 1 The  type  column of table  evts  contains two conditions:  eventA and eventB (if your eventstypes are specified in a different column, you need to define the keywordargument eventcolumn in the fit` command below)"},{"id":27,"pagetitle":"Overlap: Multiple events","title":"Specify formulas and basisfunctions","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/multiple_events/#Specify-formulas-and-basisfunctions","content":" Specify formulas and basisfunctions bf1 = firbasis(τ = (-0.4, 0.8), sfreq = 50)\nbf2 = firbasis(τ = (-0.2, 1.2), sfreq = 50) For each event, a basis function and formula must be specified. The same basis and formulas may be used. f  = @formula 0 ~ 1 FormulaTerm\nResponse:\n  0\nPredictors:\n  1 For each event, we must specify the formula and basis function to be used.  bfDict = [ \"eventA\" => (f, bf1),\n           \"eventB\" => (f, bf2) ] Finally, fitting & plotting works the same way as always m = Unfold.fit(\n    UnfoldModel,\n    bfDict,\n    evts,\n    dat,\n    solver = (x, y) -> Unfold.solver_default(x, y; stderror = true),\n    eventcolumn = \"type\",\n)\nresults = coeftable(m)\nplot_erp(results; stderror = true, mapping = (; col = :eventname))"},{"id":30,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Loading Data into Unfold","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Loading-Data-into-Unfold","content":" Loading Data into Unfold Unfold is generally agnostic to how you load your data. You only require a Matrix (channel x time) or 3D-Array(channel x time x epochs) and an event-dataframe."},{"id":31,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Setup","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Setup","content":" Setup using Unfold\nusing UnfoldMakie,CairoMakie\nusing PyMNE\nusing DataFrames"},{"id":32,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"MNE Demo Dataset","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#MNE-Demo-Dataset","content":" MNE Demo Dataset The easiest way to showcase this is to simply use a demo-dataset from MNE. limo_epochs = PyMNE.datasets.limo.load_data(subject=1,path=\"~/MNE/DATA\",update_path=false)\nlimo_epochs Now we can fit a simple  Unfold  model to it.  First extract the data & convert it to Julia/Unfold requirements data = limo_epochs.get_data(picks=\"B11\")\ndata  = permutedims(data,[2,3,1]) # get into ch x times x epochs\n\nfunction convert_pandas(df_pd)\n      df= DataFrame()\n    for col in df_pd.columns\n        df[!, col] = getproperty(df_pd, col).values\n    end\n    return df\nend\nevents = convert_pandas(limo_epochs.metadata)\nrename!(events,2=>:coherence) # negative signs in formulas are not good ;)\nevents.face = string.(events.face) # ugly names, but fast\n Next fit an Unfold Model uf = fit(UnfoldModel,[Any=>(@formula(0~face+coherence),Float64.(limo_epochs.times))],events,data)\nresults = coeftable(uf) plot_results(results)"},{"id":33,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Read some of your own data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Read-some-of-your-own-data","content":" Read some of your own data We can make use of all PyMNE importer functions to load the data. Try it for your own data! Get starting with Unfold in no-time! #eeglabdata = PyMNE.io.read_raw_eeglab(\"pathToEEGLabSet.set\")"},{"id":34,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Contribute?","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Contribute?","content":" Contribute? Some extra conversions are needed to import the data from PyMNE to Unfold (as shown above). We could try putting these in a wrapper function - do you want to tackle this challenge? Would be a great first contribution to the toolbox :-)"},{"id":37,"pagetitle":"Standard errors","title":"Standard Errors","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/standarderrors/#standard_errors","content":" Standard Errors"},{"id":38,"pagetitle":"Standard errors","title":"Setup some data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/standarderrors/#Setup-some-data","content":" Setup some data using Unfold\nusing UnfoldMakie, CairoMakie\nusing UnfoldSim\ndat, evts = UnfoldSim.predef_eeg(; noiselevel = 10, return_epoched = true)\n\nf = @formula 0 ~ 1 + condition + continuous\ndesignDict = Dict(Any => (f, range(0, 1, length = size(dat, 1)))) It is possible to specify a solver that calculates the standard errors of the estimates for a single subject as it possible for  custom solvers . se_solver = (x, y) -> Unfold.solver_default(x, y, stderror = true)\nm = Unfold.fit(UnfoldModel, designDict, evts, dat, solver = se_solver)\nresults = coeftable(m)\nplot_erp(results; stderror = true) Warning In case of overlap-correction:  Use single-subject standard errors on your own risk. EEG data is autocorrelated, which means that standard errors are typically too small."},{"id":41,"pagetitle":"About basisfunctions","title":"Basis Functions","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#Basis-Functions","content":" Basis Functions This document will give you an explanation of basis functions. We start with basis functions for fMRI because they are very popular."},{"id":42,"pagetitle":"About basisfunctions","title":"HRF / BOLD","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#HRF-/-BOLD","content":" HRF / BOLD We want to define a basis function. There are currently only few basisfunctions implemented in Unfold.jl, but your imagination knows no borders! We first have a look at the BOLD-HRF basisfunction aka  Blood Oxygenation Level Dependent Hemodynamic Response Function : using Unfold, DSP\n\nTR = 1.5 # the sampling rate\nbold = hrfbasis(TR) # using default SPM parameters\neventonset = 1.3\nbold_kernel = e -> Unfold.kernel(bold, e)\nlines(bold_kernel(eventonset)[:,1]) # returns a matrix, thus [:, 1] This is the shape that is assumed to reflect the activity for an event. Generally, we would like to know how much to scale this response shape per condition, e.g. in  condA  we might scale it by 0.7, in  condB  by 1.2. But let's start at the beginning and first simulate an fMRI signal. Then you will also appreciate why we need to deconvolve it later."},{"id":43,"pagetitle":"About basisfunctions","title":"Convolving a response shape to get a \"recorded\" fMRI signal","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#Convolving-a-response-shape-to-get-a-\"recorded\"-fMRI-signal","content":" Convolving a response shape to get a \"recorded\" fMRI signal We start by convolving this HRF function with an impulse vector at event onsets. y = zeros(100) # signal length = 100\ny[[10, 30, 45]] .= 0.7 # 3 events at given for condition A\ny[[37]] .= 1.2 # 1 events at given for condition B\n\ny_conv = conv(y, bold_kernel(0)) # convolve!\nlines(y_conv[:,1]) Next, we would add some noise: using Random\ny_conv += randn(size(y_conv))\nlines(y_conv[:,1]) 🎉 - we did it, we simulated fMRI data. Now you can see that the conditions overlap in time. To get back to the original amplitude values, we need to specify a basis function and use Unfold to deconvolve the signals. Note Events can fall between TR (the sampling rate). Some packages subsample the time signal, but in  Unfold  we can call the  bold.kernel  function directly at a given event time, which allows us to use non-TR multiples."},{"id":44,"pagetitle":"About basisfunctions","title":"FIR Basis Function","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#FIR-Basis-Function","content":" FIR Basis Function Okay, let's have a look at a different basis function: The FIR basisfunction. FIR stands for  Finite-Impulse-Response  and is a term taken from the filtering literature. basisfunction = firbasis(τ=(-0.4,.8), sfreq=50, name=\"myFIRbasis\")\nfir_kernel = e -> Unfold.kernel(basisfunction, e)\nm = fir_kernel(0)\nf = Figure()\nf[1,1] = Axis(f)\nfor col = 1:size(m, 2)\n    lines!(m[:,col])\nend\ncurrent_figure() The first thing to notice is that it is not a single basisfunction, but a set of basisfunctions. So every condition is explained by several basis functions! To make it clear better show it in 2D: fir_kernel(0)[1:10,1:10] 10×10 SparseArrays.SparseMatrixCSC{Int64, Int64} with 10 stored entries:\n 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1 (all  .  are  0 's) The FIR basis set consists of multiple basis functions. That is, each event is now  time-expanded  to multiple predictors, each with a certain time delay to the event onset. This allows us to model any linear overlap shape, and doesn't force us to make assumptions about the convolution kernel, as we had to do in the BOLD case."},{"id":47,"pagetitle":"Development environment","title":"Install a dev-version of Unfold","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/development/#Install-a-dev-version-of-Unfold","content":" Install a dev-version of Unfold In order to see and change the tutorials, you have to install a local dev-version of Unfold via: ]dev --local Unfold This clones the  git#main  into  ./dev/Unfold"},{"id":48,"pagetitle":"Development environment","title":"Instantiating the documentation environment","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/development/#Instantiating-the-documentation-environment","content":" Instantiating the documentation environment To generate documentation, we recommend to install LiveServer.jl - then you can do: using LiveServer\nservedocs(skip_dirs=joinpath(\"docs\",\"src\",\"generated\"),literate_dir=joinpath(\"docs\",\"literate\")) If you prefer a one-off: activate the   ./docs  folder (be sure to  ]instantiate  the first time!) run  include(\"docs/make.jl\")"},{"id":53,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"Marginal effects","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#effects","content":" Marginal effects Marginal effect plots  are useful for understanding model fits. If you are an EEG researcher, you can think of the coefficients as the 'difference waves' and the (marginal) effects as the 'modelled ERP evaluated at a certain predictor value combination'. In some way, we are fitting a model with coefficients, receiving intercepts and slopes, and then try to recover the 'classical' ERPs in their \"data-domain\", typically with some effect adjustment, overlap removal, or similar."},{"id":54,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"Setup things","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#Setup-things","content":" Setup things Setup some packages using Unfold\nusing DataFrames\nusing Random\nusing CSV\nusing UnfoldMakie\nusing UnfoldSim\nusing UnfoldMakie Generate data and fit a model with a 2-level categorical predictor and a continuous predictor without interaction. data, evts = UnfoldSim.predef_eeg(; noiselevel = 8)\n\nbasisfunction = firbasis(τ = (-0.1, 0.5), sfreq = 100; interpolate = false)\n\nf = @formula 0 ~ 1 + condition + continuous # 1\n\nm = fit(UnfoldModel, [Any => (f, basisfunction)], evts, data, eventcolumn = \"type\") Plot the results plot_erp(coeftable(m))\n\n#=\nThe coefficients are represented by three lines on a figure:\n- the intercept showing the reference category for a typical p1/n1/p3 ERP components;\n- the slope of continuous variables with 1µV range;\n- the effect of categorical variabe with 3µV range.\n=#"},{"id":55,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"Effects function","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#Effects-function","content":" Effects function In order to better understand the actual predicted ERP curves, often researchers had to do manual contrasts. Remember that a linear model is  y = X * b , which allows (after  b  was estimated) to input a so-called  contrast  vector for X. You might know this in the form of  [1, 0, -1, 1]  or similar form. However, for larger models, this method can be prone to errors. The  effects  function is a convenient way to specify contrast vectors by providing the actual levels of the experimental design. It can be used to calculate all possible combinations of multiple variables. If a predictor-variable is not specified here, the function will automatically set it to its typical value. This value is usually the  mean , but for categorical variables, it could be something else. The R package  emmeans  has a lot of discussion on this topic. eff = effects(Dict(:condition => [\"car\", \"face\"]), m)\nplot_erp(eff; mapping = (; color = :condition,)) We can also generate continuous predictions: eff = effects(Dict(:continuous => -5:0.5:5), m)\nplot_erp(\n    eff;\n    mapping = (; color = :continuous, group = :continuous => nonnumeric),\n    categorical_color = false,\n    categorical_group = false,\n) Or we can split our marginal effects by condition and calculate all combinations \"automagically\". eff = effects(Dict(:condition => [\"car\", \"face\"], :continuous => -5:2:5), m)\nplot_erp(eff; mapping = (; color = :condition, col = :continuous))"},{"id":56,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"What is typical anyway?","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#What-is-typical-anyway?","content":" What is typical anyway? The  effects  function includes an argument called  typical , which specifies the function applied to the marginalized covariates/factors. The default value is  mean , which is usually sufficient for analysis. However, for skewed distributions, it may be more appropriate to use the  mode , while for outliers, the  median  or  winsor  mean may be more appropriate. To illustrate, we will use the  maximum  function on the  continuous  predictor. eff_max = effects(Dict(:condition => [\"car\", \"face\"]), m; typical = maximum)\neff_max.typical .= :maximum\neff = effects(Dict(:condition => [\"car\", \"face\"]), m)\neff.typical .= :mean # mean is the default\n\nplot_erp(vcat(eff, eff_max); mapping = (; color = :condition, col = :typical)) This page was generated using  Literate.jl ."},{"id":59,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Using Unfold.jl from Python","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Using-Unfold.jl-from-Python","content":" Using Unfold.jl from Python it is straight forward to call Unfold from Python using  JuliaCall ."},{"id":60,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Quick start","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Quick-start","content":" Quick start Create a Python environment and install JuliaCall. pip install juliacall Create a Julia environment and install Unfold # Import the Julia package manager\nfrom juliacall import Pkg as jlPkg\n\n# Activate the environment in the current folder\njlPkg.activate(\".\")\n\n# Install Unfold (in the activated environment)\njlPkg.add(\"Unfold\") Import Julia's main module and Unfold # Import Julia's Main module\nfrom juliacall import Main as jl\n\n# Import Unfold\n# The function seval() can be used to evaluate a piece of Julia code given as a string\njl.seval(\"using Unfold\")\nUnfold = jl.Unfold # simplify name Now you can use all Unfold functions as for example dummy_model = Unfold.UnfoldLinearModel(jl.Dict())"},{"id":61,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Example: Unfold model fitting from Python","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Example:-Unfold-model-fitting-from-Python","content":" Example: Unfold model fitting from Python In this  notebook , you can find a more detailed example of how to use Unfold from Python to load data, fit an Unfold model and visualise the results in Python."},{"id":62,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Important limitations","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Important-limitations","content":" Important limitations Python doesnt not offer the full expressions that are available in Julia. So there are some things you need to give special attention: @formula : we havent found a way to call macros yet, even though we think it should be possible. For now please use  f = jl.seval(\"@formula(0~1+my+cool+design)\") . Later versions might support something like  f = @formula(\"0~1+my+cool+design)\"  directly Specifying the design : Since Unfold 0.7 we officially switched to the [\"eventtypeA\"=>(formula,basisfunction),\n\"eventtypeB\"=>(otherformula,otherbasisfunction)] Array-based syntax, from a Dict-based syntax. Unfortunately,  =>  (a pair) is not supported in Python and one needs to do some rewriting: jl.convert(jl.Pair,(formula,basisfunction)) which makes the code less readable. We are thinking of ways to remedy this - but right now there is now way around. For now, it is also possible to use the old syntax e.g. in python {\"eventtypeA\"=>(formula,basisfunction),\"eventtypeB\"=>(otherformula,otherbasisfunction)} which is clearly easier to read :) UnfoldSim.design : we need a  Dict  with a  Symbol  , one has to do something like  condition_dict_jl = {convert(jl.Symbol,\"condA\"):[\"car\", \"face\"]}  to do so. We will [try to allow strings}(https://github.com/unfoldtoolbox/UnfoldSim.jl/issues/96) here as well, removing this constraint. When preprocessing your raw data through MNE Python, take the following into consideration: The  Raw object  contains the  first_samp  attribute which is an integer representing the number of time samples that passed between the onset of the hardware acquisition system and the time when data recording started. The Raw data doesn't include these time samples, meaning that the first sample is the beginning of the data aquisition. From the Raw object you can obtain an events array from the annotations through  mne.events from annotations() . The events array, however, does include first samp, meaning that the annotated events in events array don't match the Raw object anymore. Alternatively, it might be easier to convert the annotations to a pandas dataframe directly (`to data frame()`), or even better, load the \"* events.tsv\" from a BIDS dataset. In the latter case, all columns will be preserved, which MNE's read_annotation drops. This page was generated using  Literate.jl ."},{"id":67,"pagetitle":"Save and load Unfold models","title":"Save and load Unfold models","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#unfold_io","content":" Save and load Unfold models Unfold.jl allows storing Unfold models in a memory-efficient way using (compressed) .jld2 files."},{"id":68,"pagetitle":"Save and load Unfold models","title":"Simulate EEG data and fit an Unfold model","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Simulate-EEG-data-and-fit-an-Unfold-model","content":" Simulate EEG data and fit an Unfold model Click to expand"},{"id":69,"pagetitle":"Save and load Unfold models","title":"Simulate some example data using UnfoldSim.jl","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Simulate-some-example-data-using-UnfoldSim.jl","content":" Simulate some example data using UnfoldSim.jl using UnfoldSim\ndata, events = UnfoldSim.predef_eeg(; n_repeats = 10)\nfirst(events, 5) 5×3 DataFrame Row continuous condition latency Float64 String Int64 1 2.77778 car 62 2 -5.0 face 132 3 -1.66667 car 196 4 -5.0 car 249 5 5.0 car 303"},{"id":70,"pagetitle":"Save and load Unfold models","title":"Fit an Unfold model","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Fit-an-Unfold-model","content":" Fit an Unfold model using Unfold\nbasisfunction = firbasis(τ = (-0.5, 1.0), sfreq = 100, name = \"stimulus\")\nf = @formula 0 ~ 1 + condition + continuous\nbfDict = Dict(Any => (f, basisfunction))\nm = fit(UnfoldModel, bfDict, events, data); ┌ Warning:  using `Dict(:A=>(@formula,times/basisfunction))` is deprecated, please use `[:A=>(@formula,times/basisfunction)]` from now on\n └  @ Unfold ~/work/Unfold.jl/Unfold.jl/src/fit.jl:74"},{"id":71,"pagetitle":"Save and load Unfold models","title":"Save and load the fitted Unfold model","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Save-and-load-the-fitted-Unfold-model","content":" Save and load the fitted Unfold model The following code saves the model in a compressed .jld2 file. The default option of the  save  function is  compress=false . For memory efficiency the designmatrix is set to missing. If needed, it can be reconstructed when loading the model. save_path = mktempdir(; cleanup = false) # create a temporary directory for the example\nsave(joinpath(save_path, \"m_compressed.jld2\"), m; compress = true); The  load  function allows to retrieve the model again. By default, the designmatrix is reconstructed. If it is not needed set  generate_Xs=false ` which improves time-efficiency. m_loaded = load(joinpath(save_path, \"m_compressed.jld2\"), UnfoldModel, generate_Xs = true); This page was generated using  Literate.jl ."},{"id":74,"pagetitle":"Non-Linear effects","title":"[Non-linear effects]](@id nonlinear)","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#[Non-linear-effects]](@id-nonlinear)","content":" [Non-linear effects]](@id nonlinear) using BSplineKit, Unfold\nusing CairoMakie\nusing DataFrames\nusing Random\nusing Colors\nusing Missings"},{"id":75,"pagetitle":"Non-Linear effects","title":"Generating a non-linear signal","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#Generating-a-non-linear-signal","content":" Generating a non-linear signal We start with generating data variables rng = MersenneTwister(2) # make repeatable\nn = 20 # number of datapoints\nevts = DataFrame(:x => rand(rng, n))\nsignal = -(3 * (evts.x .- 0.5)) .^ 2 .+ 0.5 .* rand(rng, n)\n\nplot(evts.x, signal) Looks perfectly non-linear. Great!"},{"id":76,"pagetitle":"Non-Linear effects","title":"Compare linear & non-linear fit","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#Compare-linear-and-non-linear-fit","content":" Compare linear & non-linear fit First, we have to reshape  signal  data to a 3d array, so it will fit to Unfold format:  1 channel x 1 timepoint x 20 datapoints. signal = reshape(signal, length(signal), 1, 1)\nsignal = permutedims(signal, [3, 2, 1])\nsize(signal) (1, 1, 20) Next we define three different models:  linear ,  4 splines  and  10 splines . Note difference in formulas: one  x , the other  spl(x, 4) . design_linear = [Any => (@formula(0 ~ 1 + x), [0])];\ndesign_spl3 = [Any => (@formula(0 ~ 1 + spl(x, 4)), [0])];\ndesign_spl10 = [Any => (@formula(0 ~ 1 + spl(x, 10)), [0])]; Next, fit the parameters. uf_linear = fit(UnfoldModel, design_linear, evts, signal);\nuf_spl3 = fit(UnfoldModel, design_spl3, evts, signal); Extract the fitted values using Unfold.effects. p_linear = Unfold.effects(Dict(:x => range(0, stop = 1, length = 100)), uf_linear);\np_spl3 = Unfold.effects(Dict(:x => range(0, stop = 1, length = 100)), uf_spl3);\np_spl10 = Unfold.effects(Dict(:x => range(0, stop = 1, length = 100)), uf_spl10);\nfirst(p_linear, 5) 5×5 DataFrame Row yhat channel x time eventname Float64 Int64 Float64 Int64 DataType 1 0.0328538 1 0.0 0 Any 2 0.0273313 1 0.010101 0 Any 3 0.0218088 1 0.020202 0 Any 4 0.0162863 1 0.030303 0 Any 5 0.0107638 1 0.040404 0 Any Plot them. pl = plot(evts.x, signal[1, 1, :])\nlines!(p_linear.x, p_linear.yhat)\nlines!(p_spl3.x, coalesce.(p_spl3.yhat, NaN))\nlines!(p_spl10.x, coalesce.(p_spl10.yhat, NaN))\npl We see here, that the linear effect (blue line) underfits the data, the yellow  spl(x, 10)  overfits it, but the green  spl(x, 4)  fits it perfectly."},{"id":77,"pagetitle":"Non-Linear effects","title":"Looking under the hood","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#Looking-under-the-hood","content":" Looking under the hood Let's have a brief look how the splines manage what they are managing. The most important bit to understand is, that we are replacing  x  by a set of coefficients  spl(x) . These new coefficients each tile the range of  x  (in our case, from [0-1]) in overlapping areas, while each will be fit by one coefficient. Because the ranges are overlapping, we get a smooth function. Maybe this becomes clear after looking at a  basisfunction : term_spl = Unfold.formulas(uf_spl10)[1].rhs.terms[2] spl(x, 10) This is the spline term. Note, this is a special type available in the BSplineKit.jl extension in Unfold.jl. It's abstract type is  AbstractSplineTerm  defined in Unfold.jl typeof(term_spl) UnfoldBSplineKitExt.BSplineTerm{StatsModels.ContinuousTerm{Float64}, Int64} const splFunction = Base.get_extension(Unfold, :UnfoldBSplineKitExt).splFunction\nsplFunction([0.2], term_spl) 1×10 Matrix{Float64}:\n 0.492619  0.438047  0.0670761  0.00225775  0.0  0.0  0.0  0.0  0.0  0.0 Each column of this 1-row matrix is a coefficient for our regression model. lines(disallowmissing(splFunction([0.2], term_spl))[1, :]) Note: We have to use  disallowmissing , because our splines return a  missing  whenever we ask it to return a value outside its defined range, e.g.: splFunction([-0.2], term_spl) 1×10 Matrix{Union{Missing, Float64}}:\n missing  missing  missing  missing  …  missing  missing  missing  missing Because it never has seen any data outside and can't extrapolate! Back to our main issue. Let's plot the whole basis set basisSet = splFunction(0.0:0.01:1, term_spl)\nbasisSet = disallowmissing(basisSet[.!any(ismissing.(basisSet), dims = 2)[:, 1], :]) # remove missings\nax = Axis(Figure()[1, 1])\n[lines!(ax, basisSet[:, k]) for k = 1:size(basisSet, 2)]\ncurrent_figure() Notice how we flipped the plot around, i.e. now on the x-axis we do not plot the coefficients, but the  x -values. Now each line is one basis-function of the spline. Unfold returns us one coefficient per basis-function β = coef(uf_spl10)[1, 1, :]\nβ = Float64.(disallowmissing(β)) 10-element Vector{Float64}:\n -0.43629459354570777\n -0.3477308181329035\n  0.4538614574712754\n -0.4065207930158754\n  0.7346158579524353\n  0.9252913204020701\n  0.27167896791779556\n -0.046335871160806175\n -0.5822988416277803\n -0.6202082891592833 But because we used an intercept, we have to do some remodelling in the  basisSet . X = hcat(ones(size(basisSet, 1)), basisSet[:, 1:5], basisSet[:, 7:end]) 71×10 Matrix{Float64}:\n 1.0  0.972634     0.027217  0.000148709  …  0.0         0.0       0.0\n 1.0  0.705645     0.274339  0.0196948       0.0         0.0       0.0\n 1.0  0.492619     0.438047  0.0670761       0.0         0.0       0.0\n 1.0  0.327462     0.530129  0.135118        0.0         0.0       0.0\n 1.0  0.204084     0.56237   0.216645        0.0         0.0       0.0\n 1.0  0.116392     0.546557  0.304483     …  0.0         0.0       0.0\n 1.0  0.0582934    0.494476  0.391456        0.0         0.0       0.0\n 1.0  0.0236969    0.417914  0.470391        0.0         0.0       0.0\n 1.0  0.00651001   0.328658  0.534112        0.0         0.0       0.0\n 1.0  0.000640778  0.238493  0.575444        0.0         0.0       0.0\n ⋮                                        ⋱                        \n 1.0  0.0          0.0       0.0             0.500742    0.335973  0.0\n 1.0  0.0          0.0       0.0             0.472071    0.412937  0.0\n 1.0  0.0          0.0       0.0             0.423651    0.500839  0.0\n 1.0  0.0          0.0       0.0          …  0.354694    0.596875  0.00252938\n 1.0  0.0          0.0       0.0             0.272257    0.677546  0.0249338\n 1.0  0.0          0.0       0.0             0.186241    0.711843  0.0899373\n 1.0  0.0          0.0       0.0             0.106554    0.668749  0.220272\n 1.0  0.0          0.0       0.0             0.0431012   0.517244  0.438668\n 1.0  0.0          0.0       0.0          …  0.00579053  0.226308  0.767859 Now we can weight the spline by the  basisfunction . weighted = (β .* X') 10×71 Matrix{Float64}:\n -0.436295    -0.436295    -0.436295    …  -0.436295     -0.436295\n -0.338215    -0.245375    -0.171299       -0.0          -0.0\n  0.0123527    0.124512     0.198813        0.0           0.0\n -6.04533e-5  -0.00800637  -0.0272678      -0.0          -0.0\n  1.39303e-7   0.00023577   0.00165858      0.0           0.0\n  0.0          0.0          0.0         …   0.0           0.0\n  0.0          0.0          0.0             0.000268113   1.15869e-5\n -0.0         -0.0         -0.0            -0.00199713   -0.000268309\n -0.0         -0.0         -0.0            -0.30119      -0.131779\n -0.0         -0.0         -0.0            -0.272066     -0.476232 Plotting them creates a nice looking plot! ax = Axis(Figure()[1, 1])\n[lines!(weighted[k, :]) for k = 1:10]\ncurrent_figure() Now sum them up. lines(sum(weighted, dims = 1)[1, :])\nplot!(X * β, color = \"gray\") #(same as matrixproduct X*β directly!)\ncurrent_figure() And this is how you can think about splines. This page was generated using  Literate.jl ."},{"id":80,"pagetitle":"Predictions","title":"The predict-family","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#The-predict-family","content":" The predict-family # Setup\nusing Unfold\nusing UnfoldSim\nusing CairoMakie\n\ndat, evts = UnfoldSim.predef_eeg(noiselevel = 5)\ndesign = [\n    \"car\" => (@formula(0 ~ 1 + continuous), firbasis(τ = (-0.5, 1), sfreq = 100)),\n    \"face\" => (@formula(0 ~ 1 + continuous), firbasis(τ = (-0.3, 0.5), sfreq = 100)),\n]\n\nm = fit(UnfoldModel, design, evts, dat; eventcolumn = :condition);"},{"id":81,"pagetitle":"Predictions","title":"Overview","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Overview","content":" Overview In a linear model  $EEG = Xβ + e$ , predictions boil down to finding  $\\hat{EEG} = Xβ$ , thus EEG data without any error term. Different types of predictions can be generated by modifying the  $X$  accordingly. Note We simulated only a single channel, all results generalize to the multi channel case"},{"id":82,"pagetitle":"Predictions","title":"Different types of predictions","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Different-types-of-predictions","content":" Different types of predictions"},{"id":83,"pagetitle":"Predictions","title":"Time-Continuous case","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Time-Continuous-case","content":" Time-Continuous case Let's start with the cases, where the EEG was not epoched before using Unfold, i.e. the EEG was analysed with e.g. FIR-deconvolution"},{"id":84,"pagetitle":"Predictions","title":"Continuous EEG","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Continuous-EEG","content":" Continuous EEG In the most simple case, we can predict the continuously modelled EEG - This returns  $EEG = Xβ$ p = predict(m) # same as predict(m, overlap = true)\nlines(p[1, 1:1000])"},{"id":85,"pagetitle":"Predictions","title":"No-overlap","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#No-overlap","content":" No-overlap We can also predict each epoch without any overlap - This results in one prediction Array per event (in our case we have two events \"car\" and \"face\", thus  size(p[1]) = 2 p = predict(m, overlap = false)\nsize(p) (2,) Each Array has the size (1, samples, epochs): size(p[1]) (1, 151, 1000) Visualizing the 1000 events series(range(-0.5, 1, step = 1 / 100), p[1][1, :, :]', solid_color = :orange)\nseries!(range(-0.3, 0.5, step = 1 / 100), p[2][1, :, :]', solid_color = :teal)\ncurrent_figure() Note At ~0.3s we can see a split between the predicted EEG single trials into 10 \"strands\" - this is the granularity of our continuous predictor. You could use  effects  to improve upon this granularity / customize it."},{"id":86,"pagetitle":"Predictions","title":"With-overlap, epoched","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#With-overlap,-epoched","content":" With-overlap, epoched Sometimes helpful is to add in the overlap we removed via the deconvolution. p = predict(m, epoch_to = [\"car\"], eventcolumn = :condition)\nseries(range(-0.5, 1, step = 1 / 100), p[1, :, 1:3]', solid_color = :orange)"},{"id":87,"pagetitle":"Predictions","title":"Partial-overlap","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Partial-overlap","content":" Partial-overlap We can also include/exclude certain events with \"partial-overlap\", i.e. only overlap with kept events. p_car = predict(m, keep_basis = [\"car\"], eventcolumn = :condition)\np_face = predict(m, exclude_basis = [\"car\"], eventcolumn = :condition) # same as keep_basis=[\"face\"]\nf = lines(p_car[1, 1:1000])\nlines!(p_face[1, 1:1000])\nf In the plot, we see the two partial predictions for car and face. They are respectively \"0\" outside the basisfunction windows Note The above options can be combined as well, e.g. to get an  epoch_to ,  exclude_basis  version.  epoch_timewindow  can be specified as well. This page was generated using  Literate.jl ."},{"id":90,"pagetitle":"Window Length Effect","title":"Window length effects","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Window-length-effects","content":" Window length effects using Unfold, UnfoldSim\nusing CairoMakie, AlgebraOfGraphics, MakieThemes\nusing Random\nusing DataFrames, DataFramesMeta\nusing ColorSchemes, Colors Important For analyzing real-world EEG data we recommend that researchers should — a priori — make an educated guess about the length of the underlying EEG activity and select this as their EW. This also suggests to use event windows with different sizes between events (as is possible with Unfold). Further, as can be seen below, when choosing longer time-windows the overfit is only of moderate size, thus we additionally recommend to generally err on the longer side, to not miss any important activity.  For a more in depth explanation on this, you can read our 2023 CCN paper:  Skukies & Ehinger, 2023 set_theme!(theme_ggthemr(:fresh)) As opposed to classical averaged ERPs overlap corrected regression ERPs can be influenced by the chosen window length: Long estimation windows might capture all relevant event-related activity, but might introduce artifacts due to overfit, short estimation windows might not overfit, but also might not capture all (overlapping) activity, and thereby introduce bias. Thus a common question we get is, how to specify the length of the estimation windows."},{"id":91,"pagetitle":"Window Length Effect","title":"Init functions","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Init-functions","content":" Init functions First we need a function that simulates some continous data; conviently we can use UnfoldSim for this function gen_data(rng, noiselevel, sfreq)\n    noise = PinkNoise(; noiselevel = noiselevel)\n\n    dat, evts = UnfoldSim.predef_eeg(\n        rng;\n        sfreq = sfreq,\n        p1 = (p100(; sfreq = sfreq), @formula(0 ~ 1 + condition), [5, 0], Dict()),\n        n1 = (n170(; sfreq = sfreq), @formula(0 ~ 1 + condition), [5, 0], Dict()),\n        p3 = (p300(; sfreq = sfreq), @formula(0 ~ 1 + continuous), [5, 0], Dict()),\n        n_repeats = 20,\n        noise = noise,\n    )\n    return dat, evts\nend; Next a convience function to calculate the estimates function calc_time_models(evts, dat, tWinList, sfreq)\n    mList = []\n    for twindow in tWinList\n        m = fit(\n            UnfoldModel,\n            [Any => (@formula(0 ~ 1), firbasis(twindow, sfreq))],\n            evts,\n            dat,\n        )\n        res = coeftable(m)\n        res.tWin .= string.(Ref(twindow[2]))\n        push!(mList, res)\n    end\n    return vcat(mList...)\nend;"},{"id":92,"pagetitle":"Window Length Effect","title":"Init variables","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Init-variables","content":" Init variables tWinList = [(-0.1, x) for x in [3, 2.5, 2, 1.5, 1, 0.5]]\nnoiselevel = 8.5\nsfreq = 250;"},{"id":93,"pagetitle":"Window Length Effect","title":"Generate data and calculate estimates","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Generate-data-and-calculate-estimates","content":" Generate data and calculate estimates dat, evts = gen_data(MersenneTwister(2), noiselevel, sfreq);\n\nres = calc_time_models(evts, dat, tWinList, sfreq); We also append some additional information to the results dataframe For comparison lets also generate the ground truth of our data; this is a bit cumbersome and you don't have to care (too much) about it dat_gt, evts_gt = UnfoldSim.predef_eeg(;\n    p1 = (p100(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()),\n    sfreq = sfreq,\n    n1 = (n170(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()),\n    p3 = (p300(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()),\n    n_repeats = 1,\n    noiselevel = 0,\n    return_epoched = true,\n);\ntime_gt = range(0, length = length(dat_gt[:, 1]), step = 1 / sfreq)\nunique_event = unique(res.tWin)\ndf_gt = DataFrame(\n    tWin = reduce(vcat, fill.(unique_event, length(dat_gt[:, 1]))),\n    eventname = Any,\n    channel = repeat([1], length(dat_gt[:, 1]) * length(unique_event)),\n    coefname = reduce(\n        vcat,\n        fill(\"GroundTruth\", length(dat_gt[:, 1]) * length(unique_event)),\n    ),\n    estimate = repeat(dat_gt[:, 1], length(unique_event)),\n    group = reduce(vcat, fill(nothing, length(dat_gt[:, 1]) * length(unique_event))),\n    stderror = reduce(vcat, fill(nothing, length(dat_gt[:, 1]) * length(unique_event))),\n    time = repeat(time_gt, length(unique_event)),\n); And append ground truth to our results df res_gt = vcat(res, df_gt);"},{"id":94,"pagetitle":"Window Length Effect","title":"Plot results","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Plot-results","content":" Plot results Choose which data to plot h_t =\n    AlgebraOfGraphics.data(res) * mapping(\n        :time,\n        :estimate,\n        color = :tWin,\n        group = (:tWin, :coefname) => (x, y) -> string(x[2]) * y,\n    ); We use the following to plot some length indicator lines untWin = unique(res_gt.tWin)\nsegDF = DataFrame(\n    :x => hcat(repeat([-0.1], length(untWin)), parse.(Float64, untWin))[:],\n    :y => repeat(reverse(1:length(untWin)), outer = 2),\n)\nsegDF.tWin .= \"0.0\"\nsegDF.tWin .= segDF.x[reverse(segDF.y .+ 6)]\nsegDF.y = segDF.y .* 0.2 .+ 6; Layer for indicator lines h_l =\n    AlgebraOfGraphics.data(@subset(segDF, :tWin .!= \"3.0\")) *\n    mapping(:x, :y, color = :tWin, group = :tWin => x -> string.(x)); Ground truth Layer h_gt =\n    AlgebraOfGraphics.data(df_gt) *\n    mapping(:time, :estimate, group = (:tWin, :coefname) => (x, y) -> string(x) * y) *\n    visual(Lines, linewidth = 5, color = Colors.Gray(0.6)); Add all visuals together and draw h1 =\n    h_gt + visual(Lines, colormap = get(ColorSchemes.Blues, 0.3:0.01:1.2)) * (h_l + h_t) |>\n    x -> draw(x, axis = (; xlabel = \"time [s]\", ylabel = \"estimate [a.u.]\")); Add zero grid lines h1 = hlines!(current_axis(), [0], color = Colors.Gray(0.8));\nh2 = vlines!(current_axis(), [0], color = Colors.Gray(0.8));\ntranslate!(h1, 0, 0, -1);\ntranslate!(h2, 0, 0, -1); Plot figure current_figure() This page was generated using  Literate.jl ."},{"id":97,"pagetitle":"Solver/optimizer implementations","title":"Solver implementation","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Solver-implementation","content":" Solver implementation This document describes how the  solver_main  is implemented and how to add custom solvers. some setup using Unfold, UnfoldSim, CairoMakie\nusing LinearAlgebra: cholesky"},{"id":98,"pagetitle":"Solver/optimizer implementations","title":"Solver main","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Solver-main","content":" Solver main This function gis a eneral purpose solver-wrapper function. It calls   prepare_fun  and iterates over the first dimension of  data , repeatedly calling the  solver_fun . Without any bells and whistles (progress, history etc.) the function roughly looks like this: function _solver_min(X, data; prepare_fun, solver_fun!, stderror = false)\n    Ĥ, dataP, prepared = prepare_fun(X, data)\n    for ch = 1:size(dataP, 2)\n        for t = 1:size(dataP, 3)\n            ch == 1 || copyto!(view(Ĥ, ch, :, t), view(Ĥ, ch - 1, :, t))\n            solver_fun!(view(Ĥ, ch, :, t), view(dataP, :, ch, t), prepared...)\n        end\n    end\n    modelfit = stderror ? calculate_stderror(X, data, Ĥ) : nothing\n\n    return modelfit\n\nend _solver_min (generic function with 1 method) Before diving into the  prepare_fun  and  solver_fun!  functions, let's discuss first the inner loop  t=1:size(dataP,3) . This loop really only comes alife (that is  size(dataP,3)!=1 ) if a mass-univariate model is fitted, that is, when ndims(data)==3`. We still have it around for 2D, un-epoched data, to have exactly the same code in both cases."},{"id":99,"pagetitle":"Solver/optimizer implementations","title":"prepare_fun`","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#prepare_fun","content":" prepare_fun ` This function is the setup / prepare function. It is typically a chain of functions with similar input / output characteristica. The first fuction of the chain/pipeline should be a function taking  (X,data) and returning  (Ĥ::AbstractArray, dataP::AbstractArray, prepared::Tuple) . Ĥ  is used to save the beta/parameters inplace dataP  is the data in format ch x repeat x time (with size(time) = 1 if data initially was a Matrix/2D-array) prepared  is a tuple of all the other variables needed in the solver-step, e.g. the  pinv(X)  or  X'X  or simply  X The  prepare  function which is typiclly the first, just permutes the data & converts everything to GPU in case  data::CuArray . The next function in a pipeline then would take this  (Ĥ::AbstractArray, dataP::AbstractArray, prepared::Tuple)  inputs and process it further.`"},{"id":100,"pagetitle":"Solver/optimizer implementations","title":"solver_fun!","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#solver_fun!","content":" solver_fun! This function actually performs the fitting. It takes the inputs  (Ĥ::view(Matrix),data::view(Array),prepared::Tuple) Ĥ  is the current beta/parameters view, a vector/slice for one channel and one timepoint data  is similarly the current data view, a vector/slice for one channel and one timepoint prepared  is the tuple-output of the  prepare  function. The  solver_fun!  can output some history of the solver, e.g. a log for iterative solvers."},{"id":101,"pagetitle":"Solver/optimizer implementations","title":"Example (simple)","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Example-(simple)","content":" Example (simple) let's setup our own solver: _my_solver!(Ĥ, data, X) = Ĥ .= Matrix(X) \\ data _my_solver! (generic function with 1 method) let's simulate some data and see this in action data, evts = UnfoldSim.predef_eeg()\nm = fit(\n    UnfoldModel,\n    @formula(0 ~ 1 + condition),\n    evts,\n    data,\n    firbasis((-0.1, 0.5), 100);\n    solver = (x, y) ->\n        Unfold.solver_main(x, y; solver_fun! = _my_solver!, show_time = true),\n) Unfold�[38;2;239;83;80m-�[39mType: �[38;2;206;147;216m::UnfoldLinearModelContinuousTime�[39m{{Float64}} \n �[1m Any�[22m �[38;2;239;83;80m=�[39m�[38;2;239;83;80m>�[39m �[38;2;239;83;80mAny�[39m: timeexpand(�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m condition) for times �[38;2;239;83;80m[�[39m�[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.1�[39m, �[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.09�[39m ... �[38;2;144;202;249m0.5�[39m�[38;2;239;83;80m]�[39m \n \n�[1m�[32m✔�[22m�[39m model is fit.  size(coefs) (�[38;2;144;202;249m1�[39m, �[38;2;144;202;249m122�[39m) \n \nUseful functions: �[38;2;255;238;88m`design(uf)`�[39m, �[38;2;255;238;88m`designmatrix(uf)`�[39m, �[38;2;255;238;88m`coef(uf)`�[39m, �[38;2;255;238;88m`coeftable(uf)`�[39m Remember from this table the time for one solve (~700ms on my test-computer) this is the time per channel. series(coef(m))"},{"id":102,"pagetitle":"Solver/optimizer implementations","title":"Cholesky Example","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Cholesky-Example","content":" Cholesky Example Note the following function is already implemented in Unfold.jl as well. See  ?Unfold.solver_predefined Given that the  prepare  function returns all necessary ingredients, this is a bit simple. So let's make it more complex for nicety, we need some unpacking wrappers _prepare_cholesky(all::Tuple) = _prepare_cholesky(all...)\n_prepare_cholesky(Ĥ, data, all::Tuple) = _prepare_cholesky(Ĥ, data, all...) _prepare_cholesky (generic function with 2 methods) this function effectively only pre-calculates the cholesky decomposition _prepare_cholesky(Ĥ, data, Xt, R_xx, R_xy) = (Ĥ, data, (Xt, cholesky(R_xx), R_xy)) _prepare_cholesky (generic function with 3 methods) now we have everything to put together our solver-pipeline _my_prepare =\n    (x, y) -> Unfold.prepare(collect(x), y) |> Unfold.prepare_XTX |> _prepare_cholesky #4 (generic function with 1 method) let's test (note we have to reshape the data) @time _my_prepare(modelmatrix(m), reshape(data, 1, :)) ([0.0 0.0 … 0.0 0.0], [0.31631798033146774; 0.40338935529989906; … ; -0.22230944464885682; -0.01320095208877194;;], ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0], LinearAlgebra.Cholesky{Float64, Matrix{Float64}}([44.721359549995796 0.0 … 1.1627553482998907 0.9167878707749137; 0.0 44.721359549995796 … 0.9391485505499116 1.1627553482998907; … ; 52.0 42.0 … 22.354427580020936 0.0008355409821590546; 41.0 52.0 … 0.0 22.354385443812227], 'U', 0), [5.0e-324, 0.0, 5.0e-324, 1.0e-323, 5.0e-324, 5.0e-324, 2.5e-323, 1.3e-322, 0.0, 2.0e-323  …  1.8e-322, 1.2731974873e-313, 1.73e-322, 1.83e-322, 5.0e-324, 1.8e-322, 1.9e-322, 6.902036085116e-310, 1.9e-322, 1.93e-322])) finally, we need a solver this is how we solve the single-channel equation function _my_cholesky!(beta, data, Xt, XtX_cholesky, R_xy)\n    @time Unfold.calc_Rxy!(R_xy, Xt, data)\n    @time beta .= XtX_cholesky \\ R_xy\nend\n\nm = fit(\n    UnfoldModel,\n    @formula(0 ~ 1 + condition),\n    evts,\n    data,\n    firbasis((-0.1, 0.5), 100);\n    solver = (x, y) -> Unfold.solver_main(\n        x,\n        y;\n        prepare_fun = _my_prepare,\n        solver_fun! = _my_cholesky!,\n        show_time = true,\n    ),\n) Unfold�[38;2;239;83;80m-�[39mType: �[38;2;206;147;216m::UnfoldLinearModelContinuousTime�[39m{{Float64}} \n �[1m Any�[22m �[38;2;239;83;80m=�[39m�[38;2;239;83;80m>�[39m �[38;2;239;83;80mAny�[39m: timeexpand(�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m condition) for times �[38;2;239;83;80m[�[39m�[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.1�[39m, �[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.09�[39m ... �[38;2;144;202;249m0.5�[39m�[38;2;239;83;80m]�[39m \n \n�[1m�[32m✔�[22m�[39m model is fit.  size(coefs) (�[38;2;144;202;249m1�[39m, �[38;2;144;202;249m122�[39m) \n \nUseful functions: �[38;2;255;238;88m`design(uf)`�[39m, �[38;2;255;238;88m`designmatrix(uf)`�[39m, �[38;2;255;238;88m`coef(uf)`�[39m, �[38;2;255;238;88m`coeftable(uf)`�[39m This (on my test-computer) took only 97ms per channel, so it is ~7x faster per channel. series(coef(m)) This page was generated using  Literate.jl ."},{"id":105,"pagetitle":"Installing Julia + Unfold.jl","title":"Installation","ref":"/UnfoldDocs/Unfold.jl/stable/installation/#install_instruct","content":" Installation"},{"id":106,"pagetitle":"Installing Julia + Unfold.jl","title":"Installing Julia","ref":"/UnfoldDocs/Unfold.jl/stable/installation/#Installing-Julia","content":" Installing Julia The easiest way to install julia is using  juliaup TLDR;  Windows:  winget install julia -s msstore Mac/Linux:  curl -fsSL https://install.julialang.org | sh We further recommend to use VSCode. Make sure to install the Julia-Plugin, and install Revise.jl -  a tutorial with screenshots can be found here"},{"id":107,"pagetitle":"Installing Julia + Unfold.jl","title":"Installing Unfold.jl","ref":"/UnfoldDocs/Unfold.jl/stable/installation/#Installing-Unfold.jl","content":" Installing Unfold.jl You can enter the package manager (similar to conda) using  ]  in the REPL (\"julia-commandline\"). This should result in  (currentFolder) pkg>  (with  currentFolder  being the project you currently work in) Hint if you see  (@v1.9) pkg>  instead, you still have to activate your environment. This can be done using: cd(\"/path/to/your/project\")   and  ]activate . or alternatively  ]activate /path/to/your/project/ Now you can do  pkg> add Unfold and after some installation: julia> using Unfold  in the REPL"},{"id":110,"pagetitle":"Solver benchmarks","title":"Benchmarks","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Benchmarks","content":" Benchmarks We ran benchmarks on 2024-11-07 as described in  ./benchmark/cuda/solver_comparison.jl . Given that some were run on a GPU, we cannot run them on continuous-integration online. Important Allocations are only CPU allocations - GPU allocations were not counted.  Solvers other than  default_multi  are currently  NOT  multi-threaded Solvers other than  default_multi  and  krylov_gpu  solve  $X'Xb = X'y$  instead of  $Xb=y$  directly. They are likely less accurate, but should be faster for multi-channel data, as we can precalulate cholesky, qr or similar & the to-be-inverted matrix is much smaller."},{"id":111,"pagetitle":"Solver benchmarks","title":"Small Model","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Small-Model","content":" Small Model n_channels = 1,\nsfreq = 10,\nn_splines = 4,\nn_repeats = 10; gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float64 0.068 (1190, 130) 1 (0.2, 0.2) PosDefException(-1) false cholesky Float64 0.00056 0.00069 0.068 (1190, 130) 1 (0.2, 0.2) true intern Float64 0.00088 0.00017 0.068 (1190, 130) 1 (0.2, 0.2) false intern Float64 0.0011 0.00069 0.068 (1190, 130) 1 (0.2, 0.2) true qr Float64 0.0013 0.00019 0.068 (1190, 130) 1 (0.2, 0.2) false cg Float64 0.0015 0.00057 0.068 (1190, 130) 1 (0.2, 0.2) false default_multi Float64 0.0017 0.00016 0.068 (1190, 130) 1 (0.2, 0.2) false qr Float64 0.002 0.00076 0.068 (1190, 130) 1 (0.2, 0.2) true cg Float64 0.0054 0.00056 0.068 (1190, 130) 1 (0.2, 0.2) true pinv Float64 0.0054 0.00032 0.068 (1190, 130) 1 (0.2, 0.2) false pinv Float64 0.016 0.0016 0.068 (1190, 130) 1 (0.2, 0.2) true krylov_gpu Float64 0.032 0.0013 0.068 (1190, 130) 1 (0.2, 0.2)"},{"id":112,"pagetitle":"Solver benchmarks","title":"small-to-midsize: multi-channel","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#small-to-midsize:-multi-channel","content":" small-to-midsize: multi-channel n_channels = 128,\nsfreq = 100,\nn_splines = 4,\nn_repeats = 200;"},{"id":113,"pagetitle":"Solver benchmarks","title":"Float64","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Float64","content":" Float64 gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float64 0.0068 (239522, 1210) 128 (0.2, 0.2) PosDefException(-1) true qr Float64 0.38 0.25 0.0068 (239522, 1210) 128 (0.2, 0.2) true pinv Float64 0.42 0.26 0.0068 (239522, 1210) 128 (0.2, 0.2) true intern Float64 0.7 0.25 0.0068 (239522, 1210) 128 (0.2, 0.2) true cg Float64 1.2 0.32 0.0068 (239522, 1210) 128 (0.2, 0.2) false cholesky Float64 1.5 0.31 0.0068 (239522, 1210) 128 (0.2, 0.2) false qr Float64 1.7 0.31 0.0068 (239522, 1210) 128 (0.2, 0.2) false cg Float64 2.0 0.3 0.0068 (239522, 1210) 128 (0.2, 0.2) false pinv Float64 2.1 0.38 0.0068 (239522, 1210) 128 (0.2, 0.2) true krylov_gpu Float64 5.9 0.4 0.0068 (239522, 1210) 128 (0.2, 0.2) false default_multi Float64 13.0 1.2 0.0068 (239522, 1210) 128 (0.2, 0.2) false intern Float64 13.0 1.7 0.0068 (239522, 1210) 128 (0.2, 0.2)"},{"id":114,"pagetitle":"Solver benchmarks","title":"Float32","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Float32","content":" Float32 gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float32 0.0068 (239522, 1210) 128 (0.2, 0.2) PosDefException(-1) true krylov_gpu Float32 0.0068 (239522, 1210) 128 (0.2, 0.2) true pinv Float32 0.39 0.25 0.0068 (239522, 1210) 128 (0.2, 0.2) true qr Float32 0.62 0.24 0.0068 (239522, 1210) 128 (0.2, 0.2) true intern Float32 0.69 0.24 0.0068 (239522, 1210) 128 (0.2, 0.2) true cg Float32 1.2 0.31 0.0068 (239522, 1210) 128 (0.2, 0.2) false cholesky Float32 1.2 0.17 0.0068 (239522, 1210) 128 (0.2, 0.2) false cg Float32 1.3 0.16 0.0068 (239522, 1210) 128 (0.2, 0.2) false qr Float32 1.4 0.17 0.0068 (239522, 1210) 128 (0.2, 0.2) false pinv Float32 1.6 0.21 0.0068 (239522, 1210) 128 (0.2, 0.2) false intern Float32 13.0 0.86 0.0068 (239522, 1210) 128 (0.2, 0.2) false default_multi Float32 13.0 0.97 0.0068 (239522, 1210) 128 (0.2, 0.2)"},{"id":115,"pagetitle":"Solver benchmarks","title":"large, realistic model","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#large,-realistic-model","content":" large, realistic model     n_channels = 128,\n    sfreq = 500,\n    n_splines = (4, 4),\n    n_repeats = 500, gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float64 0.0015 (3001479, 9616) 128 (0.2, 0.2) PosDefException(-1) false cholesky Float64 0.0015 (3001479, 9616) 128 (0.2, 0.2) PosDefException(2760) false intern Float64 0.0015 (3001479, 9616) 128 (0.2, 0.2) SingularException(9599) true cg Float64 9.3 3.6 0.0015 (3001479, 9616) 128 (0.2, 0.2) true qr Float64 11.0 3.5 0.0015 (3001479, 9616) 128 (0.2, 0.2) true intern Float64 13.0 3.5 0.0015 (3001479, 9616) 128 (0.2, 0.2) false qr Float64 80.0 6.3 0.0015 (3001479, 9616) 128 (0.2, 0.2) true pinv Float64 80.0 4.2 0.0015 (3001479, 9616) 128 (0.2, 0.2) true krylov_gpu Float64 107.0 3.9 0.0015 (3001479, 9616) 128 (0.2, 0.2) false default_multi Float64 500.0 15.0 0.0015 (3001479, 9616) 128 (0.2, 0.2) false pinv Float64 520.0 11.0 0.0015 (3001479, 9616) 128 (0.2, 0.2) false cg Float64 939.0 5.7 0.0015 (3001479, 9616) 128 (0.2, 0.2)"},{"id":118,"pagetitle":"Overview of package extensions","title":"Package-extensions","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#Package-extensions","content":" Package-extensions In  Julia 1.9 Package Extensions were introduced. Unfold.jl is making use of them in four ways. Prior to using some functionality, you have to add + load specific package(s) for the functionality to be available. The reason for this is, that if you don't need e.g. GPU-support, you also will not need to install it."},{"id":119,"pagetitle":"Overview of package extensions","title":"MixedModels","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#MixedModels","content":" MixedModels To use formulas like  @formula(0~1+condition+(1+condition|subject))  you have to load MixedModels. e.g. using MixedModels\nusing Unfold"},{"id":120,"pagetitle":"Overview of package extensions","title":"GPU: Krylov,CUDA","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#GPU:-Krylov,CUDA","content":" GPU: Krylov,CUDA To use gpu support as described in @Ref(custom_solvers) you have to: using Krylov,CUDA\nusing Unfold"},{"id":121,"pagetitle":"Overview of package extensions","title":"RobustSolvers.jl","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#RobustSolvers.jl","content":" RobustSolvers.jl To use robust (outlier-\"safe\") solvers support as described in @Ref(custom_solvers) you have to: using RobustSolvers\nusing Unfold"},{"id":122,"pagetitle":"Overview of package extensions","title":"Non-linear effects: BSplineKit.jl","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#Non-linear-effects:-BSplineKit.jl","content":" Non-linear effects: BSplineKit.jl Finally to use non-linear effects/splines like in  @formula 0~1+spl(continuous,5)  you have to use: using BSplineKit\nusing Unfold Note In principle you should be able to load the package after loading Unfold. But sometimes this doesnt work, a  Base.retry_load_extensions()  call might help in these situations."},{"id":125,"pagetitle":"API: Functions","title":"Effects.effects","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Effects.effects-Union{Tuple{T}, Tuple{AbstractDict, T}} where T<:UnfoldModel","content":" Effects.effects  —  Method effects(design::AbstractDict, model::UnfoldModel; typical = mean) Calculates marginal effects for all term combinations in  design . Implementation based on Effects.jl package; likely could repackage in UnfoldEffects.jl; somebody wants to do it? This would make it easier to cross-maintain it to changes/bug fixes in the Effects.jl package.  design  is a dictionary containing those predictors (as keys) with levels (as values), that you want to evaluate. The  typical  refers to the value, which other predictors that are not specified in the dictionary, should take on. For MixedModels, the returned effects are based on the \"typical\" subject, i.e. all random effects are put to 0. Example  julia> f = @formula 0 ~ categoricalA + continuousA + continuousB\n julia> uf = fit(UnfoldModel, (Any => (f, times)), data, events)\n julia> d = Dict(:categorical => [\"levelA\", \"levelB\"], :continuous => [-2, 0, 2])\n julia> effects(d, uf) will result in 6 predicted values: A/-2, A/0, A/2, B/-2, B/0, B/2. source"},{"id":126,"pagetitle":"API: Functions","title":"FileIO.load","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#FileIO.load-Tuple{Any, Type{<:UnfoldModel}}","content":" FileIO.load  —  Method FileIO.load(file, ::Type{<:UnfoldModel}; generate_Xs=true) Load UnfoldModel from a .jld2 file.  By default, the designmatrix is reconstructed. If it is not needed set  generate_Xs=false  which improves time-efficiency. source"},{"id":127,"pagetitle":"API: Functions","title":"FileIO.save","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#FileIO.save-Union{Tuple{T}, Tuple{Any, T}} where T<:UnfoldModel","content":" FileIO.save  —  Method FileIO.save(file, uf::T; compress=false) where {T<:UnfoldModel} Save UnfoldModel in a (by default uncompressed) .jld2 file. For memory efficiency the designmatrix is set to missing. If needed, it can be reconstructed when loading the model. source"},{"id":128,"pagetitle":"API: Functions","title":"StatsAPI.coefnames","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.coefnames-Tuple{Unfold.TimeExpandedTerm}","content":" StatsAPI.coefnames  —  Method coefnames(term)\n coefnames of a TimeExpandedTerm concatenates the basis-function name with the kronecker product of the term name and the basis-function colnames. Separator is ' : ' Some examples for a firbasis:         basis 313 : (Intercept) : 0.1         basis 313 : (Intercept) : 0.2         basis_313 : (Intercept) : 0.3         ... source"},{"id":129,"pagetitle":"API: Functions","title":"StatsAPI.fit","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{T}, StatsModels.FormulaTerm, DataFrames.AbstractDataFrame, AbstractArray, Union{Unfold.BasisFunction, AbstractArray}}} where T<:UnfoldModel","content":" StatsAPI.fit  —  Method fit(type::UnfoldModel,d::Vector{Pair},tbl::AbstractDataFrame,data::Array)\nfit(type::UnfoldModel,f::FormulaTerm,tbl::AbstractDataFrame,data::Array{T,3},times)\nfit(type::UnfoldModel,f::FormulaTerm,tbl::AbstractDataFrame,data::Array{T,2},basisfunction::BasisFunction) Generates Designmatrix & fits model, either mass-univariate (one model per epoched-timepoint) or time-expanded (modeling linear overlap). keyword arguments fit::Bool  (default:  true ) - fit the model after constructing the designmatrix. Setting this to  false  is sometimes helpful if you only want to inspect the designmatrix. contrasts::Dict : (default:  Dict() ) contrast to be applied to formula. Example:  Dict(:my_condition=>EffectsCoding()) . More information here: https://juliastats.org/StatsModels.jl/stable/contrasts/ eventcolumn::Union{Symbol,String}  (default  :event ) - the column in  tbl  to differentiate the basisfunctions as defined in  d::Vector{Pair} solver::function : (default:  solver_default ). The solver used for  y=Xb , e.g.  (X,y;kwargs...) -> solver_default(X,y;kwargs...) . There are faster & alternative solvers available, see  solver_predefined  for a list of options, see  solver benchmark  in the online documentation. To use the GPU, you can provide the data as a  CuArray  after  using CUDA . Please change the solver to e.g.  solver_predef(X,y;solver=:qr)  as lsmr+cuda => crash typically. It's worth though, speed increases >100x possible show_progress::Bool  (default  true ) - show progress via ProgressMeter - passed to  solver eventfields::Array: (optional, default [:latency] ) Array of symbols, representing column names in tbl`, which are passed to basisfunction event-wise. First field of array always defines eventonset in samples. If a  Vector[Pairs]  is provided, it has to have one of the following structures: For  deconvolution  analyses (use  Any=>(f,bf)  to match all rows of  tbl  in one basis functions). Assumes  data  is a continuous EEG stream, either a  Vector  or a  ch x time Matrix f1 = @formula(0~1+my_condition)\n[\n :A=>(f1,firbasis((-0.1,1),128), # sfreq = 128Hz\n :B=>(f2,firbasis((-3,2),128)\n] for  mass-univariate  analyses without deconvolution. Assumes  data  to be cut into epochs already (see  Unfold.epoch ). Follows  eeglab  standard  ch x time x trials : timesvector = range(-0.1,3,step=1/100)\n[\n :A=>(f1,timesvector),\n :B=>(f2,timesvector)\n] Notes The  type  can be specified directly as well e.g.  fit(type::UnfoldLinearModel)  instead of relying on the automatic inference The data is reshaped if it is missing one dimension to have the first dimension then  1  \"Channel\". Examples Mass Univariate Linear julia> data,evts = UnfoldSim.predef_eeg()\njulia> data_e,times = Unfold.epoch(data=data,tbl=evts,τ=(-1.,1.9),sfreq=100) # cut the data into epochs. data_e is now ch x times x epoch\n\njulia> f  = @formula 0~1+continuousA+continuousB \njulia> model = fit(UnfoldModel,f,evts,data_e,times)\n# or:\njulia> model = fit(UnfoldModel,[Any=>(f,times)],evts,data_e) Timexpanded Univariate Linear julia> basisfunction = firbasis(τ=(-1,1),sfreq=10)\njulia> model = fit(UnfoldModel,f,evts,data,basisfunction)\n# or\njulia> model = fit(UnfoldModel,[Any=>(f,basisfunction],evts,data) source"},{"id":130,"pagetitle":"API: Functions","title":"StatsAPI.modelmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.modelmatrix","content":" StatsAPI.modelmatrix  —  Function StatsModels.modelmatrix(uf::UnfoldLinearModelContinuousTime, basisfunction = true) Setting the optional second args to false, will return the modelmatrix without the timeexpansion / basisfunction applied. source"},{"id":131,"pagetitle":"API: Functions","title":"StatsAPI.modelmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.modelmatrix-Tuple{UnfoldLinearModel, Any}","content":" StatsAPI.modelmatrix  —  Method modelmatrix(uf::UnfoldLinearModel) returns the modelmatrix of the model. Concatenates them, except in the MassUnivariate cases, where a vector of modelmatrices is return Compare with  modelmatrices  which returns a vector of modelmatrices, one per event source"},{"id":132,"pagetitle":"API: Functions","title":"StatsAPI.predict","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.predict-Tuple{Any, Vector{<:StatsModels.FormulaTerm}, Vector{<:DataFrames.DataFrame}}","content":" StatsAPI.predict  —  Method function predict(\n    uf::UnfoldModel,\n    f::Vector{<:FormulaTerm},\n    evts::Vector{<:DataFrame};\n    overlap::Bool = true,\n    kwargs...\n) Returns a predicted (\"y_hat = X*b\")  Array .  uf  is an  <:UnfoldModel f  is a (vector of) formulas, typically  Unfold.formulas(uf) , but formulas can be modified e.g. by  effects . evts  is a (vector of) events, can be  Unfold.events(uf)  to return the (possibly continuous-time) predictions of the model. Can be a custom even kwargs: if  overlap = true  (default), overlap based on the  latency  column of  evts  will be simulated, or in the case of  !ContinuousTimeTrait  just X*coef is returned.  if  overlap = false , returns predictions without overlap (models with  ContinuousTimeTrait  (=> with basisfunction / deconvolution) only), via  predict_no_overlap if  keep_basis  or  exclude_basis  is defined, then  predict_partial_overlap  is called, which allows to selective introduce overlap based on specified (or excluded respective) events/basisfunctions epoch_to  and   epoch_timewindow : calculate (partial) overlap controlled predictions, but returns them at the specified  epoch_at  event, with the times  epoch_timewindow  (default is taken from the basisfunction) in samples. eventcolumn  can be specified as well if different from the default  event . Hint: all  kwargs  can be  Vector , or if e.g.  string  types are provided, will be put into a  length==1  vector. Output If  overlap=false , returns a 3D-Array If  overlap=true  and  epoch_to = nothing  (default), returns a 2D-array If  overlap=true  and  epoch_to != nothing , returns a 3D array source"},{"id":133,"pagetitle":"API: Functions","title":"StatsModels.modelcols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsModels.modelcols-Tuple{Unfold.TimeExpandedTerm, Any}","content":" StatsModels.modelcols  —  Method modelcols(term, tbl)\n calculates the actual designmatrix for a timeexpandedterm. Multiple dispatch on StatsModels.modelcols source"},{"id":134,"pagetitle":"API: Functions","title":"Unfold._modelcols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold._modelcols-Tuple{StatsModels.FormulaTerm, Any}","content":" Unfold._modelcols  —  Method _modelcols(form::FormulaTerm, events) source"},{"id":135,"pagetitle":"API: Functions","title":"Unfold._modelcols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold._modelcols-Tuple{Vector, Vector}","content":" Unfold._modelcols  —  Method _modelcols(forms::Vector,events::Vector) A wrapper around StatsModels.modelcols that is only needed for easy multiple dispatch source"},{"id":136,"pagetitle":"API: Functions","title":"Unfold.apply_basisfunction","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.apply_basisfunction-Tuple{Any, Unfold.BasisFunction, Any, Any}","content":" Unfold.apply_basisfunction  —  Method apply_basisfunction(\n    form,\n    basisfunction,\n    eventfields,\n    eventname\n)\n timeexpand the rhs-term of the formula with the basisfunction source"},{"id":137,"pagetitle":"API: Functions","title":"Unfold.combine_yhat!","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.combine_yhat!-Union{Tuple{T}, Tuple{Vector{<:Array{T}}, Array{T}}} where T","content":" Unfold.combine_yhat!  —  Method combine_yhat(list,single) combines single into list, if either list or single contains missing, automatically casts the respective counter-part to allow missings as well source"},{"id":138,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{Any, Any, Any}","content":" Unfold.designmatrix  —  Method designmatrix(type, f, tbl; kwargs...) call without basis function, continue with basisfunction =  nothing source"},{"id":139,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{Type{<:UnfoldModel}, Union{Tuple, StatsModels.FormulaTerm}, Any, Any}","content":" Unfold.designmatrix  —  Method designmatrix(\n    unfoldmodeltype,\n    f,\n    tbl,\n    basisfunction;\n    contrasts,\n    eventname,\n    kwargs...\n)\n designmatrix(type, f, tbl; kwargs...) Return a  DesignMatrix  used to fit the models. Arguments type::UnfoldModel f::FormulaTerm: Formula to be used in this designmatrix tbl: Events (usually a data frame) to be modelled basisfunction::BasisFunction: basisfunction to be used in modeling (if specified) contrasts::Dict: (optional) contrast to be applied to formula eventfields::Array: (optional) Array of symbols which are passed to basisfunction event-wise.  First field of array always defines eventonset in samples. Default is [:latency] Examples julia>  designmatrix(UnfoldLinearModelContinuousTime,Dict(Any=>(f,basisfunction1),tbl) source"},{"id":140,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{Type{<:UnfoldModel}, Vector{<:Pair}, Any}","content":" Unfold.designmatrix  —  Method designmatrix(\n    T::Type{<:UnfoldModel},\n    design_array::Vector{<:Pair},\n    tbl;\n    eventcolumn = :event,\n    contrasts = Dict{Symbol,Any}(),\n    kwargs..., iteratively calls  designmatrix  for each event in the design_array, and returns a list of  <:AbstractDesignMatrix source"},{"id":141,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{UnfoldModel, Any}","content":" Unfold.designmatrix  —  Method designmatrix(\n    uf::UnfoldModel,\n    tbl;\n    eventcolumn = :event,\n    contrasts = Dict{Symbol,Any}(),\n    kwargs..., Main function called from  fit(UnfoldModel...) , generates the designmatrix, returns a list of  <:AbstractDesignMatrix source"},{"id":142,"pagetitle":"API: Functions","title":"Unfold.drop_missing_epochs","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.drop_missing_epochs-Union{Tuple{T}, Tuple{Any, AbstractArray{T, 3}}} where T","content":" Unfold.drop_missing_epochs  —  Method [X,y] = drop_missing_epochs(X, y::Array) Helper function to remove epochs of  y  that contain missings. Drops them from both  X  and   y . Often used in combination with  Unfold.epoch X can be anything that has two dimensions (Matrix, DataFrame etc) source"},{"id":143,"pagetitle":"API: Functions","title":"Unfold.empty_modelmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.empty_modelmatrix-Tuple{AbstractDesignMatrix}","content":" Unfold.empty_modelmatrix  —  Method empty_modelmatrix(d::AbstractDesignMatrix) returns an empty modelmatrix of the type DesignMatrix type of  d source"},{"id":144,"pagetitle":"API: Functions","title":"Unfold.epoch","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.epoch-Union{Tuple{T}, Tuple{Vector{T}, Any, Any, Any}} where T<:Union{Missing, Number}","content":" Unfold.epoch  —  Method epoch(data::Array{T,1},evts::DataFrame,τ::Tuple/Vector,sfreq;kwargs..., Basic function to epoch data; all input also available as kwargs. Additional kwarg:  eventtime =:latency, which defines the column in  evts  that is used to cut the data (in samples). For uneven sample-times we use  round() ` source"},{"id":145,"pagetitle":"API: Functions","title":"Unfold.equalize_size","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.equalize_size-Union{Tuple{T}, Tuple{AbstractMatrix, AbstractMatrix{T}}} where T<:(Union{Missing, var\"#s133\"} where var\"#s133\"<:Number)","content":" Unfold.equalize_size  —  Method equalize_size(X, data)\n Equates the length of data and designmatrix by cutting the shorter one The reason we need this is because when generating the designmatrix, we do not know how long the data actually are. We only assume that event-latencies are synchronized with the data source"},{"id":146,"pagetitle":"API: Functions","title":"Unfold.firbasis","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.firbasis","content":" Unfold.firbasis  —  Function firbasis(τ, sfreq; ...)\nfirbasis(τ, sfreq, name; interpolate)\n Generate a sparse FIR basis around the  τ  timevector at sampling rate  sfreq . This is useful if you cannot make any assumptions on the shape of the event responses. If unrounded events are supplied, they are split between samples. E.g. event-latency = 1.2 will result in a \"0.8\" and a \"0.2\" entry. keyword arguments interpolate  (Bool, default false): if true, interpolates events between samples linearly. This results in  predict  functions to return a trailling 0 Examples Generate a FIR basis function from -0.1s to 0.3s at 100Hz julia>  f = firbasis([-0.1,0.3],100) Evaluate at an event occuring at sample 103.3 julia>  f(103.3) source"},{"id":147,"pagetitle":"API: Functions","title":"Unfold.firkernel","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.firkernel-Tuple{Any, Any}","content":" Unfold.firkernel  —  Method firkernel(e, times; interpolate)\n Calculate a sparse firbasis Examples julia>  f = firkernel(103.3,range(-0.1,step=0.01,stop=0.31)) source"},{"id":148,"pagetitle":"API: Functions","title":"Unfold.formulas","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.formulas-Tuple{Vector{<:Pair}}","content":" Unfold.formulas  —  Method formulas(design::Vector{<:Pair}) returns vector of formulas, no schema has been applied (those formulas never saw the data). Also no timeexpansion has been applied (in the case of timecontinuous models) source"},{"id":149,"pagetitle":"API: Functions","title":"Unfold.get_basis_colnames","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.get_basis_colnames-Tuple{AbstractArray{<:StatsModels.FormulaTerm}}","content":" Unfold.get_basis_colnames  —  Method get_basis_colnames(m)\nget_basis_colnames(formulas) returns list of colnames - e.g. times for firbasis. source"},{"id":150,"pagetitle":"API: Functions","title":"Unfold.get_basis_indices","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.get_basis_indices-Tuple{Any, Vector}","content":" Unfold.get_basis_indices  —  Method get_basis_indices(uf, basisnames::Vector) returns a boolean vector with length spanning all coefficients, which coefficient is defined by  basisnames  (vector of names) source"},{"id":151,"pagetitle":"API: Functions","title":"Unfold.get_basis_names","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.get_basis_names-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T}} where T<:UnfoldModel","content":" Unfold.get_basis_names  —  Method get_basisnames(model::UnfoldModel) Return the basisnames for all predictor terms as a vector. The returned vector contains the name of the event type/basis, repeated by their actual coefficient number (after StatsModels.apply_schema / timeexpansion). If a model has more than one event type (e.g. stimulus and fixation), the vectors are concatenated. source"},{"id":152,"pagetitle":"API: Functions","title":"Unfold.hrfbasis","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.hrfbasis-Tuple{Float64}","content":" Unfold.hrfbasis  —  Method hrfbasis(TR; parameters, name)\n Generate a Hemodynamic-Response-Functio (HRF) basis with inverse-samplingrate \"TR\" (=1/FS) Optional Parameters p:                                                            defaults                                                           {seconds}         p(1) - delay of response (relative to onset)          6         p(2) - delay of undershoot (relative to onset)       16         p(3) - dispersion of response                         1         p(4) - dispersion of undershoot                       1         p(5) - ratio of response to undershoot                6         p(6) - onset {seconds}                                0         p(7) - length of kernel {seconds}                    32 Examples Generate a HRF basis function object with Sampling rate 1/TR. And evaluate it at an event occuring at TR 103.3 with duration of 4.1 TRs julia>  f = hrfbasis(2.3)\njulia>  f(103.3,4.1)\n source"},{"id":153,"pagetitle":"API: Functions","title":"Unfold.hrfkernel","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.hrfkernel-Tuple{Any, Any, Any}","content":" Unfold.hrfkernel  —  Method hrfkernel(e, TR, p)\n Calculate a HRF kernel. Input e can be [onset duration] Examples julia>  f = hrfkernel(103.3,2.3,[6. 16. 1. 1. 6. 0. 32.]) source"},{"id":154,"pagetitle":"API: Functions","title":"Unfold.linearize","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.linearize-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}","content":" Unfold.linearize  —  Method linearize(x)\n Flatten a 1D array from of a 2D/3D array. Also drops the empty dimension source"},{"id":155,"pagetitle":"API: Functions","title":"Unfold.matrix_by_basisname","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.matrix_by_basisname-Tuple{AbstractMatrix, Any, Vector}","content":" Unfold.matrix_by_basisname  —  Method Returns a view of the Matrix  y , according to the indices of the timeexpanded  basisname source"},{"id":156,"pagetitle":"API: Functions","title":"Unfold.modelmatrices","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.modelmatrices-Tuple{AbstractDesignMatrix}","content":" Unfold.modelmatrices  —  Method modelmatrices(X::AbstractDesignMatrix)\nmodelmatrices(X::Vector{<:AbstractDesignMatrix})\nmodelmatrices(modelmatrix::AbstractMatrix) Returns the modelmatrices (also called designmatrices) separately for the events. This is similar to  StatsModels.modelcols , but merely access the precomputed designmatrix. If the designmatrix needs to be computed, please use  modelcols Compare to  modelmatrix  which further concatenates the designmatrices (in the ContinuousTime case). source"},{"id":157,"pagetitle":"API: Functions","title":"Unfold.predict_no_overlap","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.predict_no_overlap-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T, Any, Vector, Vector}} where T<:UnfoldModel","content":" Unfold.predict_no_overlap  —  Method predict_no_overlap(, uf, coefs, f, evts)\n in ContinuousTime case (typically the deconvolution model), we return idealized predictions without overlap between events. in the Not-ContinuousTime case (typically the MassUnivariate model), we return predictions for each event independently. In that case, the function is unfortunately a missnomer, as overlap cannot be removed from mass-univariate models. source"},{"id":158,"pagetitle":"API: Functions","title":"Unfold.predict_partial_overlap","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.predict_partial_overlap-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T, Any}} where T<:UnfoldModel","content":" Unfold.predict_partial_overlap  —  Method predict_partial_overlap(, uf, args; kwargs...)\n Returns predicted time-continuous values, but only for a subset of events. This is achieved by excluding the part of the designmatrix that belongs to the basisfunctions/events you do not want to have in your model. Typically called via  predict , for configuration, keyword-arguments and usage see there. One difference is, that we require the  coefs(uf::UnfoldModel)  already exctracted.  Due to the time-continuous nature, running it with a model not containing the  ContinuousTimeTrait  it will throw an error. source"},{"id":159,"pagetitle":"API: Functions","title":"Unfold.predicttable","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.predicttable","content":" Unfold.predicttable  —  Function predicttable(model<:UnfoldModel,events=Unfold.events(model),args...;kwargs...) Shortcut to call efficiently call (pseudocode)  result_to_table(predict(...)) . Returns a tidy DataFrame with the predicted results. Loops all input to  predict , but really only makes sense to use if you specify either: overlap = false  (the default) or  epoch_to = \"eventname\" . source"},{"id":160,"pagetitle":"API: Functions","title":"Unfold.prepare","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.prepare-Union{Tuple{T}, Tuple{Any, AbstractMatrix{<:Union{Missing, T}}}} where T<:Number","content":" Unfold.prepare  —  Method prepare(X, data)\n convert and permutedim input to follow the following output: Ĥ, Y, X = prepare(X, data) where  Ĥ  is used to save the beta,  Y  is the data in format ch x repeat x time (with size(time) = 1 if data is a Matrix), and  X . if data is a CuArray, everything is transformed to CuArrays as well (via UnfoldCUDAExt.jl, CUDA needs to be loaded) same datatype between X and data is enforced source"},{"id":161,"pagetitle":"API: Functions","title":"Unfold.prepare_XTX","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.prepare_XTX-Tuple{Tuple}","content":" Unfold.prepare_XTX  —  Method prepare_XTX(all)\n instead of solving y = Xb, we solve X'Xb = X'y. This function calculates X'X and instantiates X'y to be used in the solver-step, to facilitate X'y calculations later, X' is also calculated. source"},{"id":162,"pagetitle":"API: Functions","title":"Unfold.prepare_pinv","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.prepare_pinv-Tuple{Tuple}","content":" Unfold.prepare_pinv  —  Method prepare_pinv(all)\n calculates pinv of the designmatrix for later use in the solver-step. This is helpful in case you have many chanels source"},{"id":163,"pagetitle":"API: Functions","title":"Unfold.result_to_table","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.result_to_table-Tuple{Any, Any, Vector{<:DataFrames.DataFrame}}","content":" Unfold.result_to_table  —  Method result_to_table(model<:UnfoldModel, eff::AbstractArray, events::Vector{<:DataFrame})\nresult_to_table(\n    eff::AbstractArray,\n    events::Vector{<:DataFrame},\n    times::Vector{<:Vector{<:Number}},\n    eventnames::Vector)\nresult_to_table(\n    eff::Vector{<:AbstractArray},\n    events::Vector{<:DataFrame},\n    times::Vector,\n    eventnames::Vector,\n) Converts an array-result (prediction or coefficient) together with the events, to a tidy dataframe. To support multi-event models, we expect everything to be put into  Vectors  - this should be refactored at some point to be compatible with broadcasting, but it is not right now. args eff : Contains the array(s) to be converted to a tidy dataframe. Should be 3D, with channel x time x predictor  events : A vector of event-dataframes, each need to match  size(eff,3) times : A vector of time-vectors, each need to match  size(eff,2) eventnames : A vector of eventnames, either symbols or strings, should be a single entry per event source"},{"id":164,"pagetitle":"API: Functions","title":"Unfold.solver_default","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.solver_default-Tuple{Any, AbstractMatrix}","content":" Unfold.solver_default  —  Method solver_default(X, y; kwargs...)\n default solvers. If data is continuous (2D), we solve Xb = y via lsmr If data is epoched (3D) we solve Xb = y via pinv We highly recommend to check out  solver_predefined  for faster options by rather solving X'Xb = X'y via QR, cholesky, pinv or ``-solver. A benchmark is available in the online documentation. Please see  ?solver_main  for keyword arguments of the solver (like  stderror ,  multithreading ,  show_time ,  show_progress ) source"},{"id":165,"pagetitle":"API: Functions","title":"Unfold.solver_predefined","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.solver_predefined-Tuple{Any, AbstractMatrix}","content":" Unfold.solver_predefined  —  Method solver_predefined(X, y_in; solver, kwargs...)\n helper function that returns solver with appropriate prepare-pipelines and fitting solver-functions. X is a (typically sparse) designmatrix, y is a 2D or 3D array. solver  : one of  :cg ,  :pinv ,  :intern ,  :qr ,  :cholesky ,  :lsmr  (default) Only  lsmr  solves Xb = y via an iterative solver and should be more accurate in principle. The other predefined-solvers solve X'Xb = X'y which is often computationally much cheaper, and because X'X can be precalculated, it should be cheaper to apply. Testing this empirically is somewhat complicated, as depending on your sparsity structure (≈ your design) and the size of your data (sfreq & minutes) the best solver and the reached accuracy can change quite a bit. GPU All solvers except :lsmr support GPU calculations. For lsmr on the GPU try  solver_krylov  instead source"},{"id":166,"pagetitle":"API: Functions","title":"Unfold.spdiagm_diag","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.spdiagm_diag-Union{Tuple{T}, Tuple{Any, Vararg{Pair{<:Integer, T}}}} where T","content":" Unfold.spdiagm_diag  —  Method Speed improved version of spdiagm, takes a single float value instead of a vector, like a version of spdiagm that takes in a UniformScaling e.g.  sz = 5 ix = [1,3,10] spdiagm_diag(sz,(.-ix.=>1)...) source"},{"id":167,"pagetitle":"API: Functions","title":"Unfold.time_expand_allBasesSameCols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.time_expand_allBasesSameCols-Tuple{FIRBasis, Any, Any}","content":" Unfold.time_expand_allBasesSameCols  —  Method Helper function to decide whether all bases have the same number of columns per event source"},{"id":168,"pagetitle":"API: Functions","title":"Unfold.timeexpand_cols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.timeexpand_cols-NTuple{4, Any}","content":" Unfold.timeexpand_cols  —  Method timeexpand_cols(basisfunction, bases, ncolsBasis, ncolsX)\n calculates in which rows the individual event-basisfunctions should go in Xdc see also timeexpand rows timeexpand vals source"},{"id":169,"pagetitle":"API: Functions","title":"Unfold.timeexpand_rows","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.timeexpand_rows-NTuple{4, Any}","content":" Unfold.timeexpand_rows  —  Method timeexpand_rows(onsets, bases, shift, ncolsX)\n calculates in which rows the individual event-basisfunctions should go in Xdc timeexpand rows timeexpand vals source"},{"id":170,"pagetitle":"API: Functions","title":"Unfold.times","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.times-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T}} where T<:UnfoldModel","content":" Unfold.times  —  Method times(model<:UnfoldModel) returns arrays of time-vectors, one for each basisfunction / parallel-fitted-model (MassUnivarite case) source"},{"id":171,"pagetitle":"API: Functions","title":"Unfold.unfold_apply_schema","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.unfold_apply_schema-Tuple{Any, Any, Any}","content":" Unfold.unfold_apply_schema  —  Method wrapper to make apply_schema mixed models as extension possible Note: type is not necessary here, but for LMM it is for multiple dispatch reasons! source"},{"id":174,"pagetitle":"API: Types","title":"Unfold.AbstractModelFit","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.AbstractModelFit","content":" Unfold.AbstractModelFit  —  Type Abstract Type to report modelresults source"},{"id":175,"pagetitle":"API: Types","title":"Unfold.BasisFunction","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.BasisFunction","content":" Unfold.BasisFunction  —  Type See FIRBasis for an examples a BasisFunction should implement: kernel() # kernel(b::BasisFunction,sample) => returns the designmatrix for that event height() # number of samples in continuous time width()  # number of coefficient columns (e.g. HRF 1 to 3, FIR=height(),except if interpolate=true ) colnames() # unique names of expanded columns times() # vector of times along expanded columns, length = height() name() # name of basisfunction collabel() [default \"colname_basis\"] # name for coeftable shift_onset() [default 0] source"},{"id":176,"pagetitle":"API: Types","title":"Unfold.DesignMatrixLinearModel","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.DesignMatrixLinearModel","content":" Unfold.DesignMatrixLinearModel  —  Type DesignMatrix Type that keeps an Array of   formulas , designmatrices  modelmatrix  (Array or Array of Arrays in case of MixedModel) and  events -dataframe  source"},{"id":177,"pagetitle":"API: Types","title":"Unfold.FIRBasis","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.FIRBasis","content":" Unfold.FIRBasis  —  Type Defines a FIRBasisfunction which can be called for each event, defining the time-expanded basis kernel mutable struct FIRBasis <: Unfold.BasisFunction times : vector of times along rows of kernel-output (in seconds) name : name of the event, should be the actual eventName in  eventcolumn  of the dataframes later shift_onset : by how many samples do we need to shift the event onsets? This number is determined by how many 'negative' timepoints the basisfunction defines interpolate : should we linearly interpolate events not on full samples? (tipp: most users would you want to call firbasis, not generate it manually) Examples julia>  b = FIRBasis(range(0,1,length=10),\"basisA\",-1) source"},{"id":178,"pagetitle":"API: Types","title":"Unfold.LinearModelFit","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.LinearModelFit","content":" Unfold.LinearModelFit  —  Type Contains the results of linearmodels (continuous and not) source"},{"id":179,"pagetitle":"API: Types","title":"Unfold.TimeExpandedTerm","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.TimeExpandedTerm","content":" Unfold.TimeExpandedTerm  —  Type Object with a  term  and an applicable  BasisFunction  and a eventfield that are later passed to the basisfunction. struct TimeExpandedTerm{T<:StatsModels.AbstractTerm} <: StatsModels.AbstractTerm term : Term that the basis function is applied to. This is regularly called in other functions to get e.g. term-coefnames and timeexpand those basisfunction : Kernel that determines what should happen to the designmatrix of the term eventfields : Which fields of the event-table should be passed to the basisfunction.Important: The first entry has to be the event-latency in samples! Examples julia>  b = TimeExpandedTerm(term,kernel,[:latencyTR,:durationTR]) source"},{"id":180,"pagetitle":"API: Types","title":"Unfold.UnfoldLinearModel","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.UnfoldLinearModel","content":" Unfold.UnfoldLinearModel  —  Type Concrete type to implement an Mass-Univariate LinearModel.  .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix modelfit  is a  Any  container for the model results source"},{"id":181,"pagetitle":"API: Types","title":"Unfold.UnfoldLinearModelContinuousTime","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.UnfoldLinearModelContinuousTime","content":" Unfold.UnfoldLinearModelContinuousTime  —  Type Concrete type to implement an deconvolution LinearModel.  .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix modelfit  is a  Any  container for the model results source"},{"id":182,"pagetitle":"API: Types","title":"Unfold.UnfoldModel","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.UnfoldModel","content":" Unfold.UnfoldModel  —  Type using Base: @deprecate_binding The main abstract model-type of the toolbox. E.g.  UnfoldLinearModel  is a concrete type of this source"},{"id":185,"pagetitle":"Mass univariate LM","title":"Mass Univariate Linear Models (no overlap correction)","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#lm_massunivariate","content":" Mass Univariate Linear Models (no overlap correction) In this notebook we will fit regression models to simulated EEG data. We will see that we need some type of overlap correction, as the events are close in time to each other, so that the respective brain responses overlap. If you want more detailed introduction to this topic check out  our paper ."},{"id":186,"pagetitle":"Mass univariate LM","title":"Setting up & loading the data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Setting-up-and-loading-the-data","content":" Setting up & loading the data using DataFrames\nusing Unfold\nusing UnfoldMakie, CairoMakie # for plotting\nusing UnfoldSim"},{"id":187,"pagetitle":"Mass univariate LM","title":"Load Data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Load-Data","content":" Load Data We'll start with some predefined simulated continuos EEG data. We have 2000 events, 1 channel and one condition with two levels data, evts = UnfoldSim.predef_eeg()"},{"id":188,"pagetitle":"Mass univariate LM","title":"Inspection","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Inspection","content":" Inspection The data has only little noise. The underlying signal pattern is a positive-negative-positive spike. times_cont = range(0,length=200,step=1/100) # we simulated with 100hz for 0.5 seconds\n\nf,ax,h = plot(times_cont,data[1:200])\nvlines!(evts[evts.latency .<= 200, :latency] ./ 100;color=:black) # show events, latency in samples!\nax.xlabel = \"time [s]\"\nax.ylabel = \"voltage [µV]\"\nf To inspect the event dataframe we use show(first(evts, 6), allcols = true) 6×3 DataFrame \n  Row  │  continuous  condition  latency  \n     │  Float64     String     Int64    \n─────┼────────────────────────────────\n   1 │   2.77778   car             62\n   2 │  -5.0       face           132\n   3 │  -1.66667   car            196\n   4 │  -5.0       car            249\n   5 │   5.0       car            303\n   6 │  -0.555556  car            366 Every row is an experimental event. Note that  :latency  refers to time in samples, (in BIDS-specification,   :onset  would typically refer to seconds)."},{"id":189,"pagetitle":"Mass univariate LM","title":"Traditional Mass Univariate Analysis","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Traditional-Mass-Univariate-Analysis","content":" Traditional Mass Univariate Analysis To perform a mass univariate analysis, you must complete the following steps: Split data into epochs  Specify a formula  Fit a linear model to each time point & channel Visualize the results."},{"id":190,"pagetitle":"Mass univariate LM","title":"1. Split data into epochs","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#1.-Split-data-into-epochs","content":" 1. Split data into epochs Initially, you have data with a duration that represents the whole experimental trial. You need to cut the data into small regular epochs related to the some event, e.g. start of fixation. # Unfold supports multi-channel, so we could provide matrix ch x time, which we can create like this from a vector:\ndata_r = reshape(data, (1,:))\n# cut the data into epochs\ndata_epochs, times = Unfold.epoch(data = data, tbl = evts, τ = (-0.4, 0.8), sfreq = 100); # channel x timesteps x trials\nsize(data_epochs) (1, 121, 2000) τ  specifies the epoch size. sfreq  - sampling rate, converts  τ  to samples. typeof(data_epochs) Array{Union{Missing, Float64}, 3} Note In julia,  missing  is supported throughout the ecosystem. Thus, we can have partial trials and they will be incorporated / ignored at the respective functions. Helpful functions are the julia-base  disallowmissing  and the internal  Unfold.drop_missing_epochs  functions"},{"id":191,"pagetitle":"Mass univariate LM","title":"2. Specify a formula","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#2.-Specify-a-formula","content":" 2. Specify a formula Define a formula to be applied to each time point (and each channel) relative to the event.  condition  and  continuous  are the names of the event-describing columns in  evts  that we want to use for modelling. f = @formula 0 ~ 1 + condition + continuous # note the formulas left side is `0 ~ ` for technical reasons`"},{"id":192,"pagetitle":"Mass univariate LM","title":"3. Fit a linear model to each time point & channel","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#3.-Fit-a-linear-model-to-each-time-point-and-channel","content":" 3. Fit a linear model to each time point & channel Fit the \" UnfoldModel \" (the  fit  syntax is used throughout the Julia ecosystem, with the first element indicating what kind of model to fit) m = fit(UnfoldModel, f, evts, data_epochs, times); ┌ Warning:  Missings in data - we remove any trial from data and designmatrix\n └  @ Unfold ~/work/Unfold.jl/Unfold.jl/src/solver/prepare.jl:19 Alternative way to call this model is below. This syntax allows you to fit multiple events at once. For example, replacing  Any  with  :fixation =>...  will fit this model specifically to the fixation event type. m = fit(UnfoldModel, [Any=>(f, times)], evts, data_epochs); ┌ Warning:  Missings in data - we remove any trial from data and designmatrix\n └  @ Unfold ~/work/Unfold.jl/Unfold.jl/src/solver/prepare.jl:19 Inspect the fitted model: m Note these functions to discover the model:  design ,  designmatrix ,  modelfit  and most importantly,  coeftable .  Info There are of course further methods, e.g. `coef`, `ranef`, `Unfold.formula`, `modelmatrix` which might be helpful at some point, but not important now. Using  coeftable , we can get a  tidy  DataFrames, very useful for your further analysis. first(coeftable(m), 6) 6×7 DataFrame Row channel coefname estimate eventname group stderror time Int64 String Float64 DataType Nothing Nothing Float64 1 1 (Intercept) 0.923324 Any -0.4 2 1 (Intercept) 0.978652 Any -0.39 3 1 (Intercept) 1.11101 Any -0.38 4 1 (Intercept) 1.33857 Any -0.37 5 1 (Intercept) 1.6288 Any -0.36 6 1 (Intercept) 1.93554 Any -0.35"},{"id":193,"pagetitle":"Mass univariate LM","title":"4. Visualize the results","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#4.-Visualize-the-results","content":" 4. Visualize the results Tidy DataFrames are easy to visualize using e.g. AlgebraOfGraphics.jl. Function  plot_erp  from  UnfoldMakie makes it even easier.   results = coeftable(m)\nplot_erp(results) As you can see, there is a lot going on, even in the baseline period! This is because the signal was simulated with overlapping events. In the next tutorial you will learn how to fix this."},{"id":196,"pagetitle":"LM overlap correction","title":"Linear Model with Overlap Correction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#lm_overlap","content":" Linear Model with Overlap Correction Note We recommend you briefly go over the mass-univariate linear modelling tutorial In this notebook we will fit regression models to (simulated) EEG data. We will see that we need some type of overlap correction, as the events are close in time to each other, so that the respective brain responses overlap. If you want more detailed introduction to this topic check out  our paper ."},{"id":197,"pagetitle":"LM overlap correction","title":"Setting up & loading the data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#Setting-up-and-loading-the-data","content":" Setting up & loading the data using Unfold\nusing UnfoldSim\nusing UnfoldMakie,CairoMakie\nusing DataFrames\n\ndata, evts = UnfoldSim.predef_eeg()"},{"id":198,"pagetitle":"LM overlap correction","title":"Overlap Correction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#Overlap-Correction","content":" Overlap Correction For an overlap correction analysis we will do one additional step: define a temporal basisfunction. The steps are as following: specify a temporal basisfunction specify a formula fit a linear model for each channel (one for all timepoints!) visualize the results."},{"id":199,"pagetitle":"LM overlap correction","title":"Timeexpanded / Deconvolved ModelFit","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#Timeexpanded-/-Deconvolved-ModelFit","content":" Timeexpanded / Deconvolved ModelFit"},{"id":200,"pagetitle":"LM overlap correction","title":"1. specify a temporal basisfunction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#1.-specify-a-temporal-basisfunction","content":" 1. specify a temporal basisfunction By default, we would want to use a FIR basisfunction. See  Basis Functions  for more details. basisfunction = firbasis(τ=(-0.4,.8),sfreq=100)"},{"id":201,"pagetitle":"LM overlap correction","title":"2. specify a formula","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#2.-specify-a-formula","content":" 2. specify a formula We specify the same formula as before f  = @formula 0~1+condition+continuous"},{"id":202,"pagetitle":"LM overlap correction","title":"3. fit the linear model","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#3.-fit-the-linear-model","content":" 3. fit the linear model The formula and basisfunction is not enough on their own. We also need to specify which event and which formula matches - this is important in cases where there are multiple events with different formulas bf_vec = [Any=>(f,basisfunction)] Note The  Any  means to use all rows in  evts . In case you have multiple events, you'd want to specify multiple basisfunctions e.g.     bfDict = [\"stimulus\"=>(f1,basisfunction1),                 \"response\"=>(f2,basisfunction2)] You likely have to specify a further argument to  fit :  eventcolumn=\"type\"  with  type  being the column in  evts  that codes for the event (stimulus / response in this case) Now we are ready to fit a  UnfoldLinearModel . Not that instead of  times  as in the mass-univariate case, we have to provide the  BasisFunction  type now. m = fit(UnfoldModel,bf_vec,evts,data);"},{"id":203,"pagetitle":"LM overlap correction","title":"4. Visualize the model","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#4.-Visualize-the-model","content":" 4. Visualize the model Similarly to the previous tutorial, we can visualize the model results = coeftable(m)\nplot_erp(results) Cool! All overlapping activity has been removed and we recovered the simulated underlying signal."},{"id":206,"pagetitle":"Mass univariate Mixed Model","title":"Mass Univariate Linear Mixed Models","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#lmm_massunivariate","content":" Mass Univariate Linear Mixed Models using Unfold\nusing UnfoldSim\nusing MixedModels # important to load to activate the UnfoldMixedModelsExtension\nusing UnfoldMakie, CairoMakie # plotting\nusing DataFrames\nusing CategoricalArrays Important You have to run  using MixedModels  before or after loading Unfold to activate the MixedModels abilities! This notebook is similar to the  Mass Univariate Linear Models (no overlap correction) tutorial , but fits mass-univariate  mixed  models - that is, one model over all subjects, instead of one model per subject. This allows to include item effects, for example."},{"id":207,"pagetitle":"Mass univariate Mixed Model","title":"Mass Univariate Mixed Models","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#Mass-Univariate-**Mixed**-Models","content":" Mass Univariate  Mixed  Models Again we have 4 steps: Split data into epochs  Specify a formula  Fit a linear model to each time point & channel Visualize the results."},{"id":208,"pagetitle":"Mass univariate Mixed Model","title":"1. Epoching","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#1.-Epoching","content":" 1. Epoching data, evts = UnfoldSim.predef_eeg(10; return_epoched = true) # simulate 10 subjects\ndata = reshape(data, 1, size(data, 1), :) # concatenate the data into a long EEG dataset\ntimes = range(0, length = size(data, 2), step = 1 / 100)\ntransform!(evts, :subject => categorical => :subject); # :subject must be categorical, otherwise MixedModels.jl complains The  events  dataFrame has an additional column (besides being much taller):  subject first(evts, 6) 6×5 DataFrame Row subject item continuous condition latency Cat… String Float64 String Int64 1 S01 I038 2.77778 face 62 2 S01 I067 1.66667 car 132 3 S01 I032 -3.88889 face 196 4 S01 I013 -2.77778 face 249 5 S01 I058 2.77778 face 303 6 S01 I094 -1.66667 face 366"},{"id":209,"pagetitle":"Mass univariate Mixed Model","title":"2. Formula specification","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#2.-Formula-specification","content":" 2. Formula specification We define the formula. Importantly, we need to specify a random effect. We use  zerocorr  to speed up the calculation. f = @formula 0 ~ 1 + condition * continuous + zerocorr(1 + condition * continuous | subject);"},{"id":210,"pagetitle":"Mass univariate Mixed Model","title":"3. Model fitting","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#3.-Model-fitting","content":" 3. Model fitting We can now run the LinearMixedModel at each time point. m = fit(UnfoldModel, f, evts, data, times) \n Progress:   4%|█▉                                       |  ETA: 0:00:11 \n   channel:  1 \n   time:     2 \n\n\n\n\n\n Progress: 100%|█████████████████████████████████████████| Time: 0:00:00 \n   channel:  1 \n   time:     45"},{"id":211,"pagetitle":"Mass univariate Mixed Model","title":"4. Visualization of results","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#4.-Visualization-of-results","content":" 4. Visualization of results Let's start with the  fixed  effects.  We see the condition effects and some residual overlap activity in the fixed effects. results = coeftable(m)\n\nres_fixef = results[isnothing.(results.group), :]\nplot_erp(res_fixef) And now comes the  random  effect: res_ranef = results[results.group .== :subject, :]\nplot_erp(res_ranef)"},{"id":212,"pagetitle":"Mass univariate Mixed Model","title":"Statistics","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#Statistics","content":" Statistics Check out the  LMM p-value tutorial"},{"id":215,"pagetitle":"LMM + overlap correction","title":"Overlap Correction with Linear Mixed Models","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#lmm_overlap","content":" Overlap Correction with Linear Mixed Models using Unfold\nusing UnfoldSim\n\nusing CategoricalArrays\nusing MixedModels\nusing UnfoldMakie, CairoMakie\nusing DataFrames This notebook is similar to the Linear Model with Overlap Correction tutorial, but fits  mixed  models with overlap correction Warning Limitation : This functionality is not ready for general use. There are still a lot of things to find out and tinker with. Don't use this if you haven't looked under the hood of the toolbox! Be aware of crashes / timeouts for non-trivial problems"},{"id":216,"pagetitle":"LMM + overlap correction","title":"Get some data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#Get-some-data","content":" Get some data dat, evts = UnfoldSim.predef_2x2(; signalsize=20, n_items=16, n_subjects=16)\n\n# We also need to fix the latencies, they are now relative to 1:size(data, 1), but we want a continuous long EEG.\nsubj_idx = [parse(Int, split(string(s), 'S')[2]) for s in evts.subject]\nevts.latency .+= size(dat, 1) .* (subj_idx .- 1)\n\ndat = dat[:] # we need all data concatenated over subjects\nevts.subject  = categorical(Array(evts.subject))"},{"id":217,"pagetitle":"LMM + overlap correction","title":"Linear Mixed Model Continuous Time","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#Linear-**Mixed**-Model-Continuous-Time","content":" Linear  Mixed  Model Continuous Time Again we have 4 steps: Specify a temporal basisfunction Specify a formula Fit a linear model for each channel (one model for all timepoints!) Visualize the results."},{"id":218,"pagetitle":"LMM + overlap correction","title":"1. Specify a temporal basisfunction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#1.-Specify-a-temporal-basisfunction","content":" 1. Specify a temporal basisfunction By default, we would want to use a FIR basis function. See  Basis Functions  for more details. basisfunction = firbasis(τ=(-0.4, .8), sfreq=20, name=\"stimulus\")"},{"id":219,"pagetitle":"LMM + overlap correction","title":"2. Specify the formula","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#2.-Specify-the-formula","content":" 2. Specify the formula Define the formula and specify a random effect.  Note We use  zerocorr  to prevent the model from computing all correlations between all timepoints and factors. f  = @formula 0 ~ 1 + A  *B + zerocorr(1 + A*B|subject); FormulaTerm\nResponse:\n  0\nPredictors:\n  1\n  A(unknown)\n  B(unknown)\n  A(unknown) & B(unknown)\n  (A,B,subject)->zerocorr((1 + A * B) | subject)"},{"id":220,"pagetitle":"LMM + overlap correction","title":"3. Fit the model","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#3.-Fit-the-model","content":" 3. Fit the model bfDict = Dict(Any=>(f, basisfunction))\n# Skipping this tutorial for now due to a significant error.\nm = fit(UnfoldModel, bfDict, evts, dat)\n\nresults = coeftable(m)\nfirst(results, 6) 6×7 DataFrame Row channel coefname estimate eventname group stderror time Int64 String Float64 Union… Union… Nothing Float64 1 1 (Intercept) 0.0728554 Any -0.4 2 1 (Intercept) 0.0941947 Any -0.35 3 1 (Intercept) 0.0694752 Any -0.3 4 1 (Intercept) 0.00866136 Any -0.25 5 1 (Intercept) -0.0422579 Any -0.2 6 1 (Intercept) -0.0524441 Any -0.15"},{"id":221,"pagetitle":"LMM + overlap correction","title":"4. Visualize results","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#4.-Visualize-results","content":" 4. Visualize results plot_erp(results; mapping=(; col = :group))"},{"id":224,"pagetitle":"UnfoldMixedModels","title":"UnfoldMixedModels","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/#UnfoldMixedModels","content":" UnfoldMixedModels Documentation for  UnfoldMixedModels . Using this package, one can fit Linear Mixed Models in a mass-univariate way (for every time-point and channel); but also combined with overlap correction (experimental!) As  UnfoldMixedModels.jl  is like an  addon  to  Unfold.jl , we recommend checking out these tutorials first. using UnfoldMixedModels\nusing UnfoldSim\ndata, evts = UnfoldSim.predef_eeg(10;return_epoched=true) # 10 subjects\ndata = reshape(data,size(data,1),:) # concatenate subjects\n\ntimes = range(-0.1,0.5,size(data,1)) # arbitrary time-vector\n\nfLMM = @formula 0 ~ 1 + condition + (1|subject) + (1|item)\nfit(UnfoldModel, [Any=>(f, times)], evts, data)\nnothing #hide"},{"id":227,"pagetitle":"Contributing guidelines","title":"Contributing guidelines","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/90-contributing/#contributing","content":" Contributing guidelines First of all, thanks for the interest! We welcome all kinds of contribution, including, but not limited to code, documentation, examples, configuration, issue creating, etc. Be polite and respectful, and follow the code of conduct."},{"id":228,"pagetitle":"Contributing guidelines","title":"Bug reports and discussions","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/90-contributing/#Bug-reports-and-discussions","content":" Bug reports and discussions If you think you found a bug, feel free to open an  issue . Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please."},{"id":229,"pagetitle":"Contributing guidelines","title":"Working on an issue","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/90-contributing/#Working-on-an-issue","content":" Working on an issue If you found an issue that interests you, comment on that issue what your plans are. If the solution to the issue is clear, you can immediately create a pull request (see below). Otherwise, say what your proposed solution is and wait for a discussion around it. Tip Feel free to ping us after a few days if there are no responses. If your solution involves code (or something that requires running the package locally), check the  developer documentation . Otherwise, you can use the GitHub interface directly to create your pull request."},{"id":232,"pagetitle":"Developer documentation","title":"Developer documentation","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#dev_docs","content":" Developer documentation Contributing guidelines If you haven't, please read the  Contributing guidelines  first. If you want to make contributions to this package that involves code, then this guide is for you."},{"id":233,"pagetitle":"Developer documentation","title":"First time clone","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#First-time-clone","content":" First time clone If you have writing rights If you have writing rights, you don't have to fork. Instead, simply clone and skip ahead. Whenever  upstream  is mentioned, use  origin  instead. If this is the first time you work with this repository, follow the instructions below to clone the repository. Fork this repo Clone your repo (this will create a  git remote  called  origin ) Add this repo as a remote: git remote add upstream https://github.com/unfoldtoolbox/UnfoldMixedModels.jl This will ensure that you have two remotes in your git:  origin  and  upstream . You will create branches and push to  origin , and you will fetch and update your local  main  branch from  upstream ."},{"id":234,"pagetitle":"Developer documentation","title":"Linting and formatting","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Linting-and-formatting","content":" Linting and formatting Install a plugin on your editor to use  EditorConfig . This will ensure that your editor is configured with important formatting settings. We use  https://pre-commit.com  to run the linters and formatters. In particular, the Julia code is formatted using  JuliaFormatter.jl , so please install it globally first: julia> # Press ]\npkg> activate\npkg> add JuliaFormatter To install  pre-commit , we recommend using  pipx  as follows: # Install pipx following the link\npipx install pre-commit With  pre-commit  installed, activate it as a pre-commit hook: pre-commit install To run the linting and formatting manually, enter the command below: pre-commit run -a Now, you can only commit if all the pre-commit tests pass ."},{"id":235,"pagetitle":"Developer documentation","title":"Testing","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Testing","content":" Testing As with most Julia packages, you can just open Julia in the repository folder, activate the environment, and run  test : julia> # press ]\npkg> activate .\npkg> test"},{"id":236,"pagetitle":"Developer documentation","title":"Working on a new issue","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Working-on-a-new-issue","content":" Working on a new issue We try to keep a linear history in this repo, so it is important to keep your branches up-to-date. Fetch from the remote and fast-forward your local main git fetch upstream\ngit switch main\ngit merge --ff-only upstream/main Branch from  main  to address the issue (see below for naming) git switch -c 42-add-answer-universe Push the new local branch to your personal remote repository git push -u origin 42-add-answer-universe Create a pull request to merge your remote branch into the org main."},{"id":237,"pagetitle":"Developer documentation","title":"Branch naming","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Branch-naming","content":" Branch naming If there is an associated issue, add the issue number. If there is no associated issue,  and the changes are small , add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update. If the changes are not small and there is no associated issue, then create the issue first, so we can properly discuss the changes. Use dash separated imperative wording related to the issue (e.g.,  14-add-tests ,  15-fix-model ,  16-remove-obsolete-files )."},{"id":238,"pagetitle":"Developer documentation","title":"Commit message","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Commit-message","content":" Commit message Use imperative or present tense, for instance:  Add feature  or  Fix bug . Have informative titles. When necessary, add a body with details. If there are breaking changes, add the information to the commit message."},{"id":239,"pagetitle":"Developer documentation","title":"Before creating a pull request","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Before-creating-a-pull-request","content":" Before creating a pull request Atomic git commits Try to create \"atomic git commits\" (recommended reading:  The Utopic Git History ). Make sure the tests pass. Make sure the pre-commit tests pass. Fetch any  main  updates from upstream and rebase your branch, if necessary: git fetch upstream\ngit rebase upstream/main BRANCH_NAME Then you can open a pull request and work with the reviewer to address any issues."},{"id":240,"pagetitle":"Developer documentation","title":"Building and viewing the documentation locally","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Building-and-viewing-the-documentation-locally","content":" Building and viewing the documentation locally Following the latest suggestions, we recommend using  LiveServer  to build the documentation. Here is how you do it: Run  julia --project=docs  to open Julia in the environment of the docs. If this is the first time building the docs Press  ]  to enter  pkg  mode Run  pkg> dev .  to use the development version of your package Press backspace to leave  pkg  mode Run  julia> using LiveServer Run  julia> servedocs()"},{"id":243,"pagetitle":"P-values for mixedModels","title":"How To get P-Values for Mass-Univariate LMM","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#lmm_pvalues","content":" How To get P-Values for Mass-Univariate LMM There are currently two ways to obtain p-values for LMMs: Wald's t-test and likelihood ratio tests (mass univariate only)."},{"id":244,"pagetitle":"P-values for mixedModels","title":"Setup","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Setup","content":" Setup using UnfoldMixedModels # we require to load MixedModels to load the PackageExtension\nusing DataFrames\nusing UnfoldSim\nusing CairoMakie\ndata_epoch, evts =\n    UnfoldSim.predef_2x2(; n_items = 52, n_subjects = 40, return_epoched = true)\ndata_epoch = reshape(data_epoch, size(data_epoch, 1), :) #\ntimes = range(0, 1, length = size(data_epoch, 1)) 0.0:0.010101010101010102:1.0"},{"id":245,"pagetitle":"P-values for mixedModels","title":"Define f0 & f1 and fit","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Define-f0-and-f1-and-fit","content":" Define f0 & f1 and fit f0 = @formula 0 ~ 1 + A + (1 + A | subject);\nf1 = @formula 0 ~ 1 + A + B + (1 + A | subject); # could also differ in random effects\n\nm0 = fit(UnfoldModel,[Any=>(f0,times)],evts,data_epoch);\nm1 = fit(UnfoldModel,[Any=>(f1,times)],evts,data_epoch);"},{"id":246,"pagetitle":"P-values for mixedModels","title":"Likelihood ratio","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Likelihood-ratio","content":" Likelihood ratio uf_lrt = likelihoodratiotest(data_epoch, m0, m1)\nuf_lrt[1] model-dof deviance χ² χ²-dof P(>χ²) �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 6 8012 �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m B �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 7 8011 1 1 0.3996 As you can see, we have some likelihood ratio outcomes, exciting!"},{"id":247,"pagetitle":"P-values for mixedModels","title":"Extract p-values","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Extract-p-values","content":" Extract p-values pvalues(uf_lrt) 100-element Vector{Vector{Float64}}:\n [0.39964251754876706]\n [0.4019640858609401]\n [0.4074237173863722]\n [0.4070454519554564]\n [0.42228971014118033]\n [0.483155056260971]\n [0.6339437552710293]\n [NaN]\n [NaN]\n [NaN]\n ⋮\n [0.34292883003473407]\n [0.33515969561309156]\n [0.33325396532570495]\n [0.3428036624385943]\n [0.3567742512609538]\n [0.37049189795207205]\n [0.38051461402659575]\n [0.3883891630406846]\n [0.39851721772119286] We have extracted the p-values and now need to make them usable.     The solution can be found in the documentation under  ?pvalues . pvals_lrt = vcat(pvalues(uf_lrt)...)\nnchan = 1\nntime = length(times)\nreshape(pvals_lrt, ntime, nchan)' # note the last transpose via ' ! 1×100 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.399643  0.401964  0.407424  0.407045  …  0.380515  0.388389  0.398517 Perfecto, these are the LRT p-values of a model  condA  vs.  condA+condB  with same random effect structure."},{"id":248,"pagetitle":"P-values for mixedModels","title":"Walds T-Test","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Walds-T-Test","content":" Walds T-Test This method is easier to calculate but has limitations in accuracy and scope. It may also be less accurate due to the liberal estimation of degrees of freedom. Testing is limited in this case, as random effects cannot be tested and only single predictors can be used, which may not be appropriate for spline effects. It is important to note that this discussion is beyond the scope of this LMM package. res = coeftable(m1)\n# only fixed effects: what is not in a ranef group is a fixef.\nres = res[isnothing.(res.group), :]\n# calculate t-value\nres[:, :tvalue] = res.estimate ./ res.stderror 300-element Vector{Float64}:\n  4.446708326696426\n  4.437580860011641\n  4.446435058073349\n  4.492672997803976\n  4.494599457419684\n  4.4880483252027075\n  4.439652303422133\n  4.45518635490581\n  4.623068236549389\n  4.663764726700654\n  ⋮\n  0.5870708293447756\n  0.43759939804174963\n  0.2172917074185397\n  0.025591530320948425\n -0.11195974844949615\n -0.28040792854804225\n -0.22668554132390997\n -0.2646530795209725\n -0.3492299276363734 We obtained Walds t, but how to translate them to a p-value? Determining the necessary degrees of freedom for the t-distribution is a complex issue with much debate surrounding it. One approach is to use the number of subjects as an upper bound for the p-value (your df will be between  $n_{subject}$  and  $\\sum{n_{trials}}$ ). df = length(unique(evts.subject)) 40 Plug it into the t-distribution. using Distributions\nres.pvalue = pdf.(TDist(df),res.tvalue) 300-element Vector{Float64}:\n 0.00010520592926163251\n 0.00010817494439425095\n 0.00010529365405567558\n 9.142141916777313e-5\n 9.088393516836884e-5\n 9.272440215982806e-5\n 0.00010749405443829126\n 0.00010251943544603832\n 6.122445474960627e-5\n 5.398423858898151e-5\n ⋮\n 0.33251660178615255\n 0.3594809847897533\n 0.38698410798874533\n 0.39632387743397085\n 0.39391857391788004\n 0.38081351375847516\n 0.38615884540577883\n 0.3824900521283194\n 0.37247026276880874"},{"id":249,"pagetitle":"P-values for mixedModels","title":"Comparison of methods","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Comparison-of-methods","content":" Comparison of methods Cool! Let's compare both methods of p-value calculation! df = DataFrame(:walds => res[res.coefname.==\"B: b_tiny\", :pvalue], :lrt => pvals_lrt)\nf = Figure()\n\nscatter(f[1,1],times,res[res.coefname .== \"B: b_tiny\",:estimate],axis=(;xlabel=\"time\",title=\"coef: B:b_tiny\"))\nscatter(f[1,2],df.walds,df.lrt,axis=(;title=\"walds-t pvalue\",ylabel=\"LRT pvalue\"))\nscatter(f[2,1],times,df.walds,axis=(;title=\"walds-t pvalue\",xlabel=\"time\"))\nscatter(f[2,2],times,df.lrt,axis=(;title=\"lrt pvalue\",xlabel=\"time\"))\n\nf Look pretty similar! Note that the Walds-T is typically too liberal (LRT also, but to a lesser exted). Best is to use the forthcoming MixedModelsPermutations.jl or go the route via R and use KenwardRoger (data not yet published)"},{"id":252,"pagetitle":"API: Functions","title":"MixedModels.likelihoodratiotest","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#MixedModels.likelihoodratiotest-Tuple{AbstractArray, Vararg{UnfoldLinearMixedModel}}","content":" MixedModels.likelihoodratiotest  —  Method likelihoodratiotest(data, m)\n Calculate likelihoodratiotest source"},{"id":253,"pagetitle":"API: Functions","title":"StatsAPI.fit!","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#StatsAPI.fit!-Union{Tuple{T}, Tuple{Union{UnfoldLinearMixedModel, UnfoldLinearMixedModelContinuousTime}, AbstractArray{T}}} where T","content":" StatsAPI.fit!  —  Method fit!(uf::UnfoldModel,data::Union{<:AbstractArray{T,2},<:AbstractArray{T,3}}) where {T<:Union{Missing, <:Number}} Fit a DesignMatrix against a 2D/3D Array data along its last dimension Data is typically interpreted as channel x time (with basisfunctions) or channel x time x epoch (for mass univariate) show_progress  (default:true), deactivate the progressmeter Returns an UnfoldModel object Examples source"},{"id":254,"pagetitle":"API: Functions","title":"StatsModels.modelcols","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#StatsModels.modelcols-Tuple{Unfold.TimeExpandedTerm{<:Union{var\"#s1\", var\"#s118\"} where {var\"#s1\"<:RandomEffectsTerm, var\"#s118\"<:MixedModels.AbstractReTerm}}, Any}","content":" StatsModels.modelcols  —  Method modelcols(term, tbl)\n This function timeexpands the random effects and generates a ReMat object source"},{"id":255,"pagetitle":"API: Functions","title":"Unfold.make_estimate","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#Unfold.make_estimate-Tuple{Union{UnfoldLinearMixedModel, UnfoldLinearMixedModelContinuousTime}}","content":" Unfold.make_estimate  —  Method Unfold.make_estimate(m::Union{UnfoldLinearMixedModel,UnfoldLinearMixedModelContinuousTime}, ) extracts betas (and sigma's for mixed models) with string grouping indicator returns as a ch x beta, or ch x time x beta (for mass univariate) source"},{"id":256,"pagetitle":"API: Functions","title":"Unfold.modelmatrices","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#Unfold.modelmatrices-Tuple{Tuple}","content":" Unfold.modelmatrices  —  Method modelmatrices(modelmatrix::Tuple) in the case of a Tuple (MixedModels - FeMat/ReMat Tuple), returns only the FeMat part source"},{"id":257,"pagetitle":"API: Functions","title":"UnfoldMixedModels.LinearMixedModel_wrapper","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.LinearMixedModel_wrapper-Union{Tuple{TData}, Tuple{Any, AbstractVector{<:TData}, Any}} where TData<:Number","content":" UnfoldMixedModels.LinearMixedModel_wrapper  —  Method LinearMixedModel_wrapper(form, data, Xs; wts)\n Wrapper to generate a LinearMixedModel. Code taken from MixedModels.jl and slightly adapted. source"},{"id":258,"pagetitle":"API: Functions","title":"UnfoldMixedModels.fake_lmm","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.fake_lmm-Union{Tuple{N}, Tuple{AbstractArray{<:Number, N}, UnfoldLinearMixedModel, Int64}} where N","content":" UnfoldMixedModels.fake_lmm  —  Method fake_lmm(data, m, k)\n Returns a partial LMM model (non-functional due to lacking data) to be used in likelihoodratiotests.  k  to selcet which of the modelfit's to fake source"},{"id":259,"pagetitle":"API: Functions","title":"UnfoldMixedModels.get_timeexpanded_random_grouping","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.get_timeexpanded_random_grouping-Tuple{Any, Any, Any}","content":" UnfoldMixedModels.get_timeexpanded_random_grouping  —  Method get_timeexpanded_random_grouping(\n    tbl_group,\n    tbl_latencies,\n    basisfunction\n)\n Get the timeranges where the random grouping variable was applied source"},{"id":260,"pagetitle":"API: Functions","title":"UnfoldMixedModels.isa_lmm_formula","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.isa_lmm_formula-Tuple{typeof(zerocorr)}","content":" UnfoldMixedModels.isa_lmm_formula  —  Method isa_lmm_formula iterates over all parts of a formula until either a  MixedModels.zerocorr , or a  |  was found. Then returns true, else returns false. source"},{"id":261,"pagetitle":"API: Functions","title":"UnfoldMixedModels.pvalues","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.pvalues-Tuple{Vector{MixedModels.LikelihoodRatioTest}}","content":" UnfoldMixedModels.pvalues  —  Method pvalues(lrtvec)\n Unfold-Method: return pvalues of likelihoodratiotests, typically calculated: Examples julia> pvalues(likelihoodratiotest(m1,m2)) where m1/m2 are UnfoldLinearMixedModel's Tipp: if you only compare two models you can easily get a vector of p-values: julia> vcat(pvalues(likelihoodratiotest(m1,m2))...) Multiple channels are returned linearized at the moment, as we do not have access to the amount of channels after the LRT, you can do: julia> reshape(vcat(pvalues(likelihoodratiotest(m1,m2))...),ntimes,nchan)' source"},{"id":262,"pagetitle":"API: Functions","title":"UnfoldMixedModels.random_effect_groupings","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.random_effect_groupings-Tuple{StatsModels.AbstractTerm}","content":" UnfoldMixedModels.random_effect_groupings  —  Method random_effect_groupings(t::MixedModels.AbstractReTerm) Returns the random effect grouping term (rhs), similar to coefnames, which returns the left hand sides source"},{"id":263,"pagetitle":"API: Functions","title":"UnfoldMixedModels.reorder_tidyσs","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.reorder_tidyσs-Tuple{Any, Any}","content":" UnfoldMixedModels.reorder_tidyσs  —  Method reorder_tidyσs(t, f) This function reorders a MixedModels.tidyσs output, according to the formula and not according to the largest RandomGrouping. source"},{"id":266,"pagetitle":"API: Types","title":"UnfoldMixedModels.UnfoldLinearMixedModel","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/types/#UnfoldMixedModels.UnfoldLinearMixedModel","content":" UnfoldMixedModels.UnfoldLinearMixedModel  —  Type Concrete type to implement an Mass-Univariate LinearMixedModel.  .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix modelfit  is a  Any  container for the model results source"},{"id":267,"pagetitle":"API: Types","title":"UnfoldMixedModels.UnfoldLinearMixedModelContinuousTime","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/types/#UnfoldMixedModels.UnfoldLinearMixedModelContinuousTime","content":" UnfoldMixedModels.UnfoldLinearMixedModelContinuousTime  —  Type Concrete type to implement an deconvolution LinearMixedModel. Warning  This is to be treated with care, not much testing went into it. .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix .modelfit  is a  Any  container for the model results source"},{"id":270,"pagetitle":"lmmERP (mass univariate)","title":"Mass Univariate Linear Mixed Models","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#lmm_massunivariate","content":" Mass Univariate Linear Mixed Models using UnfoldMixedModels\nusing UnfoldSim\n\nusing UnfoldMakie, CairoMakie # plotting\nusing DataFrames\nusing CategoricalArrays This notebook is similar to the  Unfold.jl Mass Univariate Linear Models (no overlap correction) tutorial , but fits mass-univariate  mixed  models - that is, one model over all subjects, instead of one model per subject. This allows to include item effects, for example."},{"id":271,"pagetitle":"lmmERP (mass univariate)","title":"Mass Univariate Mixed Models","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#Mass-Univariate-**Mixed**-Models","content":" Mass Univariate  Mixed  Models Again we have 4 steps: Split data into epochs Specify a formula Fit a linear model to each time point & channel Visualize the results."},{"id":272,"pagetitle":"lmmERP (mass univariate)","title":"1. Epoching","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#1.-Epoching","content":" 1. Epoching data, evts = UnfoldSim.predef_eeg(10; return_epoched = true) # simulate 10 subjects\ndata = reshape(data, 1, size(data, 1), :) # concatenate the data into a long EEG dataset\ntimes = range(0, length = size(data, 2), step = 1 / 100)\ntransform!(evts, :subject => categorical => :subject); # :subject must be categorical, otherwise MixedModels.jl complains The  events  dataFrame has an additional column (besides being much taller):  subject first(evts, 6) 6×5 DataFrame Row subject item continuous condition latency Cat… String Float64 String Int64 1 S01 I038 2.77778 face 62 2 S01 I067 1.66667 car 132 3 S01 I032 -3.88889 face 196 4 S01 I013 -2.77778 face 249 5 S01 I058 2.77778 face 303 6 S01 I094 -1.66667 face 366"},{"id":273,"pagetitle":"lmmERP (mass univariate)","title":"2. Formula specification","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#2.-Formula-specification","content":" 2. Formula specification We define the formula. Importantly, we need to specify a random effect. We use  zerocorr  to speed up the calculation. f = @formula 0 ~ 1 + condition * continuous + zerocorr(1 + condition * continuous | subject);"},{"id":274,"pagetitle":"lmmERP (mass univariate)","title":"3. Model fitting","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#3.-Model-fitting","content":" 3. Model fitting We can now run the LinearMixedModel at each time point. m = fit(UnfoldModel, f, evts, data, times) \nProgress:   4%|█▉                                       |  ETA: 0:00:12\n  channel:  1\n  time:     2\n\n\n\n\n\nProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\n  channel:  1\n  time:     45"},{"id":275,"pagetitle":"lmmERP (mass univariate)","title":"4. Visualization of results","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#4.-Visualization-of-results","content":" 4. Visualization of results Let's start with the  fixed  effects. We see the condition effects and some residual overlap activity in the fixed effects. results = coeftable(m)\n\nres_fixef = results[isnothing.(results.group), :]\nplot_erp(res_fixef) And now comes the  random  effect: res_ranef = results[results.group .== :subject, :]\nplot_erp(res_ranef)"},{"id":276,"pagetitle":"lmmERP (mass univariate)","title":"Statistics","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#Statistics","content":" Statistics Check out the  LMM p-value tutorial"},{"id":279,"pagetitle":"lmmERP (overlap correction)","title":"Overlap Correction with Linear Mixed Models","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#lmm_overlap","content":" Overlap Correction with Linear Mixed Models using UnfoldMixedModels\n\nusing UnfoldSim\n\nusing CategoricalArrays\nusing UnfoldMakie, CairoMakie\nusing DataFrames This notebook is similar to the Linear Model with Overlap Correction tutorial, but fits  mixed  models with overlap correction Warning Limitation : This functionality is not ready for general use. There are still a lot of things to find out and tinker with. Don't use this if you haven't looked under the hood of the toolbox! Be aware of crashes / timeouts for non-trivial problems"},{"id":280,"pagetitle":"lmmERP (overlap correction)","title":"Get some data","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#Get-some-data","content":" Get some data dat, evts = UnfoldSim.predef_2x2(; signalsize=20, n_items=16, n_subjects=16)\n\n# We also need to fix the latencies, they are now relative to 1:size(data, 1), but we want a continuous long EEG.\nsubj_idx = [parse(Int, split(string(s), 'S')[2]) for s in evts.subject]\nevts.latency .+= size(dat, 1) .* (subj_idx .- 1)\n\ndat = dat[:] # we need all data concatenated over subjects\nevts.subject  = categorical(Array(evts.subject))"},{"id":281,"pagetitle":"lmmERP (overlap correction)","title":"Linear Mixed Model Continuous Time","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#Linear-**Mixed**-Model-Continuous-Time","content":" Linear  Mixed  Model Continuous Time Again we have 4 steps: Specify a temporal basisfunction Specify a formula Fit a linear model for each channel (one model for all timepoints!) Visualize the results."},{"id":282,"pagetitle":"lmmERP (overlap correction)","title":"1. Specify a temporal basisfunction","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#1.-Specify-a-temporal-basisfunction","content":" 1. Specify a temporal basisfunction By default, we would want to use a FIR basis function. basisfunction = firbasis(τ=(-0.4, .8), sfreq=20, name=\"stimulus\")"},{"id":283,"pagetitle":"lmmERP (overlap correction)","title":"2. Specify the formula","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#2.-Specify-the-formula","content":" 2. Specify the formula Define the formula and specify a random effect. Note We use  zerocorr  to prevent the model from computing all correlations between all timepoints and factors. f  = @formula 0 ~ 1 + A  *B + zerocorr(1 + A*B|subject); FormulaTerm\nResponse:\n  0\nPredictors:\n  1\n  A(unknown)\n  B(unknown)\n  A(unknown) & B(unknown)\n  (A,B,subject)->zerocorr((1 + A * B) | subject)"},{"id":284,"pagetitle":"lmmERP (overlap correction)","title":"3. Fit the model","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#3.-Fit-the-model","content":" 3. Fit the model bfDict = [Any=>(f, basisfunction)]\n# Skipping this tutorial for now due to a significant error.\nm = fit(UnfoldModel, bfDict, evts, dat)\n\nresults = coeftable(m)\nfirst(results, 6) 6×7 DataFrame Row channel coefname estimate eventname group stderror time Int64 String Float64 Union… Union… Nothing Float64 1 1 (Intercept) 0.0728554 Any -0.4 2 1 (Intercept) 0.0941947 Any -0.35 3 1 (Intercept) 0.0694752 Any -0.3 4 1 (Intercept) 0.00866136 Any -0.25 5 1 (Intercept) -0.0422579 Any -0.2 6 1 (Intercept) -0.0524441 Any -0.15"},{"id":285,"pagetitle":"lmmERP (overlap correction)","title":"4. Visualize results","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#4.-Visualize-results","content":" 4. Visualize results plot_erp(results; mapping=(; col = :group))"},{"id":288,"pagetitle":"Home","title":"UnfoldSim.jl Documentation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#UnfoldSim.jl-Documentation","content":" UnfoldSim.jl Documentation Welcome to  UnfoldSim.jl : a Julia package for simulating multivariate timeseries data with a focus on EEG, especially event-related potentials (ERPs).  The user provides four ingredients: 1) an experimental design, with both categorical and continuous variables, 2) event basis functions specified via linear or hierarchical models, 3) an inter-event onset distribution, and 4) a noise specification."},{"id":289,"pagetitle":"Home","title":"Key features","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Key-features","content":" Key features Modularity:  Choose or implement different designs, components, onset distributions or noise types Multi-subject  & complex experimental designs Multi-channel  via EEG-forward models Continuous or epoched  data with potentially  overlapping  signals Potential support for  other modalities , e.g. single-voxel fMRI or pupil dilation"},{"id":290,"pagetitle":"Home","title":"Installation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Installation","content":" Installation julia> using Pkg; Pkg.add(\"UnfoldSim\") For more detailed instructions please refer to  Installing Julia & UnfoldSim.jl ."},{"id":291,"pagetitle":"Home","title":"Usage example","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Usage-example","content":" Usage example"},{"id":292,"pagetitle":"Home","title":"Start simulating time series data","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Start-simulating-time-series-data","content":" Start simulating time series data We offer some predefined (EEG) signals, check them out! For instance, a P1/N170/P300 complex (containing three typical ERP components). using UnfoldSim\ndata, events = UnfoldSim.predef_eeg(; n_repeats = 1, noiselevel = 0.8)"},{"id":293,"pagetitle":"Home","title":"Or simulate epoched data directly","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Or-simulate-epoched-data-directly","content":" Or simulate epoched data directly data, events = UnfoldSim.predef_eeg(; n_repeats = 20, noiselevel = 0.8, return_epoched = true)"},{"id":294,"pagetitle":"Home","title":"Where to start: Learning roadmap","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Where-to-start:-Learning-roadmap","content":" Where to start: Learning roadmap"},{"id":295,"pagetitle":"Home","title":"1. First steps","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#1.-First-steps","content":" 1. First steps 📌 Goal: Learn about the simulation workflow and run your first simulation 🔗  Quickstart  |  Simulate event-related potentials (ERPs)"},{"id":296,"pagetitle":"Home","title":"2. Intermediate topics","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#2.-Intermediate-topics","content":" 2. Intermediate topics 📌 Goal: Learn about multi-subject and multi-channel simulations  🔗  Multi-subject simulation  |  Generate multi channel data"},{"id":297,"pagetitle":"Home","title":"3. Advanced topics","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#3.-Advanced-topics","content":" 3. Advanced topics 📌 Goal: Learn how to implement your own experimental designs, components, etc. 🔗  Define a new (imbalanced) design  |  Define a new component (with variable duration and shift)  |  Use existing experimental designs & onsets in the simulation"},{"id":298,"pagetitle":"Home","title":"Statement of need","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Statement-of-need","content":" Statement of need EEG researchers often analyze data containing (temporally) overlapping events (e.g. stimulus onset and button press, or consecutive eye-fixations), non-linear effects, and complex experimental designs. For a multitude of reasons, we often need to simulate such kinds of data: Simulated EEG data is useful to test preprocessing and analysis tools, validate statistical methods, illustrate conceptual issues, test toolbox functionalities, and find limitations of traditional analysis workflows. For instance, such simulation tools allow for testing the assumptions of new analysis algorithms and testing their robustness against any violation of these assumptions."},{"id":301,"pagetitle":"API / Docstrings","title":"UnfoldSim.AutoRegressiveNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.AutoRegressiveNoise","content":" UnfoldSim.AutoRegressiveNoise  —  Type AutoRegressiveNoise <: AbstractNoise Not implemented. source"},{"id":302,"pagetitle":"API / Docstrings","title":"UnfoldSim.ExponentialNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.ExponentialNoise","content":" UnfoldSim.ExponentialNoise  —  Type ExponentialNoise <: AbstractNoise Type for generating noise with exponential decay in AR spectrum. Tip: To manually create noise samples use the  simulate_noise  function. Warning With the current implementation we try to get exponential decay over the whole autoregressive (AR) spectrum, which is N samples (the total number of samples in the signal) long. This involves the inversion of a Cholesky matrix of size NxN matrix, which will need lots of RAM for non-trivial problems. Fields noiselevel = 1  (optional): Factor that is used to scale the noise. ν = 1.5  (optional): Exponential factor of AR decay \"nu\". Examples julia> noise = ExponentialNoise()\nExponentialNoise\n  noiselevel: Int64 1\n  ν: Float64 1.5\n\njulia> using StableRNGs\n\njulia> simulate_noise(StableRNG(1), noise, 5)\n5-element Vector{Float64}:\n  -5.325200748641231\n  -3.437402125380177\n   2.7852625669058884\n  -1.5381022393382109\n -14.818799857226612 See also  PinkNoise ,  RedNoise ,  NoNoise ,  WhiteNoise . source"},{"id":303,"pagetitle":"API / Docstrings","title":"UnfoldSim.Hartmut","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.Hartmut","content":" UnfoldSim.Hartmut  —  Type Hartmut <: AbstractHeadmodel Type for accessing the HArtMuT model (Harmening et al., 2022), a head model which includes not only brain sources but also muscular and ocular sources. Note: Use  Hartmut()  to create an instance of this head model. Fields artefacual::Any : Dict with artefactual sources (e.g. muscular and ocular) containing label, leadfield, orientation and position. cortical::Any :  Dict with cortical sources containing label, leadfield, orientation and position. electrodes::Any : Dict with electrode labels and their positions in 3D space. Examples julia> h = Hartmut()\nPlease cite: HArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\nHArtMuT-Headmodel\n227 electrodes:  (AF3,AF3h...) - hartmut.electrodes\n2004 source points: (Left Middle Temporal Gyrus, posterior division,...) - hartmut.cortical\n4260 source points: (Muscle_DepressorLabii_left,...) - hartmut.artefactual\n\nIn addition to UnfoldSim.jl please cite:\nHArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\n\n# Access artefactual sources\njulia> h.artefactual\nDict{String, Any} with 4 entries:\n  \"label\"       => [\"Muscle_DepressorLabii_left\", \"Muscle_DepressorLabii_left\", \"Muscle_DepressorLabii_left\", \"Muscle_DepressorLabii_left\", \"Muscle_DepressorLabii_left\", \"Muscle_DepressorLabii_left\", \"Muscle_DepressorLabii_left\", \"Mu…\n  \"leadfield\"   => [-0.00148682 -0.00229078 … -0.307231 -0.321305; 0.0141537 0.0134523 … -0.141177 -0.140583; … ; 0.108747 0.1091 … 0.106614 0.117126; 0.0257134 0.0248186 … 0.00105064 -0.00433068;;; 0.0898798 0.0891799 … 2.02466 1.81…\n  \"orientation\" => [0.54244 0.482395 -0.687789; 0.546949 0.507161 -0.666059; … ; 0.193693 -0.979684 0.0519768; 0.327641 -0.944196 -0.0338583]\n  \"pos\"         => [-29.3728 58.6061 -120.829; -28.4183 59.0185 -121.448; … ; -21.8088 70.5968 -28.7679; -21.1545 70.1282 -31.4184] source"},{"id":304,"pagetitle":"API / Docstrings","title":"UnfoldSim.LinearModelComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.LinearModelComponent","content":" UnfoldSim.LinearModelComponent  —  Type LinearModelComponent <: AbstractComponent A multiple regression component for one subject. All fields can be named. Works best with  SingleSubjectDesign . Fields basis::Any : an object, if accessed, provides a 'basis function', e.g.  hanning(40)::Vector , this defines the response at a single event. It will be weighted by the model prediction. Future versions will allow for functions, as of v0.3 this is restricted to array-like objects formula::Any : StatsModels  formula  object, e.g.   @formula 0 ~ 1 + cond  (left-hand side must be 0). β::Vector  Vector of betas/coefficients, must fit the formula. contrasts::Dict  (optional): Determines which coding scheme to use for which categorical variables. Default is empty which corresponds to dummy coding.    For more information see  https://juliastats.org/StatsModels.jl/stable/contrasts . Examples julia> LinearModelComponent(;\n           basis = hanning(40),\n           formula = @formula(0 ~ 1 + cond),\n           β = [1., 2.],\n           contrasts = Dict(:cond => EffectsCoding())\n       )\nLinearModelComponent\n  basis: Array{Float64}((40,)) [0.0, 0.006474868681043577, 0.02573177902642726, 0.0572719871733951, 0.10027861829824952, 0.1536378232452003, 0.21596762663442215, 0.28565371929847283, 0.3608912680417737, 0.43973165987233853  …  0.43973165987233853, 0.3608912680417737, 0.28565371929847283, 0.21596762663442215, 0.1536378232452003, 0.10027861829824952, 0.0572719871733951, 0.02573177902642726, 0.006474868681043577, 0.0]\n  formula: StatsModels.FormulaTerm{StatsModels.ConstantTerm{Int64}, Tuple{StatsModels.ConstantTerm{Int64}, StatsModels.Term}}\n  β: Array{Float64}((2,)) [1.0, 2.0]\n  contrasts: Dict{Symbol, EffectsCoding} See also  MixedModelComponent ,  MultichannelComponent . source"},{"id":305,"pagetitle":"API / Docstrings","title":"UnfoldSim.LogNormalOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.LogNormalOnset","content":" UnfoldSim.LogNormalOnset  —  Type LogNormalOnset <: AbstractOnset Log-normal inter-event distances (in samples) using the  Distributions.jl  truncated LogNormal distribution ( code and mathematical reference ). Be careful with large  μ  and  σ  values, as they are on logscale. σ>8 can quickly give you out-of-memory sized signals!  Tip: To manually generate inter-event distance samples use the  simulate_interonset_distances  function. Fields μ : The mean of the log-transformed variable (the log-normal random variable's logarithm follows a normal distribution). σ : The standard deviation of the log-transformed variable. offset = 0  (optional): The minimal distance between events. truncate_upper = nothing  (optional): Upper limit (in samples) at which the distribution is truncated. Examples julia> onset_distribution = LogNormalOnset(3, 0.25, 10, 25)\nLogNormalOnset\n  μ: Int64 3\n  σ: Float64 0.25\n  offset: Int64 10\n  truncate_upper: Int64 25 See also  UniformOnset ,  NoOnset . source"},{"id":306,"pagetitle":"API / Docstrings","title":"UnfoldSim.MixedModelComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.MixedModelComponent","content":" UnfoldSim.MixedModelComponent  —  Type MixedModelComponent <: AbstractComponent A component that adds a hierarchical relation between parameters according to a Linear Mixed Model (LMM) defined via  MixedModels.jl . All fields can be named. Works best with  MultiSubjectDesign . Fields basis::Any : an object, if accessed, provides a 'basis function', e.g.  hanning(40)::Vector , this defines the response at a single event. It will be weighted by the model prediction. Future versions will allow for functions, as of v0.3 this is restricted to array-like objects formula::Any : Formula-object in the style of MixedModels.jl e.g.  @formula 0 ~ 1 + cond + (1|subject) . The left-hand side is ignored. β::Vector  Vector of betas (fixed effects), must fit the formula. σs::Dict  Dict of random effect variances, e.g.  Dict(:subject => [0.5, 0.4])  or to specify correlation matrix  Dict(:subject=>[0.5,0.4,I(2,2)],...) . Technically, this will be passed to the MixedModels.jl  create_re  function, which creates the θ matrices. contrasts::Dict  (optional): Dict in the style of MixedModels.jl. Determines which coding scheme to use for which categorical variables. Default is empty which corresponds to dummy coding. For more information see  https://juliastats.org/StatsModels.jl/stable/contrasts . Examples julia> MixedModelComponent(;\n           basis = hanning(40),\n           formula = @formula(0 ~ 1 + cond + (1 + cond|subject)),\n           β = [1., 2.],\n           σs= Dict(:subject => [0.5, 0.4]),\n           contrasts=Dict(:cond => EffectsCoding())\n       )\nMixedModelComponent\n  basis: Array{Float64}((40,)) [0.0, 0.006474868681043577, 0.02573177902642726, 0.0572719871733951, 0.10027861829824952, 0.1536378232452003, 0.21596762663442215, 0.28565371929847283, 0.3608912680417737, 0.43973165987233853  …  0.43973165987233853, 0.3608912680417737, 0.28565371929847283, 0.21596762663442215, 0.1536378232452003, 0.10027861829824952, 0.0572719871733951, 0.02573177902642726, 0.006474868681043577, 0.0]\n  formula: StatsModels.FormulaTerm{StatsModels.ConstantTerm{Int64}, Tuple{StatsModels.ConstantTerm{Int64}, StatsModels.Term, StatsModels.FunctionTerm{typeof(|), Vector{StatsModels.AbstractTerm}}}}\n  β: Array{Float64}((2,)) [1.0, 2.0]\n  σs: Dict{Symbol, Vector{Float64}}\n  contrasts: Dict{Symbol, EffectsCoding} See also  LinearModelComponent ,  MultichannelComponent . source"},{"id":307,"pagetitle":"API / Docstrings","title":"UnfoldSim.MultiSubjectDesign","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.MultiSubjectDesign","content":" UnfoldSim.MultiSubjectDesign  —  Type MultiSubjectDesign <: AbstractDesign A type for specifying the experimental design for multiple subjects (based on the given random-effects structure). Tip: Check the resulting dataframe using the  generate_events  function.  Please note that the number of items  n_items  has to be a multiple of the number of between-item levels. The sample applies for  n_subjects  and the number of between-subject levels. Fields n_subjects::Int : Number of subjects. n_items::Int : Number of items/stimuli (sometimes ≈ trials). subjects_between::Dict{Symbol,Vector} : Effects between subjects, e.g. young vs old. items_between::Dict{Symbol,Vector} : Effects between items, e.g. natural vs artificial images, (but shown to all subjects if not specified also in  subjects_between ). both_within::Dict{Symbol,Vector} : Effects completely crossed i.e. conditions/covariates that are both within-subject and within-item. event_order_function = (rng, x) -> x : Can be used to sort, or shuffle the events e.g.  (rng, x) -> shuffle(rng, x)  (or shorter just  event_order_function = shuffle ).   The default is the identify function, i.e. not changing the order of the events. Examples # Declaring the same condition both between-subject and between-item results in a full between-subject/item design.\njulia> design = MultiSubjectDesign(;\n                       n_items = 10,\n                       n_subjects = 30,\n                       subjects_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n                       items_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n                       )\nMultiSubjectDesign\n  n_subjects: Int64 30\n  n_items: Int64 10\n  subjects_between: Dict{Symbol, Vector}\n  items_between: Dict{Symbol, Vector}\n  both_within: Dict{Symbol, Vector}\n  event_order_function: #3 (function of type UnfoldSim.var\"#3#7\")\n\njulia> generate_events(StableRNG(1), design)\n150×3 DataFrame\n Row │ subject  cond    item   \n     │ String   String  String \n─────┼─────────────────────────\n   1 │ S01      levelA  I01\n   2 │ S01      levelA  I03\n   3 │ S01      levelA  I05\n  ⋮  │    ⋮       ⋮       ⋮\n 148 │ S30      levelB  I06\n 149 │ S30      levelB  I08\n 150 │ S30      levelB  I10\n               144 rows omitted See also  SingleSubjectDesign ,  RepeatDesign source"},{"id":308,"pagetitle":"API / Docstrings","title":"UnfoldSim.MultichannelComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.MultichannelComponent","content":" UnfoldSim.MultichannelComponent  —  Type MultichannelComponent <: AbstractComponent Projects a  AbstractComponent  to multiple \"channels\" via the  projection  vector. Optionally,  noise  can be added to the source prior to projection. By default a  MultichannelComponent  can be constructed using one of the following options for  projection : projection::AbstractVector : Directly pass a custom projection vector. projection::Pair{<:AbstractHeadmodel,String} : Generate a projection vector by specifying which headmodel to use and which sources should be active. Fields component::AbstractComponent : The component that should be projected to the sensors. projection::AbstractVector  or  projection::Pair{<:AbstractHeadmodel,String} : Vector  p  that projects the (source) component  c[t]  (where  t  is time) to the sensors  s .   The length of  p  equals the number of sensors  s . Typically, it is a slice of the leadfield matrix.  out[s,t] = p[s]*c[t] . noise::AbstractNoise  (optional): Noise added in the source space. Default is  NoNoise . Examples # Variant 1: Specify the projection vector manually\njulia> c1 = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1), β = [1]);\n\njulia> mc1 = UnfoldSim.MultichannelComponent(c, [1, 2, -1, 3, 5, 2.3, 1])\nMultichannelComponent\n  component: LinearModelComponent\n  projection: Array{Float64}((7,)) [1.0, 2.0, -1.0, 3.0, 5.0, 2.3, 1.0]\n  noise: NoNoise NoNoise()\n\n# Variant 2: Use a headmodel and specify a source\njulia> c2 = LinearModelComponent(; basis = p300(), formula = @formula(0 ~ 1), β = [1]);\n\njulia> hart = headmodel(type = \"hartmut\");\nPlease cite: HArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\n\njulia> mc2 = UnfoldSim.MultichannelComponent(c2, hart => \"Right Occipital Pole\")\nMultichannelComponent\n  component: LinearModelComponent\n  projection: Array{Float64}((227,)) [-0.03461859471337842, -0.04321094803502425, 0.0037088347968313525, -0.014722528968861278, -0.0234889834534478, 0.02731807504242923, 0.038863688452528036, 0.1190531258070562, -0.09956890221613562, -0.0867729334438599  …  0.37435404409695094, -0.020863789022627935, 0.25627478723535513, -0.05777985212119245, 0.37104376432271147, -0.19446620423767172, 0.2590764703721097, -0.12923837607416555, 0.1732886690359311, 0.4703016561960567]\n  noise: NoNoise NoNoise() See also  LinearModelComponent ,  MixedModelComponent . source"},{"id":309,"pagetitle":"API / Docstrings","title":"UnfoldSim.NoNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.NoNoise","content":" UnfoldSim.NoNoise  —  Type NoNoise <: AbstractNoise A type for simulations without noise; return zeros instead of noise. Tip: To manually create noise samples use the  simulate_noise  function. Examples julia> noise = NoNoise()\nNoNoise()\n\njulia> using StableRNGs\n\njulia> simulate_noise(StableRNG(1), noise, 3)\n3-element Vector{Float64}:\n 0.0\n 0.0\n 0.0 See also  PinkNoise ,  RedNoise ,  ExponentialNoise ,  WhiteNoise . source"},{"id":310,"pagetitle":"API / Docstrings","title":"UnfoldSim.NoOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.NoOnset","content":" UnfoldSim.NoOnset  —  Type NoOnset <: AbstractOnset For cases where the user wants to simulate epoched data without any overlap between consecutive events. Examples julia> onset_distribution = NoOnset()\nNoOnset() See also  UniformOnset ,  LogNormalOnset . source"},{"id":311,"pagetitle":"API / Docstrings","title":"UnfoldSim.PinkNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.PinkNoise","content":" UnfoldSim.PinkNoise  —  Type PinkNoise <: AbstractNoise A type for generating Pink Noise using the  SignalAnalysis.jl  implementation. The noise values are sampled from a standard normal distribution 𝒩(μ=0, σ=1). That means that ~95% of the values are between ~-2 and ~2 (with  noiselevel = 1 ). Tip: To manually create noise samples use the  simulate_noise  function. Fields noiselevel = 1  (optional): Factor that is used to scale the noise. func = SignalAnalysis.PinkGaussian  (optional): Function that is used to create the noise samples.   This field is for internal use and should not typically be modified directly by the user.   Changes to this field may result in unexpected behavior. Examples julia> noise = PinkNoise(noiselevel = 3)\nPinkNoise\n  noiselevel: Int64 3\n  func: UnionAll\n\njulia> using StableRNGs\n\njulia> simulate_noise(StableRNG(1), noise, 5)\n5-element Vector{Float64}:\n 2.578878369756878\n 3.4972108606501786\n 2.878568584946028\n 2.2725654770788384\n 3.5291669151888683 See also  RedNoise ,  WhiteNoise ,  ExponentialNoise ,  NoNoise . source"},{"id":312,"pagetitle":"API / Docstrings","title":"UnfoldSim.RealisticNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.RealisticNoise","content":" UnfoldSim.RealisticNoise  —  Type RealisticNoise <: AbstractNoise Not implemented - planned to use Artifacts.jl to provide real EEG data to add. source"},{"id":313,"pagetitle":"API / Docstrings","title":"UnfoldSim.RedNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.RedNoise","content":" UnfoldSim.RedNoise  —  Type RedNoise <: AbstractNoise A type for generating Red Noise using the  SignalAnalysis.jl  implementation. The noise values are sampled from a standard normal distribution 𝒩(μ=0, σ=1). That means that ~95% of the values are between ~-2 and ~2 (with  noiselevel = 1 ). Tip: To manually create noise samples use the  simulate_noise  function. Fields noiselevel = 1  (optional): Factor that is used to scale the noise. func = SignalAnalysis.RedGaussian  (optional): Function that is used to create the noise samples.   This field is for internal use and should not typically be modified directly by the user.   Changes to this field may result in unexpected behavior. Examples julia> noise = RedNoise(noiselevel = 2)\nRedNoise\n  noiselevel: Int64 2\n  func: UnionAll\n\njulia> using StableRNGs\n\njulia> simulate_noise(StableRNG(2), noise, 3)\n3-element Vector{Float64}:\n -0.34153942884005967\n -0.4651387715669636\n -0.4951538876376382 See also  PinkNoise ,  WhiteNoise ,  ExponentialNoise ,  NoNoise . source"},{"id":314,"pagetitle":"API / Docstrings","title":"UnfoldSim.RepeatDesign","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.RepeatDesign","content":" UnfoldSim.RepeatDesign  —  Type RepeatDesign{T} <: AbstractDesign Repeat a design (and the corresponding events DataFrame) multiple times to mimick repeatedly recorded trials. Tip: Check the resulting dataframe using the  generate_events  function. Please note that when using an  event_order_function (e.g.  shuffle ) in a  RepeatDesign , the corresponding RNG is shared across repetitions and not deep-copied for each repetition. As a result, the order of events will differ for each repetition. Fields design::T : The experimental design that should be repeated. repeat::Int = 1 : The number of repetitions. Examples julia> using StableRNGs # For using the `generate_events` function in a reproducible way\n\njulia> design_once =\n           SingleSubjectDesign(;\n               conditions = Dict(\n                   :stimulus_type => [\"natural\", \"artificial\"],\n                   :contrast_level => range(0, 1, length = 2),\n               ),\n               event_order_function = shuffle,\n           );\n\njulia> generate_events(StableRNG(1), design_once)\n4×2 DataFrame\n Row │ contrast_level  stimulus_type \n     │ Float64         String        \n─────┼───────────────────────────────\n   1 │            1.0  natural\n   2 │            1.0  artificial\n   3 │            0.0  natural\n   4 │            0.0  artificial\n\njulia> design = RepeatDesign(design_once, 2)\nRepeatDesign{SingleSubjectDesign}\n  design: SingleSubjectDesign\n  repeat: Int64 2\n\njulia> generate_events(StableRNG(1), design)\n8×2 DataFrame\n Row │ contrast_level  stimulus_type \n     │ Float64         String        \n─────┼───────────────────────────────\n   1 │            1.0  natural\n   2 │            1.0  artificial\n   3 │            0.0  natural\n   4 │            0.0  artificial\n   5 │            1.0  artificial\n   6 │            0.0  natural\n   7 │            1.0  natural\n   8 │            0.0  artificial See also  SingleSubjectDesign ,  MultiSubjectDesign source"},{"id":315,"pagetitle":"API / Docstrings","title":"UnfoldSim.Simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.Simulation","content":" UnfoldSim.Simulation  —  Type Simulation A type to store all \"ingredients\" for a simulation including their parameters. Can either be created by the user or will be created automatically when calling the  simulate  function with the required \"ingredients\". Tip: Use the  subtypes  function to get an overview of the implemented \"ingredients\", e.g.  subtypes(AbstractDesign) . Fields design::AbstractDesign : Experimental design. components::Vector{AbstractComponent} : Response function(s) for the events (e.g. the ERP shape in EEG). onset::AbstractOnset : Inter-onset distance distribution. noisetype::AbstractNoise : Noise type. Examples julia> design = SingleSubjectDesign(; conditions = Dict(:stimulus_type => [\"natural\", \"artificial\"]));\n\njulia> component = LinearModelComponent(;\n           basis = p100(),\n           formula = @formula(0 ~ 1 + stimulus_type),\n           β = [2, 3],\n       );\n\njulia> onset = UniformOnset();\n\njulia> noise = PinkNoise();\n\njulia> simulation = Simulation(design, component, onset, noise);\n\njulia> using StableRNGs\n\njulia> data, events = simulate(StableRNG(1), simulation);\n\njulia> events\n2×2 DataFrame\n Row │ stimulus_type  latency \n     │ String         Int64   \n─────┼────────────────────────\n   1 │ natural             20\n   2 │ artificial          70\n\njulia> data\n85-element Vector{Float64}:\n  0.8596261232522926\n  1.1657369535500595\n  0.9595228616486761\n  ⋮\n  0.9925202143746904\n  0.2390652543395527\n -0.11672523788068771 source"},{"id":316,"pagetitle":"API / Docstrings","title":"UnfoldSim.SingleSubjectDesign","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.SingleSubjectDesign","content":" UnfoldSim.SingleSubjectDesign  —  Type SingleSubjectDesign <: AbstractDesign A type for specifying the experimental design for a single subject (based on the given conditions). Tip: Check the resulting dataframe using the  generate_events  function.  The number of trials/rows in the output of  generate_events([rng, ]design)  depends on the full factorial of your  conditions .  To increase the number of repetitions, e.g. by 5, simply use  RepeatDesign(SingleSubjectDesign(...), 5) .  If conditions are omitted (or set to  nothing ), a single trial is simulated with a column  :dummy  and content  :dummy  - this is for convenience. Fields conditions::Dict{Symbol,Vector} : Experimental conditions, e.g.  Dict(:A => [\"a_small\",\"a_big\"], :B => [\"b_tiny\",\"b_large\"]) . event_order_function = (rng, x) -> x : Can be used to sort by specifying  sort , or shuffling by providing  shuffle , or custom functions following the interface  (rng, x) -> my_shuffle(rng,x) .   The default is the identify function, i.e. not changing the order of the events. Examples julia> using StableRNGs # For using the `generate_events` function in a reproducible way\n\njulia> design =\n           SingleSubjectDesign(;\n               conditions = Dict(\n                   :stimulus_type => [\"natural\", \"artificial\"],\n                   :contrast_level => range(0, 1, length = 5),\n               ),\n           )\nSingleSubjectDesign\n  conditions: Dict{Symbol, Vector}\n  event_order_function: #10 (function of type UnfoldSim.var\"#10#14\")\n\njulia> generate_events(StableRNG(1), design)\n10×2 DataFrame\n Row │ contrast_level  stimulus_type \n     │ Float64         String        \n─────┼───────────────────────────────\n   1 │           0.0   natural\n   2 │           0.25  natural\n   3 │           0.5   natural\n  ⋮  │       ⋮               ⋮\n   8 │           0.5   artificial\n   9 │           0.75  artificial\n  10 │           1.0   artificial\n                       4 rows omitted See also  MultiSubjectDesign ,  RepeatDesign source"},{"id":317,"pagetitle":"API / Docstrings","title":"UnfoldSim.UniformOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.UniformOnset","content":" UnfoldSim.UniformOnset  —  Type UniformOnset <: AbstractOnset Provide a Uniform Distribution for the inter-event distances (in samples). Tip: To manually generate inter-event distance samples use the  simulate_interonset_distances  function. Fields width = 50  (optional): Width of the uniform distribution (=> the \"jitter\"). Since the lower bound is 0,  width  is also the upper bound. offset = 0  (optional): The minimal distance between events. The maximal distance is  offset + width . Examples julia> onset_distribution = UniformOnset(width = 25, offset = 5)\nUniformOnset\n  width: Int64 25\n  offset: Int64 5 See also  LogNormalOnset ,  NoOnset . source"},{"id":318,"pagetitle":"API / Docstrings","title":"UnfoldSim.WhiteNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.WhiteNoise","content":" UnfoldSim.WhiteNoise  —  Type WhiteNoise <: AbstractNoise A type for generating White Noise using  randn  - thus Gaussian noise. The noise values are sampled from a standard normal distribution 𝒩(μ=0, σ=1). That means that ~95% of the values are between ~-2 and ~2 (with  noiselevel = 1 ). Tip: To manually create noise samples use the  simulate_noise  function. Fields noiselevel = 1  (optional): Factor that is used to scale the noise. imfilter = nothing  (optional): Use  imfilter > 0  to smooth the noise using  Image.imfilter  with a Gaussian kernel with  σ = imfilter . Examples julia> noise = WhiteNoise()\nWhiteNoise\n  noiselevel: Int64 1\n  imfilter: Nothing nothing\n\njulia> using StableRNGs\n\njulia> simulate_noise(StableRNG(1), noise, 3)\n3-element Vector{Float64}:\n -0.5325200748641231\n  0.098465514284785\n  0.7528865221245234 See also  PinkNoise ,  RedNoise ,  ExponentialNoise ,  NoNoise . source"},{"id":319,"pagetitle":"API / Docstrings","title":"Base.length","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#Base.length-Tuple{AbstractDesign}","content":" Base.length  —  Method Length is the product of all dimensions and equals the number of events in the corresponding events dataframe. source"},{"id":320,"pagetitle":"API / Docstrings","title":"Base.size","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#Base.size-Tuple{MultiSubjectDesign}","content":" Base.size  —  Method Return the dimensions of the experiment design. source"},{"id":321,"pagetitle":"API / Docstrings","title":"DSP.Windows.hanning","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#DSP.Windows.hanning-Tuple{Any, Any, Any}","content":" DSP.Windows.hanning  —  Method hanning(duration, offset, sfreq) Generate a (potentially shifted) hanning window with a certain duration.  Note: This function extends the  DSP.hanning  function using multiple dispatch. Arguments duration : in s. offset : in s, defines hanning peak i.e. shift of the hanning window. sfreq : Sampling rate in Hz. Returns Vector : Contains a shifted (i.e. zero-padded) hanning window. Examples julia> UnfoldSim.hanning(0.1, 0.3, 100)\n25-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n ⋮\n 0.9698463103929542\n 0.75\n 0.41317591116653485\n 0.11697777844051105\n 0.0 source"},{"id":322,"pagetitle":"API / Docstrings","title":"UnfoldSim.PuRF","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.PuRF-Tuple{}","content":" UnfoldSim.PuRF  —  Method PuRF(; n = 10.1, tmax = 0.93, sfreq = 100) Default generator for PuRF Pupil Response Function. The canonical PRF is a gamma function and implemented according to Denison 2020 equation (2) going back to Hoeks & Levelt, 1993. The pupil response is evaluated at t = 0:1/sfreq:3*tmax. The response is normalized by the peak-maximum at tmax, thus typically a pupil-response of 1 is returned (disregarding numerical issues). Keyword arguments: n = 10.1 : shape parameter tmax = 0.93 : peak maximum sfreq = 100 : sampling frequency Returns Vector : canonical pupil response with length(0:1/sfreq:3*tmax) entries. Examples julia> PuRF(; n = 5)\n280-element Vector{Float64}:\n 0.0\n 2.0216617815131253e-8\n 6.130689396024061e-7\n 4.4118063684811444e-6\n 1.761817666835793e-5\n ⋮\n 0.012726253506722554\n 0.012280989091455786\n 0.011850525657416842\n 0.011434405338911133\n 0.011032182932283816 source"},{"id":323,"pagetitle":"API / Docstrings","title":"UnfoldSim.add_noise!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.add_noise!-Tuple{Any, AbstractNoise, Any}","content":" UnfoldSim.add_noise!  —  Method add_noise!(rng, noisetype::AbstractNoise, signal) Generate and add noise to a signal. Assumes that the signal can be linearized, that is, that the noise is stationary. source"},{"id":324,"pagetitle":"API / Docstrings","title":"UnfoldSim.add_responses!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.add_responses!-Tuple{Any, Vector, Vararg{Any, 4}}","content":" UnfoldSim.add_responses!  —  Method add_responses!(signal, responses::Vector, e, s, tvec, trial_idx)\nadd_responses!(signal, responses::Matrix, e, s, tvec, trial_idx)\nadd_responses!(signal, responses::AbstractArray, e, s, tvec, trial_idx) Add (in-place) the given  responses  to the  signal , for both 2D (1 channel) and 3D (X channel case). Helper function. Arguments signal : Continuous EEG signal to be modified in place. Has the dimensions  channels x continuous_time x subjects . responses::Union{Vector, Matrix, AbstractArray} : Responses to be added. In the multi-channel case, the dimensions are  channels x maxlength(components) x length(simulation.design) , else  maxlength(components) x length(simulation.design) .  The data for all the subjects and their respective trials is concatenated. e : Index of the channel (in  signal ) for which to add the response. s : Index of the subject (in  signal ) for which to add the response. tvec : Time points (indices in  signal ) at which to add the response. trial_idx : Index of the particular trial (in  responses ) from where the response is to be added. Returns Nothing :  signal  is modified in-place. Examples julia> signal, responses, tvec = zeros(5,15,2), ones(5,6), 1:5;\n\njulia> UnfoldSim.add_responses!(signal, responses, 1, 2, tvec, 5);\n\njulia> signal\n5×15×2 Array{Float64, 3}:\n[:, :, 1] =\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n\n[:, :, 2] =\n 1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 source"},{"id":325,"pagetitle":"API / Docstrings","title":"UnfoldSim.apply_event_order_function","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.apply_event_order_function-Tuple{Any, Any, Any}","content":" UnfoldSim.apply_event_order_function  —  Method apply_event_order_function(fun, rng, events) Apply  fun(rng, events) , raise an error if function  fun  is wrongly defined. Convenience function to not repeat the error handling at multiple places. source"},{"id":326,"pagetitle":"API / Docstrings","title":"UnfoldSim.closest_src","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.closest_src-Tuple{AbstractVector{<:AbstractVector}, Any}","content":" UnfoldSim.closest_src  —  Method closest_src(coords_list::AbstractVector{<:AbstractVector}, pos) When applied to a vector of target coordinate vectors, return the index of the closest position in  pos  for each of the targets.  Returns Vector : Index of the closest position in  pos  for each vector in  coords_list . Examples julia> positions = [0 0 0; 2 2 2; 3 3 3; 4 4 4];\njulia> target_coordinate_vectors = [[0.5, 0, 0.5], [10, 1, 8]];\n\njulia> UnfoldSim.closest_src(target_coordinate_vectors, positions)\n2-element Vector{Int64}:\n 1\n 4 source"},{"id":327,"pagetitle":"API / Docstrings","title":"UnfoldSim.closest_src","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.closest_src-Tuple{Hartmut, String}","content":" UnfoldSim.closest_src  —  Method closest_src(head::Hartmut, label::String) Return the index of the Harmut model source point that is closest (using Euclidean distance) to the mean position of the source points matching the given  label . Important We use the average in Euclidean space, but the cortex is a curved surface. In most cases they will not overlap. Ideally we would calculate the average on the surface, but this is a bit more complex to do (you'd need to calculate the vertices etc.). Arguments head::Hartmut : Headmodel of type  Hartmut . label::String : Label of the source point(s) of interest. Returns Int : Index of the closest Hartmut source point. Examples julia> hartmut = Hartmut();\nPlease cite: HArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\n\njulia> label = \"Right Cingulate Gyrus, posterior division\";\n\njulia> UnfoldSim.closest_src(hartmut, label)\n1875 source"},{"id":328,"pagetitle":"API / Docstrings","title":"UnfoldSim.closest_src","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.closest_src-Tuple{Vector{<:Real}, Any}","content":" UnfoldSim.closest_src  —  Method closest_src(coords::Vector{<:Real}, pos) Return the index of the position that is closest to the target coordinates (using the Euclidean distance). Arguments coords::Vector{<:Real} : Target coordinate vector (typically with length 3). pos : Matrix that contains all possible positions.   Its dimensions are the number of positions  n  times number of entries in the position coordinate vectors (usually 3) i.e.  n x 3 . Returns Int : Row index of the position in  pos  that is closest to  coords . Examples julia> positions = [0 0 0; 2 2 2; 3 3 3; 4 4 4]\n4×3 Matrix{Int64}:\n 0  0  0\n 2  2  2\n 3  3  3\n 4  4  4\n\njulia> target_coordinates = [0.5, 0, 0.5]\n3-element Vector{Float64}:\n 0.5\n 0.0\n 0.5\n\n julia> UnfoldSim.closest_src(target_coordinates, positions)\n1 source"},{"id":329,"pagetitle":"API / Docstrings","title":"UnfoldSim.create_continuous_signal","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.create_continuous_signal-Tuple{Any, Any, Any}","content":" UnfoldSim.create_continuous_signal  —  Method create_continuous_signal(rng, responses, simulation) Simulate onset latencies and add together a continuous signal, based on the given responses and simulation parameters. Helper function. Arguments rng : Random number generator, important to ensure reproducibility. responses : Responses to be combined with the given onsets. simulation : Simulation parameters, including design, components, onsets, and noisetype. Returns (signal, latencies)::Tuple{Array, Array} : signal  contains the generated signal. Has the dimensions  channels x continuous_time x subjects . latencies  contains the onset latencies. Examples julia> using StableRNGs # to get an RNG\n\njulia> design = SingleSubjectDesign(; conditions = Dict(:cond => [\"natural\", \"artificial\"]));\n\njulia> c1 = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1 + cond), β = [1, 0.5]);\n\njulia> c2 = LinearModelComponent(; basis = p300(), formula = @formula(0 ~ 1), β = [2]);\n\njulia> simulation = Simulation(design, [c1, c2], UniformOnset(; width = 0, offset = 30), PinkNoise());\n\njulia> responses = simulate_responses(StableRNG(1), [c1, c2], simulation)\n45×2 Matrix{Float64}:\n 0.0        0.0\n 0.0        0.0\n ⋮          \n 0.0233794  0.0233794\n 0.0        0.0\n\njulia> signal, latencies = UnfoldSim.create_continuous_signal(StableRNG(1), responses, simulation);\n\njulia> signal\n106-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n ⋮\n 0.023379444289913343\n 0.0\n 0.0\n\n julia> latencies\n2-element Vector{Int64}:\n 31\n 61 source"},{"id":330,"pagetitle":"API / Docstrings","title":"UnfoldSim.epoch","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.epoch-Tuple{AbstractVector, Vararg{Any}}","content":" UnfoldSim.epoch  —  Method epoch(data::AbstractVector, args...; kwargs...) One channel case. The data is reshaped and then passed to the multi-channel epoch method. source"},{"id":331,"pagetitle":"API / Docstrings","title":"UnfoldSim.epoch","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.epoch-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Any, Tuple{Number, Number}, Any}} where T<:Union{Missing, Number}","content":" UnfoldSim.epoch  —  Method epoch(\n    data::AbstractArray{T,2},\n    events,\n    τ::Tuple{Number,Number},\n    sfreq;\n    eventtime::Symbol = :latency,\n) where {T<:Union{Missing,Number}} Helper function to segment continuous  data  into epochs based on the given  events  and the time window  τ . Adapted from Unfold.jl: https://github.com/unfoldtoolbox/Unfold.jl/blob/b3  a21c2bb7e93d2f45ec64b0197f4663a6d7939a/src/utilities.jl#L40 Arguments data::AbstractArray{T,2} : Continuous data with the dimensions  channels x continuous_time . events : Events data frame (based on the design) with latencies. τ::Tuple{Number,Number} : Time window for epoching in s. sfreq : Sampling frequency in Hz. Keyword arguments eventtime::Symbol = :latency : The name of the column in  events  that contains the latencies. Returns Array : Epoched data with the dimensions  channels x times x event  (or  times x event  for the single channel case). Examples # One channel example\njulia> data, events = UnfoldSim.predef_eeg();\n\njulia> size(data), size(events)\n((120199,), (2000, 3))\n\njulia> UnfoldSim.epoch(data, events, (-0.2, 1), 100)\n121×2000 Matrix{Float64}:\n  0.114127   -0.105347     …  -0.125485   1.6383\n  0.128198    0.0474874        0.0112935  1.28122\n  0.0547917  -0.0832977       -0.126181   0.850062\n  0.0992842  -0.230224        -0.0449072  0.496583\n  0.024461   -0.175023        -0.0223837  0.170389\n  0.165133   -0.000793527  …  -0.0278197  0.104454\n  ⋮                        ⋱              \n -0.362249    2.91297          0.546699   0.0\n -0.199265    2.58394          0.171159   0.0\n -0.184075    2.34611         -0.0269841  0.0\n -0.13901     2.11971         -0.0552873  0.0\n -0.0674085   1.74561      …  -0.187959   0.0 source"},{"id":332,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events","content":" UnfoldSim.generate_events  —  Function generate_events(design::AbstractDesign)\ngenerate_events(rng::AbstractRNG, design::AbstractDesign) Generate a full-factorial events DataFrame based on the experimental conditions and covariates defined in the design. Arguments design::AbstractDesign : Experimental design for which the events DataFrame should be created. rng::AbstractRNG  (optional): Random number generator (RNG) to make the process reproducible. If none is given,  MersenneTwister(1)  will be used. Returns DataFrame : Each row corresponds to one combination of condition/covariate levels which is often equivalent to one stimulus or trial. source"},{"id":333,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events-Tuple{Random.AbstractRNG, MultiSubjectDesign}","content":" UnfoldSim.generate_events  —  Method generate_events(design::MultiSubjectDesign)\ngenerate_events(rng::AbstractRNG, design::MultiSubjectDesign) Generate the events Dataframe according to  MixedModelsSim.jl 's  simdat_crossed  function. Afterwards apply  design.event_order_function  and finally sort by  :subject .  Note: No condition can be named  dv  which is used internally in MixedModelsSim / MixedModels as a dummy left-side Examples julia> using Random # for shuffling\njulia> using StableRNGs\n\njulia> design = MultiSubjectDesign(;\n                       n_items = 4,\n                       n_subjects = 5,\n                       both_within = Dict(:condition => [\"red\", \"green\"]),\n                       event_order_function = shuffle,\n                       );\n\njulia> generate_events(StableRNG(1), design)\n40×3 DataFrame\n Row │ subject  item    condition \n     │ String   String  String    \n─────┼────────────────────────────\n   1 │ S1       I2      red\n   2 │ S1       I2      green\n   3 │ S1       I3      green\n  ⋮  │    ⋮       ⋮         ⋮\n  38 │ S5       I3      red\n  39 │ S5       I2      red\n  40 │ S5       I4      green\n                   34 rows omitted source"},{"id":334,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events-Tuple{Random.AbstractRNG, RepeatDesign}","content":" UnfoldSim.generate_events  —  Method UnfoldSim.generate_events([rng::AbstractRNG, ]design::RepeatDesign{T}) For a  RepeatDesign , iteratively call  generate_events  for the underlying {T} design and concatenate the results. In case of  MultiSubjectDesign , sort by subject.  Please note that when using an  event_order_function (e.g.  shuffle ) in a  RepeatDesign , the corresponding RNG is shared across repetitions and not deep-copied for each repetition. As a result, the order of events will differ for each repetition. source"},{"id":335,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events-Tuple{Random.AbstractRNG, SingleSubjectDesign}","content":" UnfoldSim.generate_events  —  Method generate_events(design::SingleSubjectDesign)\ngenerate_events(rng::AbstractRNG, design::SingleSubjectDesign) Generate the events DataFrame based on  design.conditions  and afterwards apply  design.event_order_function . If  design.conditions  is  nothing , a single trial is simulated with a column  :dummy  and content  :dummy  - this is for convenience. Examples julia> using Random # for shuffling\njulia> using StableRNGs\n\njulia> design = SingleSubjectDesign(;\n           conditions = Dict(:A => [\"small\", \"large\"], :B => range(1, 5, length = 3)),\n           event_order_function = shuffle,\n       );\n\n# Variant 1: Without specifying an RNG, MersenneTwister(1) will be used for the shuffling specified as `event_order_function`.\njulia> generate_events(design)\n6×2 DataFrame\n Row │ A       B       \n     │ String  Float64 \n─────┼─────────────────\n   1 │ large       5.0\n   2 │ large       1.0\n   3 │ large       3.0\n   4 │ small       1.0\n   5 │ small       3.0\n   6 │ small       5.0\n\n# Variant 2: Use a custom RNG.\njulia> generate_events(StableRNG(1), design)\n6×2 DataFrame\n Row │ A       B       \n     │ String  Float64 \n─────┼─────────────────\n   1 │ large       5.0\n   2 │ large       3.0\n   3 │ small       1.0\n   4 │ small       3.0\n   5 │ large       1.0\n   6 │ small       5.0 source"},{"id":336,"pagetitle":"API / Docstrings","title":"UnfoldSim.hartmut_citation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.hartmut_citation-Tuple{}","content":" UnfoldSim.hartmut_citation  —  Method Return the citation string for HArtMuT. source"},{"id":337,"pagetitle":"API / Docstrings","title":"UnfoldSim.hrf","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.hrf-Tuple{}","content":" UnfoldSim.hrf  —  Method hrf(;\nTR = 1,\npeak = 6.0,\npost_undershoot = 16,\nlength = 32.0,\npeak_width = 1.0,\npost_undershoot_width = 1,\namplitude = 6,\nshift = 0) Generate a parameterized BOLD haemodynamic response function (HRF) kernel based on gamma-functions. Implementation and default parameters were taken from the SPM-toolbox. Note: TR = 1/sfreq Keyword arguments TR = 1 : repetition time, 1/sfreq. length = 32.0 : total length of the kernel in seconds. amplitude = 6 : maximal amplitude. peak = 6.0 : peak timing. peak_width = 1.0 : width of the peak. post_undershoot = 16 : post-undershoot timing. post_undershoot_width = 1 : post-undershoot width. shift = 0 : shift the whole HRF. Returns Vector : HRF BOLD response. Examples julia> hrf()\n33-element Vector{Float64}:\n  0.0\n  0.0007715994433635659\n  0.019784004131204957\n  0.08202939459091822\n  0.158157713522699\n  ⋮\n -0.0006784790038792572\n -0.00042675060451877775\n -0.000263494738348278\n -0.00015990722628360688\n -9.548780093799345e-5 source"},{"id":338,"pagetitle":"API / Docstrings","title":"UnfoldSim.leadfield","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.leadfield-Tuple{Hartmut}","content":" UnfoldSim.leadfield  —  Method leadfield(hart::Hartmut; type = \"cortical\") Return the leadfield for the (cortical or artefacual) sources of the HArtMuT model. Keyword arguments type = \"cortical\" : Defines whether the \"cortical\" or \"artefactual\" leadfield should be returned. Returns Array{Float64, 3} : Leadfield values i.e. how much each source contributes to the potential measured at each electrode.   The output dimensions are  electrodes x sources x spatial dimension . Examples julia> h = Hartmut();\nPlease cite: HArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\n\njulia> lf = leadfield(h);\n\njulia> size(lf)\n(227, 2004, 3)\n\n# Access the leadfield for one spatial dimension\njulia> lf[:,:,1]\n227×2004 Matrix{Float64}:\n  0.151429    0.0284341  …  -0.119927     -0.158114\n  0.1732      0.0441432     -0.110515     -0.165316\n  0.249592    0.10857       -0.000593027  -0.0206122\n  0.245206    0.104854      -0.0200251    -0.055392\n  0.126496    0.0118467     -0.128248     -0.146107\n  0.253092    0.111688   …   0.02277       0.0184387\n  ⋮                      ⋱                \n  0.20306     0.138837       0.133486      0.18334\n -0.689154   -1.00904       -0.108276     -0.105398\n  0.192729    0.148448       0.0924756     0.142322\n -1.26181    -1.59936       -0.140598     -0.133054\n  0.213982    0.145953   …   0.115515      0.170698\n  0.0731569   0.0794415      0.0485819     0.107929 source"},{"id":339,"pagetitle":"API / Docstrings","title":"UnfoldSim.magnitude","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.magnitude-Tuple{AbstractHeadmodel}","content":" UnfoldSim.magnitude  —  Method magnitude(headmodel::AbstractHeadmodel) Return the magnitude for the given  headmodel  based on the leadfield (and potentially the source orientations) specified in the  headmodel . If the  headmodel  includes source orientations these are used in the calculations, otherwise the  leadfield  is returned assuming that the source orientations are already included. Please note that (at least in the case of the HArtMuT model) the leadfield for the cortical sources is used. Returns Matrix{Float64} : Contribution of each source to the potential measured at each electrode taking into account the orientation of the sources.   The output dimensions are  electrodes x sources . Examples # Using the HArtMut model as an example\njulia> h = Hartmut();\nPlease cite: HArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\n\njulia> magnitude(h)\n227×2004 Matrix{Float64}:\n  0.111706   …   0.301065\n  0.0774359      0.332934\n  ⋮          ⋱  \n -0.164539      -0.246555 source"},{"id":340,"pagetitle":"API / Docstrings","title":"UnfoldSim.magnitude","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.magnitude-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractMatrix{T}}} where T<:Real","content":" UnfoldSim.magnitude  —  Method magnitude(lf::AbstractArray{T,3}, orientation::AbstractArray{T,2}) where {T<:Real} Return the magnitude of the leadfield  lf  along the given  orientation . Arguments lf::AbstractArray{T,3} : Leadfield with the dimensions  electrodes x sources x spatial dimension . orientation::AbstractArray{T,2} : Source orientations with the dimensions  sources x spatial dimensions . Examples # Specify the leadfield (often given by a headmodel)\njulia> lf = cat([1 0; 0 1; 0 0], [1 1; 0 0; 0.5 0.5], dims=3);\n\n# Specify the source orientations\njulia> ori = [1.0 0; 0 1]\n\n# Calculate the magnitude\njulia> magnitude(lf, ori)\n3×2 Matrix{Float64}:\n 1.0  1.0\n 0.0  0.0\n 0.0  0.5 source"},{"id":341,"pagetitle":"API / Docstrings","title":"UnfoldSim.maxlength","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.maxlength-Tuple{Vector{<:AbstractComponent}}","content":" UnfoldSim.maxlength  —  Method maxlength(c::Vector{<:AbstractComponent}) = maximum(length.(c)) Return the maximum of the individual components' lengths. source"},{"id":342,"pagetitle":"API / Docstrings","title":"UnfoldSim.n170","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n170-Tuple{}","content":" UnfoldSim.n170  —  Method n170(; sfreq = 100) Generate a Hanning window mimicking an N170 EEG component with a negative (!) peak at 170ms and a width of 150ms. Keyword arguments sfreq = 100 : Sampling frequency in Hz. Returns Vector : Contains a shifted (i.e. zero-padded) hanning window. Examples julia> n170(; sfreq = 120)\n28-element Vector{Float64}:\n -0.0\n -0.0\n -0.0\n -0.0\n -0.0\n  ⋮\n -0.45386582026834904\n -0.2771308221117309\n -0.1304955413896705\n -0.03376388529782215\n -0.0 See also  p100 ,  p300 ,  n400 ,  hanning . source"},{"id":343,"pagetitle":"API / Docstrings","title":"UnfoldSim.n400","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n400-Tuple{}","content":" UnfoldSim.n400  —  Method n400(; sfreq = 100) Generate a Hanning window mimicking an N400 EEG component with a negative (!) peak at 400ms and a width of 400ms. Keyword arguments sfreq = 100 : Sampling frequency in Hz. Returns Vector : Contains a shifted (i.e. zero-padded) hanning window. Examples julia> n400(; sfreq = 250)\n150-element Vector{Float64}:\n -0.0\n -0.0\n -0.0\n -0.0\n -0.0\n  ⋮\n -0.016025649301821876\n -0.009035651368646647\n -0.00402259358460233\n -0.0010066617640578368\n -0.0 See also  p100 ,  p300 ,  n170 ,  hanning . source"},{"id":344,"pagetitle":"API / Docstrings","title":"UnfoldSim.n_channels","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n_channels-Tuple{AbstractComponent}","content":" UnfoldSim.n_channels  —  Method n_channels(c::AbstractComponent) Return the number of channels for the given component  c . By default = 1. source"},{"id":345,"pagetitle":"API / Docstrings","title":"UnfoldSim.n_channels","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n_channels-Tuple{MultichannelComponent}","content":" UnfoldSim.n_channels  —  Method n_channels(c::MultichannelComponent) For  MultichannelComponent  return the length of the projection vector. source"},{"id":346,"pagetitle":"API / Docstrings","title":"UnfoldSim.n_channels","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n_channels-Tuple{Vector{<:AbstractComponent}}","content":" UnfoldSim.n_channels  —  Method n_channels(c::Vector{<:AbstractComponent}) For a vector of  MultichannelComponent s, return the number of channels for the first component but assert all are of equal length. source"},{"id":347,"pagetitle":"API / Docstrings","title":"UnfoldSim.orientation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.orientation-Tuple{Hartmut}","content":" UnfoldSim.orientation  —  Method orientation(hart::Hartmut; type = \"cortical\") Return the orientations of the (cortical or artefacual) sources of the HArtMuT model.  The norm of the orientation vectors is 1 and the values are between -1 and 1. Keyword arguments type = \"cortical\" : Defines whether the \"cortical\" or \"artefactual\" orientations should be returned. Returns Matrix{Float64} : Orientations in 3D space. The output dimensions are  sources x spatial dimensions . Examples julia> h = Hartmut();\nPlease cite: HArtMuT: Harmening Nils, Klug Marius, Gramann Klaus and Miklody Daniel - 10.1088/1741-2552/aca8ce\n\njulia> orientation(h)\n2004×3 Matrix{Float64}:\n -0.921919   0.364292   0.131744\n -0.900757  -0.415843  -0.125345\n -0.954087   0.117479  -0.27553\n -0.814613  -0.55344    0.17352\n -0.790526   0.276849  -0.546281\n  ⋮                    \n -0.962905   0.20498   -0.17549\n -0.828358   0.557468  -0.0552498\n -0.963785  -0.265607  -0.0239074\n -0.953909   0.203615   0.22045\n -0.75762    0.128027   0.640016 source"},{"id":348,"pagetitle":"API / Docstrings","title":"UnfoldSim.p100","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.p100-Tuple{}","content":" UnfoldSim.p100  —  Method p100(; sfreq = 100) Generate a Hanning window mimicking a P100 EEG component with a peak at 100ms and a width of 100ms. Keyword arguments sfreq = 100 : Sampling frequency in Hz. Returns Vector : Contains a shifted (i.e. zero-padded) hanning window. Examples julia> p100(; sfreq = 200)\n30-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n ⋮\n 0.37725725642960045\n 0.22652592093878665\n 0.10542974530180327\n 0.02709137914968268\n 0.0 See also  p300 ,  n170 ,  n400 ,  hanning . source"},{"id":349,"pagetitle":"API / Docstrings","title":"UnfoldSim.p300","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.p300-Tuple{}","content":" UnfoldSim.p300  —  Method p300(; sfreq = 100) Generate a Hanning window mimicking a P300 EEG component with a peak at 300ms and a width of 300ms. Keyword arguments sfreq = 100 : Sampling frequency in Hz. Returns Vector : Contains a shifted (i.e. zero-padded) hanning window. Examples julia> p300(; sfreq = 150)\n67-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n ⋮\n 0.07937323358440934\n 0.04518400232274078\n 0.02025351319275137\n 0.005089279059533658\n 0.0 See also  p100 ,  n170 ,  n400 ,  hanning . source"},{"id":350,"pagetitle":"API / Docstrings","title":"UnfoldSim.pad_array","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.pad_array-Tuple{Vector, Tuple, Any}","content":" UnfoldSim.pad_array  —  Method pad_array(arr::Vector, len::Int, val)    \npad_array(arr::Vector, len::Tuple, val) Pads the input array  arr  with a specified value  val  either before or after the existing elements, based on the sign of  len . Arguments arr::Vector : The input array to be padded. len::Union{Int, Tuple} : The number of times that  val  should be added.   If  len  is negative, the values are added before the existing array. Otherwise, they are added after the existing array.   If  len  is a tuple,  pad_array  is called twice which enables padding the array before and after in one function call. val : The value to be used for padding. Returns Vector : Padded vector with the new length  length(arr) + sum(abs.(len)) . Examples # Create an array that will be padded\njulia> my_array = rand(5)\n5-element Vector{Float64}:\n 0.0420017254437951\n 0.19179144973603235\n 0.5388760239550549\n 0.6973699906283798\n 0.9966598131018376\n\n # Pad the array with zeros before the original array\njulia> pad_array(my_array, -2, 0)\n7-element Vector{Float64}:\n 0.0\n 0.0\n 0.0420017254437951\n 0.19179144973603235\n 0.5388760239550549\n 0.6973699906283798\n 0.9966598131018376\n\n# Pad the array with the value 5 before and after the original array\njulia> pad_array(my_array, (-2, 1), 5)\n8-element Vector{Float64}:\n 5.0\n 5.0\n 0.0420017254437951\n 0.19179144973603235\n 0.5388760239550549\n 0.6973699906283798\n 0.9966598131018376\n 5.0 source"},{"id":351,"pagetitle":"API / Docstrings","title":"UnfoldSim.predef_2x2","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.predef_2x2-Tuple{Random.AbstractRNG}","content":" UnfoldSim.predef_2x2  —  Method predef_2x2(rng::AbstractRNG; <keyword arguments>) Simulate data for a 2x2 design i.e. a design with two conditions with two levels each. Note that this function is mainly used for demonstration and internal testing purposes or whenever a quick simulation is needed.  The most used keyword argument is:  return_epoched = true  which returns already epoched data. If you want epoched data without overlap, specify  onset = NoOnset()  and  return_epoched = true .  Be careful if you modify  n_items  with  n_subjects = 1 ,  n_items  has to be a multiple of 4 (or your equivalent conditions factorial, e.g. all combinations length). In difference to  predef_EEG ,  predef_2x2  is sample based (no sampling rate to be specified), and also has a 2x2 design, instead of a 2-categorical, 1-continuous design. Keyword arguments Design n_items = 100 : Number of items. n_subjects = 1 : Number of subjects. conditions = Dict(:A => [\"a_small\",\"a_big\"], :B => [\"b_tiny\",\"b_large\"]) : Experimental conditions with their levels. event_order_function = shuffle : Random trial order. Component / Signal signalsize = 100 : Length of simulated hanning window. basis = hanning(signalsize) : The actual \"function\".  signalsize  is only used here. β = [1, -0.5, .5, +1] : The parameters for the fixed effects. σs = Dict(:subject => [1, 0.5, 0.5, 0.5],:item => [1]) : Only needed in n_subjects >= 2 cases; specifies the random effects. contrasts = Dict(:A => EffectsCoding(), :B => EffectsCoding()) : Effect coding by default. formula = n_subjects == 1 ? @formula(0 ~ 1 + A*B) : @formula(dv ~ 1 + A*B + (A*B|subject) + (1|item)) : Model formula with interaction. Onset overlap = (0.5,0.2) , onset = UniformOnset(; offset = signalsize * overlap[1], width = signalsize * overlap[2]) , # Put offset to 1 for no overlap. put width to 0 for no jitter Noise noiselevel = 0.2 . noise = PinkNoise(; noiselevel = noiselevel) . Other parameters return_epoched = false : If true, already epoched data is returned. Otherwise, continuous data is returned. Returns (data, events)::Tuple{Array, DataFrame} :  data  contains the simulated EEG data. Its dimensionality depends on the status of  return_epoched  and whether n subjects >=2: `continuous time , continuous time x n subjects , times x size(design)[1] or times x size(design)[1] x n_subjects`.  events  contains the event combinations based on the experimental design. Each row corresponds to one combination of condition levels which is often equivalent to one stimulus or trial. Examples julia> data, events = UnfoldSim.predef_2x2();\n\njulia> events\n100×3 DataFrame\n Row │ A        B        latency \n     │ String   String   Int64   \n─────┼───────────────────────────\n   1 │ a_small  b_large       62\n   2 │ a_big    b_tiny       132\n  ⋮  │    ⋮        ⋮        ⋮\n  99 │ a_big    b_large     5883\n 100 │ a_big    b_tiny      5935\n                  96 rows omitted\n\njulia> data\n6035-element Vector{Float64}:\n  0.32384561187165956\n  0.4108799249488322\n  0.4715514814540277\n  0.5936253009785152\n  ⋮\n  0.047664408295942984\n  0.051193074728432035\n -0.08951617593287822\n -0.14456000097460356 See also  predef_eeg . source"},{"id":352,"pagetitle":"API / Docstrings","title":"UnfoldSim.predef_eeg","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.predef_eeg-Tuple{Any}","content":" UnfoldSim.predef_eeg  —  Method predef_eeg(; <keyword arguments>)\npredef_eeg(rng; <keyword arguments>)\npredef_eeg(rng, n_subjects; <keyword arguments>) Simulate data for a P1/N1/P3 component complex. Note that this function is mainly used for demonstration and internal testing purposes or whenever a quick simulation is needed.  In case  n_subjects  is defined -  MixedModelComponents  are generated (multi-subject simulation), else  LinearModelComponents  (single-subject simulation).  The most used keyword argument is:  return_epoched = true  which returns already epoched data. If you want epoched data without overlap, specify  onset = NoOnset()  and  return_epoched = true . Keyword arguments Design n_repeats = 100 : Number of times the experimental design is repeated. Only used in the single-subject case. n_items = 100 : Number of items. Only used in the multi-subject case. event_order_function = shuffle : Random trial order. Use  event_order_function = (rng, x) -> x  to deactivate. conditions = Dict(:condition => [\"car\", \"face\"], :continuous => range(-5, 5, length = 10)) : Conditions and covariates used in this predefined design. Component / Signal sfreq = 100 : Sampling frequency. p1 = (p100(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()) : P1 with amplitude 5; no effects. n1 = (n170(; sfreq = sfreq), @formula(0 ~ 1 + condition), [5, 3], Dict()) : N1 with amplitude 5, dummy-coded condition effect (levels \"car\", \"face\") of 3. p3 = (p300(; sfreq = sfreq), @formula(0 ~ 1 + continuous), [5, 1], Dict()) : P3 with amplitude 5, continuous effect range [-5,5] with slope 1. Onset overlap = (0.5,0.2) , # convenient parameterization for the default  onset::UniformOnset . ( offset ,  width ) in seconds. If you do not want any overlap, either use  onset=NoOnset() , or put the offset to a value larger than the maximum used component length, e.g.  overlap=(1,0.2) . Put the  width  to  0  to have no jitter between events. onset = UniformOnset(; offset = sfreq * 0.5 * overlap[1], width = sfreq * 0.5 * overlap[2]) ,  Noise noiselevel = 0.2 . noise = PinkNoise(; noiselevel = noiselevel) . Other parameters return_epoched = false : If true, already epoched data is returned. Otherwise, continuous data is returned. Returns (data, events)::Tuple{Array, DataFrame} :  data  contains the simulated EEG data. Its dimensionality depends on the status of  return_epoched  and whether it's a single- or multisubject simulation (1D, 2D or 3D array):  continuous_time ,  continuous_time x n_subjects ,  times x size(design)[1]  or  times x size(design)[1] x n_subjects .  events  contains the event combinations based on the experimental design. Each row corresponds to one combination of condition/covariate levels which is often equivalent to one stimulus or trial. Examples julia> data, events = UnfoldSim.predef_eeg();\n\njulia> events\n2000×3 DataFrame\n  Row │ continuous  condition  latency \n      │ Float64     String     Int64   \n──────┼────────────────────────────────\n    1 │   2.77778   car             62\n    2 │  -5.0       face           132\n  ⋮   │     ⋮           ⋮         ⋮\n 1999 │  -0.555556  face        120096\n 2000 │  -2.77778   car         120154\n\njulia> data\n120199-element Vector{Float64}:\n  0.31631798033146774\n  0.40338935529989906\n  0.46409775558165056\n  0.5862082040156747\n  ⋮\n -0.1879589005111152\n -0.3163314509311509\n -0.22230944464885682\n -0.01320095208877194 See also  predef_2x2 . source"},{"id":353,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate","content":" UnfoldSim.simulate  —  Function simulate(\nrng::AbstractRNG,\ndesign::AbstractDesign,\ncomponents,\nonset::AbstractOnset,\nnoise::AbstractNoise = NoNoise();\nreturn_epoched = false,\n)\n\nsimulate(\ndesign::AbstractDesign,\ncomponents,\nonset::AbstractOnset,\nnoise::AbstractNoise = NoNoise();\nreturn_epoched = false,\n) Simulate continuous or epoched signal, given  design , [Array of]  component ,  onset  and  optional  noise  and  rng . Main simulation function. Arguments rng::AbstractRNG  (optional): Random number generator, important to ensure reproducibility. design::AbstractDesign : Desired experimental design. components :  Component (s) for the desired signal. onset::AbstractOnset : Desired inter-onset distance distribution. noise::AbstractNoise = NoNoise()  (optional): Desired noise. Keyword arguments return_epoched::Bool = false : If set to  true  epoched data is returned, otherwise a continuous signal is returned (see also Notes below). Returns (signal, events)::Tuple{Array, DataFrame} : signal  : Generated signal. Depending on the design, on the components and on     return_epoched , the output can be a 1-D, 2-D, 3-D or 4-D Array.    For example, a 4-D Array would have the dimensions  channels x time x trials x subjects . events : Generated events data frame with latencies. Examples Adapted from the  quickstart tutorial  in the UnfoldSim docs. julia> using Random # to get an RNG\n\njulia> design =\n    SingleSubjectDesign(; conditions = Dict(:cond_A => [\"level_A\", \"level_B\"])) |>\n    x -> RepeatDesign(x, 10);\n\njulia> component = LinearModelComponent(; \n    basis = [0, 0, 0, 0.5, 1, 1, 0.5, 0, 0],\n    formula = @formula(0 ~ 1 + cond_A),\n    β = [1, 0.5],\n);\n\njulia> onset = UniformOnset(; width = 20, offset = 4);\n\njulia> noise = PinkNoise(; noiselevel = 0.2);\n\n# Variant 1: Use a custom RNG.\njulia> data, events = simulate(MersenneTwister(2), design, component, onset, noise);\n\njulia> data\n293-element Vector{Float64}:\n -0.013583193323430123\n  0.09159433856866195\n  ⋮\n -0.25190584567097907\n -0.20179992275876316\n\njulia> events\n20×2 DataFrame\n Row │ cond_A   latency \n     │ String   Int64   \n─────┼──────────────────\n   1 │ level_A        9\n   2 │ level_B       20\n   3 │ level_A       27\n   4 │ level_B       37\n  ⋮  │    ⋮        ⋮\n  18 │ level_B      257\n  19 │ level_A      271\n  20 │ level_B      284\n         13 rows omitted\n\n# Variant 2: Without specifying an RNG, MersenneTwister(1) will be used for the simulation.\njulia> data1, events1 = simulate(design, component, onset, noise);\n┌ Warning: No random generator defined, used the default (`Random.MersenneTwister(1)`) with a fixed seed. This will always return the same results and the user is strongly encouraged to provide their own random generator! Notes Some remarks on how the noise is added: If  return_epoched = true  and  onset = NoOnset()  the noise is added to the epoched data matrix. If  onset  is not  NoOnset , a continuous signal is created and the noise is added to this    i.e. this means that the noise won't be the same as in the  onset = NoOnset()  case even if  return_epoched = true . The case  return_epoched = false  and  onset = NoOnset()  is not possible and therefore    covered by an assert statement. Additional remarks on the overlap of adjacent signals when  return_epoched = true : If  onset = NoOnset()  there will not be any overlapping signals in the data because the onset calculation and conversion to a continuous signal is skipped. If an inter-onset distance distribution is given, a continuous signal(potentially with overlap) is constructed and partitioned into epochs afterwards. source"},{"id":354,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_and_add!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_and_add!-Tuple{AbstractMatrix, Any, Any, Any}","content":" UnfoldSim.simulate_and_add!  —  Method simulate_and_add!(epoch_data::AbstractMatrix, c, simulation, rng)\nsimulate_and_add!(epoch_data::AbstractArray, c, simulation, rng) Helper function to call  simulate_component  and add it to a provided Array  epoch_data . source"},{"id":355,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, AbstractComponent, Simulation}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::AbstractComponent, simulation::Simulation) By default call  simulate_component  with  (rng, c::Abstractcomponent, design::AbstractDesign)  instead of the whole simulation. This function exist solely to provide a \"hook\" if for a custom component something else than the design is necessary, e.g. a dependency on the onsets, noise or similar. source"},{"id":356,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, LinearModelComponent, AbstractDesign}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::LinearModelComponent, design::AbstractDesign) Generate a linear model design matrix, weight it by the coefficients  c.β  and multiply the result with the given basis vector. Returns Matrix{Float64} : Simulated component for each event in the events data frame. The output dimensions are  length(c.basis) x length(design) . Examples julia> design = SingleSubjectDesign(; conditions = Dict(:cond => [\"natural\", \"artificial\"]));\n\njulia> c = UnfoldSim.LinearModelComponent([0, 1, 1, 0], @formula(0 ~ 1 + cond), [1, 2], Dict());\n\njulia> using StableRNGs\n\njulia> simulate_component(StableRNG(1), c, design)\n4×2 Matrix{Float64}:\n 0.0  0.0\n 3.0  1.0\n 3.0  1.0\n 0.0  0.0 source"},{"id":357,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, MixedModelComponent, AbstractDesign}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::MixedModelComponent, design::AbstractDesign, return_parameters = false) Generate a MixedModel and simulate data according to the given parameters  c.β  and  c.σs . Keyword arguments return_parameters::Bool = false : Can be used to return the per-event parameters used to weight the basis function. Sometimes useful to inspect what is simulated. Returns Matrix{Float64} : Simulated component for each event in the events data frame. The output dimensions are  length(c.basis) x length(design) . Notes MixedModels/Sim does not allow simulation of data without white noise of the residuals. Because we want our own noise, we use the following trick to remove the MixedModels-Noise: Practically, we upscale the specified  σs  by factor 10 000, and request a white-noise-level of  σ = 0.0001 . Internally in MixedModels/Sim,  σs  are relative to  σ , and thus are normalized correctly, while keeping the noise 10 000 times smaller than the random effects We cannot exclude that this trick runs into strange numerical issues if the random effect  σs  are very large compared to the fixed effects. Currently, it is not possible to use a different basis for fixed and random effects. If this is needed, some code-scaffold is available but commented out at the moment and requires a bit of implementation work. Examples julia> design = MultiSubjectDesign(; n_subjects = 2, n_items = 6, items_between = Dict(:cond => [\"A\", \"B\"]));\n\njulia> c = UnfoldSim.MixedModelComponent([0, 1, 1, 0], @formula(0 ~ 1 + cond + (1|subject)), [1, 2], Dict(:subject => [2],), Dict());\n\njulia> using StableRNGs\n\njulia> simulate_component(StableRNG(1), c, design)\n4×12 Matrix{Float64}:\n -0.0      -0.0       -0.0      -0.0       -0.0     -0.0       0.0       0.0      0.0       0.0      0.0       0.0\n -2.70645  -0.706388  -2.70632  -0.706482  -2.7066  -0.706424  0.325722  2.32569  0.325627  2.32564  0.325468  2.32565\n -2.70645  -0.706388  -2.70632  -0.706482  -2.7066  -0.706424  0.325722  2.32569  0.325627  2.32564  0.325468  2.32565\n -0.0      -0.0       -0.0      -0.0       -0.0     -0.0       0.0       0.0      0.0       0.0      0.0       0.0\n\njulia> simulate_component(StableRNG(1), c, design, return_parameters = true)\n1×12 Matrix{Float64}:\n -2.70645  -0.706388  -2.70632  -0.706482  -2.7066  -0.706424  0.325722  2.32569  0.325627  2.32564  0.325468  2.32565 source"},{"id":358,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, MultichannelComponent, AbstractDesign}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::MultichannelComponent, design::AbstractDesign) Return the projection of a  MultichannelComponent c  from \"source\" to \"sensor\" space. Returns Array{Float64,3} : Projected simulated component for each event in the events data frame. The output dimensions are  length(c.projection) x length(c.basis) x length(design) . Examples julia> design = SingleSubjectDesign(; conditions = Dict(:cond => [\"natural\", \"artificial\"]));\n\njulia> c = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1 + cond), β = [1, 0.5]);\njulia> mc = UnfoldSim.MultichannelComponent(c, [1, 2, -1, 3, 5, 2.3, 1], PinkNoise());\n\njulia> using StableRNGs\n\njulia> simulate_component(StableRNG(1), mc, design)\n7×15×2 Array{Float64, 3}:\n[:, :, 1] =\n  0.859626   1.16574   0.959523   0.757522   1.17639   1.65156   1.3742    1.76706   2.76971   2.0306    1.17429   1.00922   1.09519   0.754659   2.25662\n  1.71925    2.33147   1.91905    1.51504    2.35278   3.30312   2.7484    3.53412   5.53942   4.0612    2.34858   2.01845   2.19039   1.50932    4.51324\n -0.859626  -1.16574  -0.959523  -0.757522  -1.17639  -1.65156  -1.3742   -1.76706  -2.76971  -2.0306   -1.17429  -1.00922  -1.09519  -0.754659  -2.25662\n  2.57888    3.49721   2.87857    2.27257    3.52917   4.95469   4.1226    5.30118   8.30913   6.09179   3.52287   3.02767   3.28558   2.26398    6.76985\n  4.29813    5.82868   4.79761    3.78761    5.88194   8.25781   6.871     8.8353   13.8485   10.153     5.87145   5.04612   5.47597   3.7733    11.2831\n  1.97714    2.68119   2.2069     1.7423     2.70569   3.79859   3.16066   4.06424   6.37033   4.67037   2.70087   2.32121   2.51894   1.73572    5.19022\n  0.859626   1.16574   0.959523   0.757522   1.17639   1.65156   1.3742    1.76706   2.76971   2.0306    1.17429   1.00922   1.09519   0.754659   2.25662\n\n[:, :, 2] =\n  0.859626   1.16574   0.959523   0.757522   1.17639   1.65156   1.31571   1.56047   2.39471   1.54567   0.689367   0.634223   0.888605   0.69617   2.25662\n  1.71925    2.33147   1.91905    1.51504    2.35278   3.30312   2.63142   3.12094   4.78942   3.09135   1.37873    1.26845    1.77721    1.39234   4.51324\n -0.859626  -1.16574  -0.959523  -0.757522  -1.17639  -1.65156  -1.31571  -1.56047  -2.39471  -1.54567  -0.689367  -0.634223  -0.888605  -0.69617  -2.25662\n  2.57888    3.49721   2.87857    2.27257    3.52917   4.95469   3.94713   4.68142   7.18413   4.63702   2.0681     1.90267    2.66582    2.08851   6.76985\n  4.29813    5.82868   4.79761    3.78761    5.88194   8.25781   6.57855   7.80236  11.9735    7.72837   3.44684    3.17112    4.44303    3.48085  11.2831\n  1.97714    2.68119   2.2069     1.7423     2.70569   3.79859   3.02613   3.58909   5.50783   3.55505   1.58554    1.45871    2.04379    1.60119   5.19022\n  0.859626   1.16574   0.959523   0.757522   1.17639   1.65156   1.31571   1.56047   2.39471   1.54567   0.689367   0.634223   0.888605   0.69617   2.25662 source"},{"id":359,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_interonset_distances","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_interonset_distances","content":" UnfoldSim.simulate_interonset_distances  —  Function simulate_interonset_distances(rng, onset::AbstractOnset, design::AbstractDesign) Generate the inter-onset distance vector by sampling from the respective distribution (in samples). Arguments rng : Random number generator (RNG) to make the process reproducible. onset::AbstractOnset : Inter-onset distance distribution to sample from. design::AbstractDesign : Experimental design with conditions and covariates. Returns Vector{Integer} : Inter-onset distances in samples. Note that these are distances between onsets and no latencies. Examples # Create an experimental design\njulia> design_single = SingleSubjectDesign(;\n           conditions = Dict(\n               :stimulus_type => [\"natural\", \"artificial\"],\n               :contrast_level => range(0, 1, length = 3),\n           ),\n       );\n\n# Create an inter-onset distance distribution\njulia> onset_distribution = LogNormalOnset(3, 0.5, 5, nothing);\n\njulia> using StableRNGs\n\njulia> simulate_interonset_distances(StableRNG(1), onset_distribution, design_single)\n6-element Vector{Int64}:\n 20\n 26\n 34\n 18\n 12\n 23 See also  simulate_onsets . source"},{"id":360,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_noise","content":" UnfoldSim.simulate_noise  —  Function simulate_noise(rng, t::AbstractNoise, n::Int) Generate noise samples of the given type  t . For details, see the documentation of the individual noise types. Use  subtypes(AbstractNoise)  for a list of the implemented noise types. Arguments rng::AbstractRNG : Random number generator (RNG) to make the process reproducible. t::AbstractNoise : Instance of a noise type e.g.  PinkNoise() . n::Int : The number of noise samples that should be generated. Returns Vector : Vector of length  n  containing the noise samples. Examples # Here we use White Noise as an example but it works in the same way for the other noise types.\njulia> noise = WhiteNoise()\nWhiteNoise\n  noiselevel: Int64 1\n  imfilter: Int64 0\n\njulia> using StableRNGs\n\njulia> simulate_noise(StableRNG(1), noise, 3)\n3-element Vector{Float64}:\n -0.5325200748641231\n  0.098465514284785\n  0.7528865221245234 source"},{"id":361,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_onsets","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_onsets-Tuple{Any, AbstractOnset, Simulation}","content":" UnfoldSim.simulate_onsets  —  Method simulate_onsets(rng, onset::AbstractOnset, simulation::Simulation) Call  simulate_interonset_distances  to generate distances between events and then add them up to generate the actual latencies in samples. Please note that this function is mainly for internal use in the context of  simulate  function calls.  Also note that the accumulation of onsets starts at 1 to avoid indexing problems in the case that the first sampled onset is 0. Arguments rng : Random number generator (RNG) to make the process reproducible. onset::AbstractOnset : Inter-onset distance distribution which is passed to  simulate_interonset_distances . simulation::Simulation : Simulation object which contains design, component(s), inter-onset distance distribution and noise. Returns Examples # Create Simulation object\njulia> design_single = SingleSubjectDesign(;\n           conditions = Dict(\n               :stimulus_type => [\"natural\", \"artificial\"],\n               :contrast_level => range(0, 1, length = 3),\n           ),\n       );\n\njulia> p1_component = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1), β = [5]);\n\njulia> simulation = Simulation(design_single, p1_component, UniformOnset(), NoNoise());\n\njulia> using StableRNGs\n\n# Simulate onsets for this simulation\njulia> simulate_onsets(StableRNG(1), simulation.onset, simulation)\n6-element Vector{Int64}:\n  20\n  70\n  97\n 110\n 150\n 182 See also  simulate_interonset_distances . source"},{"id":362,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_responses","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_responses-Tuple{Any, Vector{<:AbstractComponent}, Simulation}","content":" UnfoldSim.simulate_responses  —  Method simulate_responses(\n    rng,\n    components::Vector{<:AbstractComponent},\n    simulation::Simulation) Simulate multiple component responses and accumulate them on a per-event basis. Returns epoch_data :  Matrix  (or  Array  in the multi-channel case) of combined simulated components.   The output dimensions are  maxlength(components) x length(simulation.design)  for single-channel components and    n_channels(components) x maxlength(components) x length(simulation.design)  for multi-channel components. Examples julia> design = SingleSubjectDesign(; conditions = Dict(:cond => [\"natural\", \"artificial\"]));\n\njulia> c1 = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1 + cond), β = [1, 0.5]);\njulia> c2 = LinearModelComponent(; basis = p300(), formula = @formula(0 ~ 1), β = [2]);\n\njulia> simulation = Simulation(design, [c1, c2], UniformOnset(; width = 0, offset = 30), PinkNoise());\n\njulia> using StableRNGs\n\njulia> simulate_responses(StableRNG(1), [c1, c2], simulation)\n45×2 Matrix{Float64}:\n 0.0        0.0\n 0.0        0.0\n 0.0        0.0\n 0.0        0.0\n 0.0        0.0\n ⋮          \n 0.352614   0.352614\n 0.203907   0.203907\n 0.0924246  0.0924246\n 0.0233794  0.0233794\n 0.0        0.0 source"},{"id":363,"pagetitle":"API / Docstrings","title":"UnfoldSim.weight_σs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.weight_σs-Tuple{Dict, Float64, Float64}","content":" UnfoldSim.weight_σs  —  Method weight_σs(σs::Dict, b_σs::Float64, σ_lmm::Float64) Weight a  σs  Dict for MixedModels.jl by  b_σs , a scaling factor typically from a  basis . Finally scales it again by  σ_lmm , as a trick to simulate noise-free LMMs (see  MixedModelsComponent ) In the future, we anticipate a function      function weight_σs(σs::Dict,b_σs::Dict,σ_lmm::Float64)  where each  σs  entry can be weighted individually by a matching  b_σs , but it is not implemented. Arguments σs::Dict  = a Dict of random effects as output of MixedModels.create_re b_σs::Float64  = a scaling factor, typically one entry of a basis function from a component σ_lmm::Float64  = a scaling factor to simulate near-zero noise LMMs Returns `NamedTuple` of the weighted random effects source"},{"id":366,"pagetitle":"Developer documentation","title":"Developer documentation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Developer-documentation","content":" Developer documentation Welcome to the developer documentation! We are excited that you are interested in contributing to our package. Feel free to submit your work in a state you are comfortable with—we genuinely appreciate every contribution! If you are interested in following best practices and learning along the way, keep reading. But don't worry, we welcome your input just as it is 🙂. Contribution guide If you haven't already, please read the  Contribution guide  first. Please note that the following documentation is adapted from the  BestieTemplate.jl developer documentation  but has been customized to fit our needs."},{"id":367,"pagetitle":"Developer documentation","title":"Development/GitHub Workflow","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Development/GitHub-Workflow","content":" Development/GitHub Workflow"},{"id":368,"pagetitle":"Developer documentation","title":"Before you start coding","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Before-you-start-coding","content":" Before you start coding Check whether there exists a GitHub issue about the topic (e.g. bug, new feature etc). If not create one with a short description of the problem or feature idea. Discuss your approach with the package maintainers either in the issue or via another channel."},{"id":369,"pagetitle":"Developer documentation","title":"First time clone & development version","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#First-time-clone-and-development-version","content":" First time clone & development version If this is the first time you work with this repository, follow the instructions below to clone the repository and create a  dev  version.  `dev` version of a Julia package Having a  dev  (development) version of a Julia package allows you to import a local version of the package with your changes instead of the registered package version (which is static)."},{"id":370,"pagetitle":"Developer documentation","title":"a) If you have writing access for the GitHub repository","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#a)-If-you-have-writing-access-for-the-GitHub-repository","content":" a) If you have writing access for the GitHub repository Option 1: Clone this repository using  git clone . Option 2 (recommended): Use the Julia  dev  command to create a development version of the package: Start a Julia session and run  cd(\"/path/to/your/project\")  to navigate to your project folder. Press  ]  to enter  pkg  mode. Run  dev --local UnfoldSim  to clone the package to  ./dev/UnfoldSim  and automatically add it to your Julia project environment. Important If you have writing rights, whenever  upstream  is mentioned below, use  origin  instead."},{"id":371,"pagetitle":"Developer documentation","title":"b) If you don't have writing access for the GitHub repository","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#b)-If-you-don't-have-writing-access-for-the-GitHub-repository","content":" b) If you don't have writing access for the GitHub repository Fork the UnfoldSim.jl repository. Clone your repository (this will create a  git remote  called  origin ). Add the UnfoldSim.jl repository as a remote: git remote add upstream https://github.com/unfoldtoolbox/UnfoldSim.jl This will ensure that you have two remotes in your git:  origin  and  upstream . You will create branches and push to  origin , and you will fetch and update your local  main  branch from  upstream . `dev` version without writing rights You can also use the  dev  command on your fork. Run  ]dev --local url/of/your/fork  to clone the package to  ./dev/UnfoldSim  and automatically add it to your Julia project environment."},{"id":372,"pagetitle":"Developer documentation","title":"Revise.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Revise.jl","content":" Revise.jl Further, we recommend to use  Revise.jl : a Julia package which allows you to track source code changes in a running Julia session without need to restart it and reload the package. We recommend to install it in the global environment: julia> # Press ]\npkg> activate\npkg> add Revise"},{"id":373,"pagetitle":"Developer documentation","title":"Working on a new issue","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Working-on-a-new-issue","content":" Working on a new issue We try to keep a linear Git history in this repository, so it is important to keep your branches up-to-date. Fetch from the remote and fast-forward your local main git fetch upstream\ngit switch main\ngit merge --ff-only upstream/main Branch from  main  to address the issue (see below for naming) git switch -c 42-add-answer-universe Push the new local branch to your personal remote repository git push -u origin 42-add-answer-universe Create a pull request to merge your remote branch into the  main  branch of the original UnfoldSim.jl repository."},{"id":374,"pagetitle":"Developer documentation","title":"Branch naming","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Branch-naming","content":" Branch naming If there is an associated issue, add the issue number. If there is no associated issue,  and the changes are small , add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update. If the changes are not small and there is no associated issue, then either create an issue first, or discuss in another channel with the maintainers. Use dash separated imperative wording related to the issue (e.g.,  14-add-tests ,  15-fix-model ,  16-remove-obsolete-files )."},{"id":375,"pagetitle":"Developer documentation","title":"Commit messages","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Commit-messages","content":" Commit messages Use imperative or present tense, for instance:  Add feature  or  Fix bug . Have informative titles. When necessary, add a body with details. If there are breaking changes, add the information to the commit message."},{"id":376,"pagetitle":"Developer documentation","title":"Before creating a pull request","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Before-creating-a-pull-request","content":" Before creating a pull request Ideally: Make sure the tests pass (see  Testing ). Add appropriate documentation (ideally using the  Docstring templates ). Ideally: Follow the formatting rules from  JuliaFormatter.jl  (see  Formatting ). Fetch any  main  updates from upstream and rebase your branch, if necessary: git fetch upstream\ngit rebase upstream/main BRANCH_NAME Then you can open a pull request and work with the reviewer to address any issues. Best practices not shackles We encourage you to share your contributions in whatever state you are comfortable with. Don’t feel overwhelmed by the number of guides — think of them as helpful resources, not strict requirements. Every contribution is valuable, and we’re happy to refine things together! "},{"id":377,"pagetitle":"Developer documentation","title":"Formatting","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Formatting","content":" Formatting"},{"id":378,"pagetitle":"Developer documentation","title":"JuliaFormatter.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#JuliaFormatter.jl","content":" JuliaFormatter.jl We use  JuliaFormatter.jl  for formatting and recommend you to install it in your global environment: julia> # Press ]\npkg> activate\npkg> add JuliaFormatter"},{"id":379,"pagetitle":"Developer documentation","title":"Beware of reviewdog 🐶","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Beware-of-reviewdog","content":" Beware of reviewdog 🐶 We use the  julia-format  Github action to ensure that the code follows the formatting rules defined by  JuliaFormatter.jl . When opening a pull request  reviewdog  will automatically make formatting suggestions for your code."},{"id":380,"pagetitle":"Developer documentation","title":"Testing","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Testing","content":" Testing As with most Julia packages, you can just open Julia in the repository folder, activate the environment, and run  test : julia> # press ]\npkg> activate .\npkg> test Running single tests Instead of running all tests, you can also run the  test/setup.jl  to load all required packages, and subsequently run single tests manually either by  include(\"test/my_test.jl\")  or by opening the file and running the specific test block you want to run."},{"id":381,"pagetitle":"Developer documentation","title":"Documentation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Documentation","content":" Documentation Documentation is key to maintaining a codebase that is easy to understand and extend. Whether it is comments in the code, docstrings, or tutorials, when writing documentation,  think about your future self or the next person reading the code or using your functions."},{"id":382,"pagetitle":"Developer documentation","title":"Building and viewing the documentation locally","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Building-and-viewing-the-documentation-locally","content":" Building and viewing the documentation locally We recommend using  LiveServer.jl  to build and preview the documentation locally. To simplify this process we created the  docs/run_liveserver.jl  script. Please follow these steps: Navigate to the  docs  folder and activate it. Run  using Revise  (in case you decided to install it in your docs environment). If this is the first time building the docs Press  ]  to enter  pkg  mode. Run  pkg> dev ..  to use the development version of your package. Press backspace to leave  pkg  mode. Run  include(\"run_liveserver.jl\") . Click on the provided link or go to  http://0.0.0.0:8000/  in your browser. Live preview of docstrings Install  Revise.jl  in the docs environment to enable live updating of docstrings in the docs preview. Separate Julia session for docs preview We recommend using a separate Julia session (in VSCode) to run the  run_liveserver.jl  script, as it continues running. This way, you can avoid \"blocking\" the REPL and run other code in the meantime."},{"id":383,"pagetitle":"Developer documentation","title":"Adding a documentation page","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Adding-a-documentation-page","content":" Adding a documentation page We recommend to write a Literate.jl document and place it in  docs/literate/FOLDER/FILENAME.jl  with  FOLDER  being  HowTo ,  Explanation ,  Tutorial  or  Reference  ( recommended reading on the 4 categories ). Literate.jl converts the  .jl  file to a  .md  automatically and places it in  docs/src/generated/FOLDER/FILENAME.md . Edit  make.jl  with a reference to  docs/src/generated/FOLDER/FILENAME.md ."},{"id":384,"pagetitle":"Developer documentation","title":"Docstring templates","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Docstring-templates","content":" Docstring templates The following docstring templates are mainly based on the  Julia manual  and  Blue: a Style Guide for Julia ."},{"id":385,"pagetitle":"Developer documentation","title":"Function docstring template","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Function-docstring-template","content":" Function docstring template \"\"\"\n    my_function(argument1:Type1; keyword_argument3::Type3 = value3)\n    my_function(argument1::Type1, optional_argument2::Type2; keyword_argument3::Type3 = value3)\n\nOne-line description using the imperative form (\"Do this\") instead of the third person and ending with a period.\n\nIf the one-line description is not sufficient, one can also write a short paragraph with additional information.\n\n# Arguments (if needed)\n- `argument1::Type1`: Description of argument1.\n- `optional_argument2::Type2` (optional): Description of optional_argument2.\n\n# Keyword arguments (if needed)\n- `keyword_argument3::Type3 = value3`: Description of keyword_argument3.\n\n# Returns\n- `result::Type4` : Description of result.\n\n# Examples\n```julia-repl\njulia> my_function(value1, value2)\nresult1\n\njulia> my_function(value1; keyword_argument3 = value4)\nresult2\n```\n\nSee also [`my_function2`](@ref), [`my_function3`](@ref).\n\"\"\" Special cases: If a function accepts many keyword arguments, only include  <keyword arguments>  as a placeholder in the signature and give a keyword list with descriptions in the Keyword arguments section of the docstring. If a function returns more than one variable, write the Returns section in the following way: # Returns\n- (result1, result2)::Tuple{Type1, Type2}:\n    - Description of result1\n    - Description of result2"},{"id":386,"pagetitle":"Developer documentation","title":"Type docstring template","ref":"/UnfoldDocs/UnfoldSim.jl/stable/developer_docs/#Type-docstring-template","content":" Type docstring template \"\"\"\n    MyType <: MyAbstractType\n\nOne-line desciption of my type which ends with a period.\n\nIf the one-line description is not sufficient, one can also write a short paragraph with additional information.\n\n# Fields\n- `field1::Type1`: Description of field1.\n- `optional_field2::Type2 = value2` (optional): Description of field2. If not provided, defaults to `value2`.\n\n# Examples\n```julia-repl\njulia> MyType(field1, field2)\nresult1\n```\n\nSee also [`MyType2`](@ref), [`my_function2`](@ref).\n\"\"\""},{"id":389,"pagetitle":"Generate multi channel data","title":"Generate multi channel data","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Generate-multi-channel-data","content":" Generate multi channel data Here you will learn how to simulate EEG data for multiple channels/electrodes. The idea is to specify a signal on source level and then use a head model or a manual projection matrix to project the source signal to a number of electrodes."},{"id":390,"pagetitle":"Generate multi channel data","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing UnfoldMakie\nusing CairoMakie\nusing DataFrames\nusing Random"},{"id":391,"pagetitle":"Generate multi channel data","title":"Specifying a design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Specifying-a-design","content":" Specifying a design We are using a one-level design for testing here. design = SingleSubjectDesign(conditions = Dict(:condA => [\"levelA\"])); Next we generate two simple components at two different times without any formula attached (we have a single condition anyway) c = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1), β = [1]);\nc2 = LinearModelComponent(; basis = p300(), formula = @formula(0 ~ 1), β = [1]);"},{"id":392,"pagetitle":"Generate multi channel data","title":"The multichannel component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#The-multichannel-component","content":" The multichannel component Next, similar to the nested design above, we can nest the component in a  MultichannelComponent . We could either provide the projection matrix manually, e.g.: mc = UnfoldSim.MultichannelComponent(c, [1, 2, -1, 3, 5, 2.3, 1]) MultichannelComponent\n  component: LinearModelComponent\n  projection: Array{Float64}((7,)) [1.0, 2.0, -1.0, 3.0, 5.0, 2.3, 1.0]\n  noise: NoNoise NoNoise()\n or maybe more convenient: use the pair-syntax: Headmodel=>Label which makes use of a headmodel (HaRTmuT is currently easily available in UnfoldSim) hart = Hartmut()\nmc = UnfoldSim.MultichannelComponent(c, hart => \"Left Postcentral Gyrus\")\nmc2 = UnfoldSim.MultichannelComponent(c2, hart => \"Right Occipital Pole\") MultichannelComponent\n  component: LinearModelComponent\n  projection: Array{Float64}((227,)) [-0.03461859471337842, -0.04321094803502425, 0.0037088347968313525, -0.014722528968861278, -0.0234889834534478, 0.02731807504242923, 0.038863688452528036, 0.1190531258070562, -0.09956890221613562, -0.0867729334438599  …  0.37435404409695094, -0.020863789022627935, 0.25627478723535513, -0.05777985212119245, 0.37104376432271147, -0.19446620423767172, 0.2590764703721097, -0.12923837607416555, 0.1732886690359311, 0.4703016561960567]\n  noise: NoNoise NoNoise()\n Hint You could also specify a noise-specific component which is applied prior to projection & summing with other components. finally we need to define the onsets of the signal onset = UniformOnset(; width = 20, offset = 4);"},{"id":393,"pagetitle":"Generate multi channel data","title":"Simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Simulation","content":" Simulation Now as usual we simulate data. Inspecting data shows our result is now indeed ~230 Electrodes large! Nice! data, events =\n    simulate(MersenneTwister(1), design, [mc, mc2], onset, PinkNoise(noiselevel = 0.05));\n\nsize(data) (227, 61) Hint The noise declared in the  simulate  function is added after mixing to channels, each channel receives independent noise. It is also possible to add noise to each individual component+source prior to projection. This would introduce correlated noise."},{"id":394,"pagetitle":"Generate multi channel data","title":"Plotting","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Plotting","content":" Plotting Let's plot using Butterfly & Topoplot first we convert the electrodes to positions usable in TopoPlots.jl pos3d = hart.electrodes[\"pos\"]\npos2d = to_positions(pos3d')\npos2d = [Point2f(p[1] + 0.5, p[2] + 0.5) for p in pos2d]; now plot! f = Figure()\ndf = DataFrame(\n    :estimate => data[:],\n    :channel => repeat(1:size(data, 1), outer = size(data, 2)),\n    :time => repeat(1:size(data, 2), inner = size(data, 1)),\n)\nplot_butterfly!(f[1, 1:2], df; positions = pos2d)\nplot_topoplot!(\n    f[2, 1],\n    df[df.time.==28, :];\n    positions = pos2d,\n    visual = (; enlarge = 0.5, label_scatter = false),\n    axis = (; limits = ((0, 1), (0, 0.9))),\n)\nplot_topoplot!(\n    f[2, 2],\n    df[df.time.==48, :];\n    positions = pos2d,\n    visual = (; enlarge = 0.5, label_scatter = false),\n    axis = (; limits = ((0, 1), (0, 0.9))),\n)\nf This page was generated using  Literate.jl ."},{"id":397,"pagetitle":"Define a new component (with variable duration and shift)","title":"Define a new component (with variable duration and shift)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Define-a-new-component-(with-variable-duration-and-shift)","content":" Define a new component (with variable duration and shift) We want a new component that changes its duration and shift depending on a column in the event design. This is somewhat already implemented in the HRF + Pupil bases."},{"id":398,"pagetitle":"Define a new component (with variable duration and shift)","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Setup","content":" Setup Click to expand using UnfoldSim\nusing Unfold\nusing Random\nusing DSP\nusing CairoMakie, UnfoldMakie\n\nsfreq = 100;"},{"id":399,"pagetitle":"Define a new component (with variable duration and shift)","title":"Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Design","content":" Design Let's generate a design with two columns, shift + duration design = UnfoldSim.SingleSubjectDesign(;\n    conditions = Dict(\n        :shift => rand(100) .* sfreq / 5,\n        :duration => 20 .+ rand(100) .* sfreq / 5,\n    ),\n) SingleSubjectDesign\n  conditions: Dict{Symbol, Vector}\n  event_order_function: #3 (function of type UnfoldSim.var\"#3#7\")\n"},{"id":400,"pagetitle":"Define a new component (with variable duration and shift)","title":"Implement a new AbstractComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Implement-a-new-AbstractComponent","content":" Implement a new AbstractComponent We also need a new  AbstractComponent struct TimeVaryingComponent <: AbstractComponent\n    basisfunction::Any\n    maxlength::Any\nend We have to define the length of a component Base.length(c::TimeVaryingComponent) = length(c.maxlength) While we could have put the TimeVaryingComponent.basisfunction directly into the simulate function, I thought this is a bit more modular function UnfoldSim.simulate(rng, c::TimeVaryingComponent, design::AbstractDesign)\n    evts = generate_events(design)\n    return c.basisfunction(evts, c.maxlength)\nend finally, the actual function that does the shifting + duration function basis_shiftduration(evts, maxlength)\n    basis = hanning.(Int.(round.(evts.duration))) ## hanning as long as duration\n    if \"shift\" ∈ names(evts)\n        basis = pad_array.(basis, Int.(round.(.-evts.shift)), 0) ## shift by adding 0 in front\n    end\n    # we should make sure that all bases have maxlength by appending / truncating\n    difftomax = maxlength .- length.(basis)\n    if any(difftomax .< 0)\n        @warn \"basis longer than max length in at least one case. either increase maxlength or redefine function. Trying to truncate the basis\"\n        basis[difftomax.>0] = pad_array.(basis[difftomax.>0], difftomax[difftomax.>0], 0)\n        return [b[1:maxlength] for b in basis]\n    else\n        return pad_array.(basis, difftomax, 0)\n    end\nend basis_shiftduration (generic function with 1 method)"},{"id":401,"pagetitle":"Define a new component (with variable duration and shift)","title":"Simulate data with the new component type","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Simulate-data-with-the-new-component-type","content":" Simulate data with the new component type erp = UnfoldSim.simulate(\n    MersenneTwister(1),\n    TimeVaryingComponent(basis_shiftduration, 50),\n    design,\n)\nplot_erpimage(hcat(erp...), sortvalues = generate_events(design).shift) This page was generated using  Literate.jl ."},{"id":404,"pagetitle":"Define a new (imbalanced) design","title":"Define a new (imbalanced) design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#Define-a-new-(imbalanced)-design","content":" Define a new (imbalanced) design A design specifies how much data is generated, and how the event-table(s) should be generated. Already implemented examples are  MultiSubjectDesign  and  SingleSubjectDesign . We need 3 things for a new design: a  struct<:AbstractDesign , a  size  and a  generate_events  function."},{"id":405,"pagetitle":"Define a new (imbalanced) design","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#Setup","content":" Setup Click to expand using UnfoldSim\nusing StableRNGs\nusing DataFrames\nusing Parameters\nusing Random"},{"id":406,"pagetitle":"Define a new (imbalanced) design","title":"1) type","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#1)-type","content":" 1)  type We need a  ImbalanceSubjectDesign  struct. You are free to implement it as you wish, as long as the other two functions are implemented @with_kw struct ImbalanceSubjectDesign <: UnfoldSim.AbstractDesign\n    n_trials::Int\n    balance::Float64 = 0.5 # default balanced\nend;"},{"id":407,"pagetitle":"Define a new (imbalanced) design","title":"2) size","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#2)-size","content":" 2)  size we need a  size(design::ImbalanceSubjectDesign)  function to tell how many events we will have. This is used at different places, e.g. in the Default onset implementation # note the trailing , to make it a Tuple\nUnfoldSim.size(design::ImbalanceSubjectDesign) = (design.n_trials,);"},{"id":408,"pagetitle":"Define a new (imbalanced) design","title":"3) generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#3)-generate_events","content":" 3)  generate_events We need a type  generate_events(rng::AbstractRNG, design::ImbalanceSubjectDesign)  function. This function should return the actual table as a  DataFrame function UnfoldSim.generate_events(rng::AbstractRNG, design::ImbalanceSubjectDesign)\n    nA = Int(round.(design.n_trials .* design.balance))\n    nB = Int(round.(design.n_trials .* (1 - design.balance)))\n    @assert nA + nB ≈ design.n_trials\n    levels = vcat(repeat([\"levelA\"], nA), repeat([\"levelB\"], nB))\n    return DataFrame(Dict(:condition => levels))\nend; Finally, we can test the function and see whether it returns a Design-DataFrame as we requested design = ImbalanceSubjectDesign(; n_trials = 6, balance = 0.2)\ngenerate_events(design) 6×1 DataFrame Row condition String 1 levelA 2 levelB 3 levelB 4 levelB 5 levelB 6 levelB This page was generated using  Literate.jl ."},{"id":411,"pagetitle":"Use existing experimental designs & onsets in the simulation","title":"Use existing experimental designs & onsets in the simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/predefinedData/#Use-existing-experimental-designs-and-onsets-in-the-simulation","content":" Use existing experimental designs & onsets in the simulation Let's say you want to use the events data frame (containing the levels of the experimental variables and the event onsets (latencies)) from a previous study in your simulation."},{"id":412,"pagetitle":"Use existing experimental designs & onsets in the simulation","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/predefinedData/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing DataFrames\nusing Random\nusing CairoMakie # for plotting From a previous study, we (somehow, e.g. by using  pyMNE.jl ) imported an event data frame like this: my_events = DataFrame(:condition => [:A, :B, :B, :A, :A], :latency => [7, 13, 22, 35, 41]) 5×2 DataFrame Row condition latency Symbol Int64 1 A 7 2 B 13 3 B 22 4 A 35 5 A 41 To use exactly these values, we can generate a new  AbstractDesign , which will always return this event dataframe struct MyManualDesign <: AbstractDesign\n    my_events::Any\nend\nUnfoldSim.generate_events(rng, d::MyManualDesign) = deepcopy(d.my_events) ## generate function which is called internally in UnfoldSim\nUnfoldSim.size(d::MyManualDesign) = size(d.my_events, 1); ## necessary function to tell what the dimensionality of the experimental design is Note Note the  UnfoldSim.generate_events  which tells Julia to \"overload\" the  generate_events  function as defined in UnfoldSim. Next we generate a  MyManualDesign mydesign = MyManualDesign(my_events); We could already use this \"solo\" and simulate some data, for example: signal = LinearModelComponent(;\n    basis = [1, 1, 0.5, 0, 0],\n    formula = @formula(0 ~ 1 + condition),\n    β = [1, 0.5],\n);\n\ndata, events =\n    simulate(MersenneTwister(1), mydesign, signal, UniformOnset(; width = 10, offset = 5))\nlines(data) # plotting\nvlines!(my_events.latency; linestyle = :dash)\ncurrent_figure() Looks good, but the events don't match our custom onsets yet."},{"id":413,"pagetitle":"Use existing experimental designs & onsets in the simulation","title":"Custom Timings","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/predefinedData/#Custom-Timings","content":" Custom Timings Finally, we want to use our custom timings as well. For this we define a new  AbstractOnset . Again, it simply returns our manually provided latencies struct MyManualOnset <: AbstractOnset end\nUnfoldSim.simulate_onsets(rng, onset::MyManualOnset, simulation::Simulation) =\n    generate_events(rng, simulation.design).latency Hint This is a bit of a trick, it relies that  MyManualOnset  is always used in combination with  MyManualDesign . You could of course repeat the structure from  MyManualDesign  also for  MyManualOnset  and have an explicit field in the structure containing the onsets. And that's it data, events = simulate(MersenneTwister(1), mydesign, signal, MyManualOnset())\nlines(data) # plotting\nvlines!(my_events.latency, linestyle = :dash)\ncurrent_figure() now everything matches, lovely! This page was generated using  Literate.jl ."},{"id":416,"pagetitle":"Get multiple trials with identical subject/item combinations","title":"Get multiple trials with identical subject/item combinations","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/repeatTrials/#howto_repeat_design","content":" Get multiple trials with identical subject/item combinations Sometimes we want to repeat a design, that is, have multiple trials with identical values, but it is not always straight forward to implement. For instance, there is no way to easily modify  MultiSubjectDesign  to have multiple identical subject/item combinations, without doing awkward repetitions of condition-levels or something. If you struggle with this problem  RepeatDesign  is an easy tool for you: using UnfoldSim\n\ndesignOnce = MultiSubjectDesign(;\n    n_items = 2,\n    n_subjects = 2,\n    subjects_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n    items_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n);\n\ndesign = RepeatDesign(designOnce, 4);\ngenerate_events(design) 8×3 DataFrame Row subject cond item String String String 1 S1 levelA I1 2 S1 levelA I1 3 S1 levelA I1 4 S1 levelA I1 5 S2 levelB I2 6 S2 levelB I2 7 S2 levelB I2 8 S2 levelB I2 As you can see, the design was simply repeated. Note If you implemented your own  AbstractDesign , you need to define the size function accordingly. E.g.:    Base.size(design::RepeatDesign{SingleSubjectDesign}) = size(design.design).*design.repeat This page was generated using  Literate.jl ."},{"id":419,"pagetitle":"Overview: Basis function (component) types","title":"Overview: Basis function (component) types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#Overview:-Basis-function-(component)-types","content":" Overview: Basis function (component) types There are several basis types directly implemented. They can be easily used for the  components . Note You can use any arbitrary shape defined by yourself! We often make use of  hanning(50)  from the DSP.jl package."},{"id":420,"pagetitle":"Overview: Basis function (component) types","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing CairoMakie\nusing DSP\nusing StableRNGs"},{"id":421,"pagetitle":"Overview: Basis function (component) types","title":"EEG","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#EEG","content":" EEG By default, the EEG bases assume a sampling rate of 100, which can easily be changed by e.g. p100(; sfreq=300) f = Figure()\nax = f[1, 1] = Axis(f)\nfor b in [p100, n170, p300, n400]\n    lines!(ax, b(), label = string(b))\n    scatter!(ax, b(), label = string(b))\nend\naxislegend(ax, merge = true)\nf"},{"id":422,"pagetitle":"Overview: Basis function (component) types","title":"fMRI","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#fMRI","content":" fMRI default hrf TR is 1. Get to know all your favourite shapes! ##--\nf = Figure()\nplotConfig = (\n    :peak => 1:3:10,\n    :post_undershoot => 10:5:30,\n    :amplitude => 2:5,\n    :shift => 0:3:10,\n    :peak_width => 0.1:0.5:1.5,\n    :post_undershoot_width => 0.1:0.5:1.5,\n)\n\nfor (ix, pl) in enumerate(plotConfig)\n    col = (ix - 1) % 3 + 1\n    row = Int(ceil(ix / 3))\n\n    ax = f[row, col] = Axis(f)\n    cfg = collect(pl)\n    for k in cfg[2]\n        lines!(ax, UnfoldSim.hrf(; TR = 0.1, (cfg[1] => k,)...), label = string(k))\n    end\n\n    axislegend(string(cfg[1]); merge = true)\nend\nf"},{"id":423,"pagetitle":"Overview: Basis function (component) types","title":"Pupil","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#Pupil","content":" Pupil We use the simplified PuRF from Hoeks & Levelt, 1993. Note that https://www.science.org/doi/10.1126/sciadv.abi9979 show some evidence in their supplementary material, that the convolution model is not fully applicable. f = Figure()\nplotConfig = (:n => 5:3:15, :tmax => 0.5:0.2:1.1)\n\nfor (ix, pl) in enumerate(plotConfig)\n    ax = f[1, ix] = Axis(f)\n    cfg = collect(pl)\n    for k in cfg[2]\n        lines!(ax, UnfoldSim.PuRF(; (cfg[1] => k,)...), label = string(k))\n    end\n\n    axislegend(string(cfg[1]); merge = true)\nend\nf This page was generated using  Literate.jl ."},{"id":426,"pagetitle":"Overview: Experimental design types","title":"Overview: Experimental design types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Overview:-Experimental-design-types","content":" Overview: Experimental design types The experimental design specifies the experimental conditions and other variables that are supposed to have an influence on the simulated data. Currently, there are three types of designs implemented:  SingleSubjectDesign ,  MultiSubjectDesign  and  RepeatDesign ."},{"id":427,"pagetitle":"Overview: Experimental design types","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Random"},{"id":428,"pagetitle":"Overview: Experimental design types","title":"Single-subject designs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Single-subject-designs","content":" Single-subject designs As the name suggests, the  SingleSubjectDesign  type can be used to specify the experimental design for a single subject. Using the  conditions  arguments, the user can specify all relevant conditions or predictors and their levels or value range. The current implementation assumes a full factorial design (also called fully crossed design) in which each level of a factor occurs with each level of the other factors. Moreover, in the current implementation, there is exactly one instance of each of these factor combinations. Example: design_single = SingleSubjectDesign(;\n    conditions = Dict(\n        :stimulus_type => [\"natural\", \"artificial\"],\n        :contrast_level => range(0, 1, length = 3),\n    ),\n); In order to inspect the design, we can use the  generate_events  function to create an event table based on the design we specified. generate_events(design_single) 6×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 natural 2 0.5 natural 3 1.0 natural 4 0.0 artificial 5 0.5 artificial 6 1.0 artificial To change the order of the trials e.g. to sort or shuffle them, one can use the  event_order_function  argument. Example: Randomize the order of trials design_single_shuffled = SingleSubjectDesign(;\n    conditions = Dict(\n        :stimulus_type => [\"natural\", \"artificial\"],\n        :contrast_level => range(0, 1, length = 3),\n    ),\n    event_order_function = shuffle,\n); Click to expand event table  generate_events(design_single_shuffled) 6×2 DataFrame Row contrast_level stimulus_type Float64 String 1 1.0 artificial 2 0.5 natural 3 0.0 artificial 4 0.0 natural 5 1.0 natural 6 0.5 artificial"},{"id":429,"pagetitle":"Overview: Experimental design types","title":"Multi-subject designs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Multi-subject-designs","content":" Multi-subject designs The  MultiSubjectDesign  type can be used to simulate data for an experiment with multiple subjects. Internally, it uses the  MixedModelsSim.jl package . One needs to specify the number of subjects  n_subjects  and the number of items  n_items  i.e. stimuli. In addition, one needs to decide for every experimental factor whether it should be between- or within-subject (and item). Note For factors that are not listed in  items_between  it is assumed that they vary within-item (accordingly for  subjects_between ). design_multi = MultiSubjectDesign(\n    n_subjects = 6,\n    n_items = 4,\n    items_between = Dict(:colour => [\"red\", \"blue\"]),\n    subjects_between = Dict(:age_group => [\"young\", \"old\"]),\n    both_within = Dict(:luminance => range(0, 1, length = 3)),\n); Click to expand event table  generate_events(design_multi) 72×5 DataFrame Row subject age_group item colour luminance String String String String Float64 1 S1 young I1 red 0.0 2 S1 young I2 blue 0.0 3 S1 young I3 red 0.0 4 S1 young I4 blue 0.0 5 S1 young I1 red 0.5 6 S1 young I2 blue 0.5 7 S1 young I3 red 0.5 8 S1 young I4 blue 0.5 9 S1 young I1 red 1.0 10 S1 young I2 blue 1.0 11 S1 young I3 red 1.0 12 S1 young I4 blue 1.0 13 S2 old I1 red 0.0 14 S2 old I2 blue 0.0 15 S2 old I3 red 0.0 16 S2 old I4 blue 0.0 17 S2 old I1 red 0.5 18 S2 old I2 blue 0.5 19 S2 old I3 red 0.5 20 S2 old I4 blue 0.5 21 S2 old I1 red 1.0 22 S2 old I2 blue 1.0 23 S2 old I3 red 1.0 24 S2 old I4 blue 1.0 25 S3 young I1 red 0.0 26 S3 young I2 blue 0.0 27 S3 young I3 red 0.0 28 S3 young I4 blue 0.0 29 S3 young I1 red 0.5 30 S3 young I2 blue 0.5 31 S3 young I3 red 0.5 32 S3 young I4 blue 0.5 33 S3 young I1 red 1.0 34 S3 young I2 blue 1.0 35 S3 young I3 red 1.0 36 S3 young I4 blue 1.0 37 S4 old I1 red 0.0 38 S4 old I2 blue 0.0 39 S4 old I3 red 0.0 40 S4 old I4 blue 0.0 41 S4 old I1 red 0.5 42 S4 old I2 blue 0.5 43 S4 old I3 red 0.5 44 S4 old I4 blue 0.5 45 S4 old I1 red 1.0 46 S4 old I2 blue 1.0 47 S4 old I3 red 1.0 48 S4 old I4 blue 1.0 49 S5 young I1 red 0.0 50 S5 young I2 blue 0.0 51 S5 young I3 red 0.0 52 S5 young I4 blue 0.0 53 S5 young I1 red 0.5 54 S5 young I2 blue 0.5 55 S5 young I3 red 0.5 56 S5 young I4 blue 0.5 57 S5 young I1 red 1.0 58 S5 young I2 blue 1.0 59 S5 young I3 red 1.0 60 S5 young I4 blue 1.0 61 S6 old I1 red 0.0 62 S6 old I2 blue 0.0 63 S6 old I3 red 0.0 64 S6 old I4 blue 0.0 65 S6 old I1 red 0.5 66 S6 old I2 blue 0.5 67 S6 old I3 red 0.5 68 S6 old I4 blue 0.5 69 S6 old I1 red 1.0 70 S6 old I2 blue 1.0 71 S6 old I3 red 1.0 72 S6 old I4 blue 1.0 As with the  SingleSubjectDesign  one can use the  event_order_function  argument to determine the order of events/trials. Important The number of subjects/items has to be a divisor of the number of factor level combinations, i.e. it is assumed that the design is balanced which means that there is an equal number of observations for all possible factor level combinations."},{"id":430,"pagetitle":"Overview: Experimental design types","title":"Repeat designs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Repeat-designs","content":" Repeat designs The  RepeatDesign  type is a functionality to encapsulate single- or multi-subject designs. It allows to repeat a generated event table multiple times. In other words, the  RepeatDesign  type allows to have multiple instances of the same item/subject/factor level combination. Example: Assume, we have the following single-subject design from above: Click to expand event table  generate_events(design_single) 6×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 natural 2 0.5 natural 3 1.0 natural 4 0.0 artificial 5 0.5 artificial 6 1.0 artificial But instead of having only one instance of the factor combinations e.g.  stimulus_type :  natural  and  contrast_level :  0 , we will repeat the design three times such that there are three occurrences of each combination. design_repeated = RepeatDesign(design_single, 3);\ngenerate_events(design_repeated) 18×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 natural 2 0.5 natural 3 1.0 natural 4 0.0 artificial 5 0.5 artificial 6 1.0 artificial 7 0.0 natural 8 0.5 natural 9 1.0 natural 10 0.0 artificial 11 0.5 artificial 12 1.0 artificial 13 0.0 natural 14 0.5 natural 15 1.0 natural 16 0.0 artificial 17 0.5 artificial 18 1.0 artificial Here  one can find another example of how to repeat design entries for multi-subject designs. This page was generated using  Literate.jl ."},{"id":433,"pagetitle":"Overview: Noise types","title":"Overview: Noise types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/noisetypes/#Overview:-Noise-types","content":" Overview: Noise types There are different types of noise signals which differ in their power spectra. If you are not familiar with different types/colors of noise yet, have a look at the  colors of noise Wikipedia page . There are several noise types directly implemented in UnfoldSim.jl. Here is a comparison: using UnfoldSim\nusing CairoMakie\nusing DSP\nusing StableRNGs\nimport StatsBase.autocor\n\nf = Figure()\nax_sig =\n    f[1, 1:3] =\n        Axis(f; title = \"1.000 samples of noise\", xlabel = \"Time\", ylabel = \"Amplitude\")\nax_spec =\n    f[2, 1:2] = Axis(\n        f;\n        title = \"Welch Periodogram\",\n        xlabel = \"Normalized frequency\",\n        ylabel = \"log(Power)\",\n    )\nax_auto =\n    f[2, 3:4] = Axis(\n        f;\n        title = \"Autocorrelogram (every 10th lag)\",\n        xlabel = \"Lag\",\n        ylabel = \"Autocorrelation\",\n    )\nfor n in [PinkNoise RedNoise WhiteNoise NoNoise ExponentialNoise]\n\n    # generate\n    noisevec = simulate_noise(StableRNG(1), n(), 10000)\n\n    # plot 1000 samples\n    lines!(ax_sig, noisevec[1:1000]; label = string(n))\n\n    # calc spectrum\n    perio = welch_pgram(noisevec)\n\n    # plot spectrum\n    lines!(ax_spec, freq(perio), log10.(power(perio)))\n\n    lags = 0:10:500\n    autocor_vec = autocor(noisevec, lags)\n    lines!(ax_auto, lags, autocor_vec)\n\nend\nf[1, 4] = Legend(f, ax_sig, \"Noise type\", tellheight = true)\nf Hint We recommed for smaller signals the  ExponentialNoise , maybe with a removed DC offset or a HighPass filter. For long signals, this Noise requires lots of memory though. maybe Pinknoise is a better choice then. This page was generated using  Literate.jl ."},{"id":436,"pagetitle":"Overview: Onset types","title":"Overview: Onset types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#Overview:-Onset-types","content":" Overview: Onset types The onset types determine the distances between event onsets in the continuous EEG signal. The distances are sampled from a certain probability distribution. Currently, there are two types of onset distributions implemented:  UniformOnset  and  LogNormalOnset ."},{"id":437,"pagetitle":"Overview: Onset types","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing CairoMakie\nusing Random\n\n# Define a simple design and repeat it 10000.\n# This will result in 20000 events i.e. event onsets.\ndesign =\n    SingleSubjectDesign(conditions = Dict(:cond => [\"A\", \"B\"])) |>\n    x -> RepeatDesign(x, 10000);"},{"id":438,"pagetitle":"Overview: Onset types","title":"UniformOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#UniformOnset","content":" UniformOnset The  UniformOnset  is based on a uniform distribution and has two parameters:  width  and  offset . Example: onset_uniform = UniformOnset(; width = 50, offset = 0); The  width  parameter defines the upper bound of the interval of the uniform distribution (its lower bound is 0) i.e. all values between 0 and  width  are equally probable. The  offset  parameter determines the minimal distance between two events and its value is added to the value sampled from the uniform distribution i.e. it shifts the distribution. Its default value is  0 , i.e. no offset. In the figure below, it is illustrated how the onset distribution changes when changing one of its parameters. Click to show the code for the figure above let\n    f = Figure()\n\n    # Define parameter combinations\n    parameters = [(((50, 0), (80, 0)), \"width\"), (((50, 0), (50, 20)), \"offset\")]\n\n    axes_list = Array{Any}(undef, length(parameters))\n\n    # Create a subplot for each parameter i.e. one for width and one for offset\n    for (index, (combinations, label)) in enumerate(parameters)\n        ax = Axis(f[index, 1], title = \"Parameter: $label\")\n        axes_list[index] = ax\n\n        # Go through all parameter combinations and plot a histogram of the sampled onsets\n        for (width, offset) in combinations\n            onsets = UnfoldSim.simulate_interonset_distances(\n                MersenneTwister(42),\n                UniformOnset(; width = width, offset = offset),\n                design,\n            )\n\n            hist!(ax, onsets, bins = range(0, 100, step = 1), label = \"($width, $offset)\")\n\n            if label == \"offset\" && offset != 0\n                vlines!(offset, color = \"black\")\n            end\n        end\n        hideydecorations!(ax)\n        hidespines!(ax, :t, :r)\n        axislegend(\n            ax,\n            framevisible = false,\n            labelsize = 12,\n            markersize = 5,\n            patchsize = (10, 10),\n        )\n    end\n    axes_list[end].xlabel = \"Time between events [samples]\"\n    linkyaxes!(axes_list...)\nend"},{"id":439,"pagetitle":"Overview: Onset types","title":"LogNormalOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#LogNormalOnset","content":" LogNormalOnset The  LogNormalOnset  is based on a log-normal distribution and has four parameters:  μ ,  σ ,  offset  and  truncate_upper . Example: onset_lognormal = LogNormalOnset(; μ = 3, σ = 0.25, offset = 0, truncate_upper = nothing); The parameters  μ  and  σ  are the location and scale parameter of the log-normal distribution. However, they are not identical to its mean and standard deviation. If a variable  $X$  is log-normally distributed then  $Y = ln(X)$  is normally distributed with mean  μ  and standard deviation  σ [1] . The  offset  parameter determines the minimal distance between two events and its value is added to the value sampled from the log-normal distribution i.e. it shifts the distribution. Its default value is  0 , i.e. no offset. The  truncate_upper  parameter allows to truncate the distribution at a certain sample value. Its default value is  nothing , i.e. no truncation. In the figure below, it is illustrated how the onset distribution changes when changing one of its parameters. Click to show the code for the figure above let\n    f = Figure(size = (600, 800))\n\n    # Define parameter combinations\n    parameters = [\n        (((3, 0.25, 0, nothing), (2.5, 0.25, 0, nothing)), \"μ\"),\n        (((3, 0.25, 0, nothing), (3, 0.35, 0, nothing)), \"σ\"),\n        (((3, 0.25, 0, nothing), (3, 0.25, 30, nothing)), \"offset\"),\n        (((3, 0.25, 0, nothing), (3, 0.25, 0, 25)), \"truncate_upper\"),\n    ]\n\n    axes_list = Array{Any}(undef, length(parameters))\n\n    # Create a subplot for each parameter i.e. one for μ, one for σ etc\n    for (index, (combinations, label)) in enumerate(parameters)\n        ax = Axis(f[index, 1], title = \"Parameter: $label\")\n        axes_list[index] = ax\n\n        # Go through all parameter combinations and plot a histogram of the sampled onsets\n        for (μ, σ, offset, truncate_upper) in combinations\n            onsets = UnfoldSim.simulate_interonset_distances(\n                MersenneTwister(42),\n                LogNormalOnset(;\n                    μ = μ,\n                    σ = σ,\n                    offset = offset,\n                    truncate_upper = truncate_upper,\n                ),\n                design,\n            )\n\n            hist!(\n                ax,\n                onsets,\n                bins = range(0, 100, step = 1),\n                label = \"($μ,$σ,$offset,$truncate_upper)\",\n            )\n\n            if label == \"offset\" && offset !== 0\n                vlines!(offset, color = \"black\")\n            elseif label == \"truncate_upper\" && truncate_upper !== nothing\n                vlines!(truncate_upper, color = \"black\")\n            end\n        end\n        hideydecorations!(ax)\n        hidespines!(ax, :t, :r)\n        axislegend(\n            ax,\n            framevisible = false,\n            labelsize = 12,\n            markersize = 5,\n            patchsize = (10, 10),\n        )\n    end\n    axes_list[end].xlabel = \"Time between events [samples]\"\n    linkyaxes!(axes_list...)\nend"},{"id":440,"pagetitle":"Overview: Onset types","title":"Overlap of subsequent events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#Overlap-of-subsequent-events","content":" Overlap of subsequent events Note The overlap of subsequent events can be indirectly controlled by setting the  offset  parameter relative to the length of the component basis.   Assuming that  signal  is a component e.g.  LinearModelComponent , if  offset  >  length(signal.basis)  -> no overlap if  offset  <  length(signal.basis)  -> there might be overlap, depending on the other parameters of the onset distribution This page was generated using  Literate.jl . 1 Wikipedia contributors. (2023, December 5). Log-normal distribution. In Wikipedia, The Free Encyclopedia. Retrieved 12:27, December 7, 2023, from https://en.wikipedia.org/w/index.php?title=Log-normal_distribution&oldid=1188400077#"},{"id":443,"pagetitle":"Overview of functionality","title":"Overview of functionality","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Overview-of-functionality","content":" Overview of functionality A UnfoldSim simulation has four ingredients: Design, Component, Onset and Noise. Here we provide a short overview of the implemented types."},{"id":444,"pagetitle":"Overview of functionality","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing InteractiveUtils"},{"id":445,"pagetitle":"Overview of functionality","title":"Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Design","content":" Design Designs define the experimental design. They can be nested, e.g.  RepeatDesign(SingleSubjectDesign,10)  would repeat the generated design-dataframe 10x. subtypes(AbstractDesign) 3-element Vector{Any}:\n MultiSubjectDesign\n RepeatDesign\n SingleSubjectDesign"},{"id":446,"pagetitle":"Overview of functionality","title":"Component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Component","content":" Component Components define a signal. Some components can be nested, e.g.  LinearModelComponent|>MultichannelComponent , see the multi-channel tutorial for more information. subtypes(AbstractComponent) 3-element Vector{Any}:\n LinearModelComponent\n MixedModelComponent\n MultichannelComponent"},{"id":447,"pagetitle":"Overview of functionality","title":"Onsets","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Onsets","content":" Onsets Onsets define the distance between events in the continuous signal. subtypes(AbstractOnset) 3-element Vector{Any}:\n LogNormalOnset\n NoOnset\n UniformOnset"},{"id":448,"pagetitle":"Overview of functionality","title":"Noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Noise","content":" Noise Choose the noise you need! subtypes(AbstractNoise) 7-element Vector{Any}:\n ExponentialNoise\n NoNoise\n PinkNoise\n RedNoise\n UnfoldSim.AutoRegressiveNoise\n UnfoldSim.RealisticNoise\n WhiteNoise This page was generated using  Literate.jl ."},{"id":451,"pagetitle":"Multi-subject simulation","title":"Multi-subject simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Multi-subject-simulation","content":" Multi-subject simulation In this tutorial, you will learn how to simulate data for multiple subjects. In particular, you will learn how to specify fixed and random effects and what their influence on the simulated data looks like."},{"id":452,"pagetitle":"Multi-subject simulation","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Unfold\nusing CairoMakie\nusing UnfoldMakie\nusing DataFrames Similar to the single subject case, multi-subject simulation depends on: Design  (typically a  MultiSubjectDesign ) Components  (typically a  MixedModelComponent ) Onset  (any) Noise  (any)"},{"id":453,"pagetitle":"Multi-subject simulation","title":"Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Design","content":" Design Our first design should be 20 subjects, with 4 items each. Any individual image is shown only either as large or small, thus we choose  items_between . design = MultiSubjectDesign(\n    n_subjects = 20,\n    n_items = 4,\n    items_between = Dict(:condition => [\"large\", \"small\"]),\n) MultiSubjectDesign\n  n_subjects: Int64 20\n  n_items: Int64 4\n  subjects_between: Dict{Symbol, Vector}\n  items_between: Dict{Symbol, Vector}\n  both_within: Dict{Symbol, Vector}\n  event_order_function: #10 (function of type UnfoldSim.var\"#10#14\")\n"},{"id":454,"pagetitle":"Multi-subject simulation","title":"Between, within?","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Between,-within?","content":" Between, within? In the beginning, the distinction between  between-items ,  between-subjects  and  within-subjects ,  within-items  and  both-between ,  both-within  feels daunting. We base our terminology on  MixedModelsSim  which uses the following definitions: subjects_between  -> effects between subjects, e.g. young vs old items_between  -> effects between items, e.g. natural vs artificial images, (but shown to all subjects if not specified in subjects_between as well) both_within  -> effects completly crossed, e.g. word vs. scramble, where the \"original\" word is the item, and shown to all subjects"},{"id":455,"pagetitle":"Multi-subject simulation","title":"Components","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Components","content":" Components For multi-subject, similar to the  LinearModelComponent  specified before, we have to define the fixed effect  β , the model parameters that are applied to all subjects. β = [1, 2] # 1 = intercept, 2 = difference between large and small 2-element Vector{Int64}:\n 1\n 2 In addition, we have to provide random effects  σs , which define the spread (and  correlation) of the subjects around the fixed effects, foreach parameter σs = Dict(\n    :subject => [0.5, 1], # we have more spread in the condition-effect\n    :item => [1], # the item-variability is higher than the subject-variability\n) Dict{Symbol, Vector} with 2 entries:\n  :item    => [1]\n  :subject => [0.5, 1.0] now we are ready to assemble the parts signal = MixedModelComponent(;\n    basis = UnfoldSim.hanning(50),\n    formula = @formula(0 ~ 1 + condition + (1 + condition | subject) + (1 | item)),\n    β = β,\n    σs = σs,\n    contrasts = Dict(:condition => EffectsCoding()), # we highly recommend specifying your contrasts, by Default its Dummy/ReferenceCoding with alphabetically sorted levels (relying 100% on StatsModels.jl)\n) MixedModelComponent\n  basis: Array{Float64}((50,)) [0.0, 0.004104993088376974, 0.016352568480485274, 0.03654162132698918, 0.0643406479383053, 0.09929318906602175, 0.14082532495113625, 0.18825509907063326, 0.24080371584473748, 0.2976083284388031  …  0.2976083284388031, 0.24080371584473748, 0.18825509907063326, 0.14082532495113625, 0.09929318906602175, 0.0643406479383053, 0.03654162132698918, 0.016352568480485274, 0.004104993088376974, 0.0]\n  formula: StatsModels.FormulaTerm{StatsModels.ConstantTerm{Int64}, Tuple{StatsModels.ConstantTerm{Int64}, StatsModels.Term, StatsModels.FunctionTerm{typeof(|), Vector{StatsModels.AbstractTerm}}, StatsModels.FunctionTerm{typeof(|), Vector{StatsModels.AbstractTerm}}}}\n  β: Array{Int64}((2,)) [1, 2]\n  σs: Dict{Symbol, Vector}\n  contrasts: Dict{Symbol, EffectsCoding}\n and simulate! data, evts = simulate(design, signal, NoOnset(), NoNoise(), return_epoched = true); ┌ Warning:  No random generator defined, used the default (`Random.MersenneTwister(1)`) with a fixed seed. This will always return the same results and the user is strongly encouraged to provide their own random generator!\n └  @ UnfoldSim ~/work/UnfoldSim.jl/UnfoldSim.jl/src/simulation.jl:17 We get data with 50 samples (our  basis  from above), with  4  items and 20 subjects. We get items and subjects separately because we chose no-overlap (via  NoOnset ) and  return_epoched = true `. size(data)\n\nfirst(evts, 5) 5×3 DataFrame Row subject item condition String String String 1 S01 I1 large 2 S01 I2 small 3 S01 I3 large 4 S01 I4 small 5 S02 I1 large Finally, let's plot the data f = Figure()\n\nfor k = 1:4\n    series(\n        f[1, k],\n        data[:, k, :]',\n        solid_color = :black,\n        axis = (; limits = ((0, 50), (-5, 6))),\n    )\n    Label(f[1, k, Top()], text = \"Item:\" * evts[k, :item] * \", c:\" * evts[k, :condition])\nend\nf Some remarks on interpreting the plot: The β main-effect of small (#2 and #4) vs. large (#1 and #3) is clearly visible. The variability between subjects, is the variability between the individual curves. The item effect shows up e.g. that #2 vs. #4 column show different values."},{"id":456,"pagetitle":"Multi-subject simulation","title":"Continuous Signals / Overlap","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Continuous-Signals-/-Overlap","content":" Continuous Signals / Overlap Let's continue our tutorial and simulate overlapping signals instead. We replace the  NoOnset  with an  UniformOnset  with 20 to 70 samples between subsequent events.  We further remove the  return_epoched , because we want to have continuous data for now. data, evts = simulate(design, signal, UniformOnset(offset = 20, width = 50), NoNoise());\nsize(data) (275, 20) with the first dimension being continuous data, and the latter still the subjects. series(data', solid_color = :black) Each line is one subject, and it looks a bit unstructured, because the event-onsets are of course random for each subject. Note All subjects have the same sequence of trials, if you need to change this, specify a  event_order_function  in the  MultiSubjectDesign ."},{"id":457,"pagetitle":"Multi-subject simulation","title":"Analyzing these data with Unfold.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Analyzing-these-data-with-Unfold.jl","content":" Analyzing these data with Unfold.jl We will analyze these data using the  Unfold.jl  toolbox. While preliminary support for deconvolution (overlap correction) for mixed models is available, here we will not make use of it, but rather apply a MixedModel to each timepoint, following the Mass-univariate approach. data, evts = simulate(\n    design,\n    signal,\n    UniformOnset(offset = 20, width = 50),\n    NoNoise();\n    return_epoched = true,\n);\nsize(data) (50, 4, 20) For Unfold.jl, we have to reshape the data, so that all subjects are concatenated. data = reshape(data, size(data, 1), :)\ntimes = range(0, 1, length = size(data, 1))\nm = fit(\n    UnfoldModel,\n    @formula(0 ~ 1 + condition + (1 | item) + (1 + condition | subject)),\n    evts,\n    data,\n    times,\n)\nplot_erp(coeftable(m), mapping = (; col = :group)) The first column shows the fixed effects, the latter the item and subject random effects as they evolve across time This page was generated using  Literate.jl ."},{"id":460,"pagetitle":"Power analysis","title":"Power analysis","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/poweranalysis/#Power-analysis","content":" Power analysis For a power analysis, we will repeatedly simulate data, and check whether we can find a significant effect. We perform the power analysis on epoched data."},{"id":461,"pagetitle":"Power analysis","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/poweranalysis/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Statistics\nusing HypothesisTests\nusing DataFrames\nusing Random"},{"id":462,"pagetitle":"Power analysis","title":"Simulation loop","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/poweranalysis/#Simulation-loop","content":" Simulation loop pvals = fill(NaN, 100)\n@time for seed in eachindex(pvals)\n    # Simulate data of 30 subjects\n    data, evts = UnfoldSim.predef_2x2(\n        MersenneTwister(seed);\n        n_subjects = 20, ## 30 subjects\n        overlap = (1, 0), ## deactivate overlap\n        noiselevel = 10,  ## add more noise to make it more challenging\n        return_epoched = true, ## saves us the epoching step\n    )\n\n\n    # take the mean over a pre-specified timewindow\n    evts.y = dropdims(mean(data[40:60, :, :], dims = 1), dims = (1))[:]\n\n    # extract the two levels of condition A\n    evts_reduced = combine(groupby(evts, [:subject, :A]), :y => mean)\n    y_big = evts_reduced[evts_reduced.A.==\"a_big\", :y_mean]\n    y_small = evts_reduced[evts_reduced.A.==\"a_small\", :y_mean]\n\n    # calculate a one-sided t-test\n    pvals[seed] = pvalue(OneSampleTTest(y_big, y_small))\nend  11.866674 seconds (22.77 M allocations: 3.059 GiB, 8.84% gc time, 80.05% compilation time: 14% of which was recompilation) Let's calculate the power power = mean(pvals .< 0.05) * 100 61.0 This page was generated using  Literate.jl ."},{"id":465,"pagetitle":"Quickstart","title":"Quickstart","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Quickstart","content":" Quickstart To get started with data simulation, the user needs to provide four ingredients: an experimental design, defining which conditions and how many events/\"trials\" exist an event basis function, defining the simulated event-related response for every event (e.g. the ERP shape in EEG) an inter-onset event distribution, defining the distances in time of the event sequence a noise specification, defining the type of noise signal that is added to the simulated signal (e.g. pink noise) Tip Use  subtypes(AbstractNoise)  (or  subtypes(AbstractComponent)  etc.) to find already implemented building blocks."},{"id":466,"pagetitle":"Quickstart","title":"Specify the simulation ingredients","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Specify-the-simulation-ingredients","content":" Specify the simulation ingredients"},{"id":467,"pagetitle":"Quickstart","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Random # to get an RNG\nusing CairoMakie # for plotting"},{"id":468,"pagetitle":"Quickstart","title":"Experimental Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Experimental-Design","content":" Experimental Design Define a 1 x 2 design with 20 trials. That is, one condition ( cond_A ) with two levels. design =\n    SingleSubjectDesign(; conditions = Dict(:cond_A => [\"level_A\", \"level_B\"])) |>\n    x -> RepeatDesign(x, 10);"},{"id":469,"pagetitle":"Quickstart","title":"Event basis function (Component)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Event-basis-function-(Component)","content":" Event basis function (Component) Define a simple component and ground truth simulation formula. Akin to ERP components, we call one simulation signal a component. Note You could easily specify multiple components by providing a vector of components, which are automatically added at the same onsets. This procedure simplifies to generate some response that is independent of simulated condition, whereas other depends on it. signal = LinearModelComponent(;\n    basis = [0, 0, 0, 0.5, 1, 1, 0.5, 0, 0],\n    formula = @formula(0 ~ 1 + cond_A),\n    β = [1, 0.5],\n);"},{"id":470,"pagetitle":"Quickstart","title":"Onsets and Noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Onsets-and-Noise","content":" Onsets and Noise We will start with a uniform (but overlapping,  offset  <  length(signal.basis) ) inter-onset distribution. onset = UniformOnset(; width = 20, offset = 4); And we will use some noise noise = PinkNoise(; noiselevel = 0.2);"},{"id":471,"pagetitle":"Quickstart","title":"Combine & Generate","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Combine-and-Generate","content":" Combine & Generate Finally, we will combine all ingredients and simulate some data. data, events = simulate(MersenneTwister(1), design, signal, onset, noise); data  is a  n-sample  Vector (but could be a Matrix for e.g.  MultiSubjectDesign  or epoched data). events  is a DataFrame that contains a column  latency  with the onsets of events (in samples)."},{"id":472,"pagetitle":"Quickstart","title":"Plot them!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Plot-them!","content":" Plot them! lines(data; color = \"black\")\nvlines!(events.latency; color = [\"orange\", \"teal\"][1 .+ (events.cond_A.==\"level_B\")])\n\ncurrent_axis().title = \"Simulated data\"\ncurrent_axis().xlabel = \"Time [samples]\"\ncurrent_axis().ylabel = \"Amplitude [μV]\"\n\ncurrent_figure() This page was generated using  Literate.jl ."},{"id":475,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Simulate event-related potentials (ERPs)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Simulate-event-related-potentials-(ERPs)","content":" Simulate event-related potentials (ERPs) One subfield of EEG research focuses on so-called event-related potentials (ERPs) which are defined as brain responses time-locked to a certain event e.g. stimulus onset. The waveform of an ERP usually consists of multiple ERP components which denote the peaks and troughs of the waveform. ERP components are characterized (and named) by their timing relative to the event, their polarity (positive or negative) and their scalp topography. For example, the N170 describes a negative deflection which occurrs roughly 170 ms after the onset of (certain) visual stimuli. Often, researchers are interested how a component (e.g. its amplitude or timing) changes depending on certain experimental factors. For example, N170 has been shown to be related to face processing and its amplitude is modulated by whether the stimulus is a face or an object e.g. a car. ( Source ) Here we will learn how to simulate a typical ERP complex with P100, N170, P300."},{"id":476,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim # For simulation\nusing Random # For randomization\nusing StableRNGs # To get an RNG\nusing Unfold # For analysis\nusing CairoMakie # For plotting\nusing UnfoldMakie # For plotting"},{"id":477,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Specify the simulation \"ingredients\"","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Specify-the-simulation-\"ingredients\"","content":" Specify the simulation \"ingredients\""},{"id":478,"pagetitle":"Simulate event-related potentials (ERPs)","title":"1. Experimental design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#1.-Experimental-design","content":" 1. Experimental design We specify an experimental design with one subject in two experimental conditions including a continuous variable with 10 values. To mimic randomization in an experiment, we shuffle the trials using the  event_order_function  argument. To generate more trials we repeat the design 100 times which results in 2000 trials in total. design =\n    SingleSubjectDesign(;\n        conditions = Dict(\n            :condition => [\"car\", \"face\"],\n            :continuous => range(0, 5, length = 10),\n        ),\n        event_order_function = shuffle,\n    ) |> x -> RepeatDesign(x, 100); The  generate_events  function can be used to create an events data frame from the specified experimental design. events_df = generate_events(StableRNG(1), design);\nfirst(events_df, 5) 5×2 DataFrame Row continuous condition Float64 String 1 2.22222 face 2 4.44444 car 3 3.88889 car 4 1.11111 car 5 0.555556 car Above you can see the first five rows extracted from the events data frame representing the experimental design. Each row corresponds to one event. The columns  continuous  and  condition  display the levels of the predictor variables for the specific event."},{"id":479,"pagetitle":"Simulate event-related potentials (ERPs)","title":"2. Event basis functions (Components)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#2.-Event-basis-functions-(Components)","content":" 2. Event basis functions (Components) Next, we create a signal consisting of three different components. For the first component, we use the prespecified  P100  base which will be unaffected by our design and has an amplitude of 5 µV. p1 = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1), β = [5]); For the second component, we use the prespecified  N170  base with an intercept of 5 µV and a condition effect of 3 µV for the “face/car” condition i.e. faces will have a more negative signal than cars. n1 = LinearModelComponent(;\n    basis = n170(),\n    formula = @formula(0 ~ 1 + condition),\n    β = [5, 3],\n); For the third component, we use the prespecified  P300  base and include a linear and a quadratic effect of the continuous variable: the larger the value of the continuous variable, the larger the simulated potential. p3 = LinearModelComponent(;\n    basis = p300(),\n    formula = @formula(0 ~ 1 + continuous + continuous^2),\n    β = [5, 1, 0.2],\n);"},{"id":480,"pagetitle":"Simulate event-related potentials (ERPs)","title":"3. Inter-onset distribution","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#3.-Inter-onset-distribution","content":" 3. Inter-onset distribution In the next step, we specify an inter-onset distribution, in this case, a uniform distribution with an inter-event distance of exactly 200 samples. onset = UniformOnset(; width = 0, offset = 200);"},{"id":481,"pagetitle":"Simulate event-related potentials (ERPs)","title":"4. Noise specification","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#4.-Noise-specification","content":" 4. Noise specification As the last ingredient, we specify the  noise , in this case, Pink noise. noise = PinkNoise(; noiselevel = 2);"},{"id":482,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Simulate data","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Simulate-data","content":" Simulate data Finally, we combine all the ingredients and simulate data. To make the simulation reproducible, one can specify a random generator. # Combine the components in a vector\ncomponents = [p1, n1, p3]\n\n# Simulate data\neeg_data, events_df = simulate(StableRNG(1), design, components, onset, noise); To inspect the simulated data we will visualize the first 1400 samples. Click to show the code for the figure below f = Figure(size = (1000, 400))\nax = Axis(\n    f[1, 1],\n    title = \"Simulated EEG data\",\n    titlesize = 18,\n    xlabel = \"Time [samples]\",\n    ylabel = \"Amplitude [µV]\",\n    xlabelsize = 16,\n    ylabelsize = 16,\n    xgridvisible = false,\n    ygridvisible = false,\n)\n\nn_samples = 1400\nlines!(eeg_data[1:n_samples]; color = \"black\")\nv_lines = [\n    vlines!(\n        [r[\"latency\"]];\n        color = [\"orange\", \"teal\"][1+(r[\"condition\"]==\"car\")],\n        label = r[\"condition\"],\n    ) for r in\n    filter(:latency => x -> x < n_samples, events_df)[:, [\"latency\", \"condition\"]] |>\n    eachrow\n]\nxlims!(ax, 0, n_samples)\naxislegend(\"Event onset\"; unique = true); current_figure() The vertical lines denote the event onsets and their colour represents the respective condition i.e. car or face."},{"id":483,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Validate the simulation results","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Validate-the-simulation-results","content":" Validate the simulation results To validate the simulation results, we use the  Unfold.jl  package  to fit an Unfold regression model to the simulated data and examine the estimated regression parameters and marginal effects. For the formula, we include a categorical predictor for  condition  and a non-linear predictor (based on splines) for  continuous . m = fit(\n    UnfoldModel,\n    [\n        Any => (\n            @formula(0 ~ 1 + condition + spl(continuous, 4)),\n            firbasis(τ = [-0.1, 1], sfreq = 100, name = \"basis\"),\n        ),\n    ],\n    events_df,\n    eeg_data,\n); To inspect the modelling results we will visualize the model coefficient estimates together with the estimated marginal effects i.e. the predicted ERPs. Click to show the code for the figure below # Create a data frame with the model coefficients and extract the coefficient names\ncoefs = coeftable(m)\ncoefnames = unique(coefs.coefname)\n\nf2 = Figure(size = (1000, 400))\nga = f2[1, 1] = GridLayout()\ngb = f2[1, 2] = GridLayout()\n\n# Plot A: Estimated regression parameters\nax_A = Axis(\n    ga[1, 1],\n    title = \"Estimated regression parameters\",\n    titlegap = 12,\n    xlabel = \"Time [s]\",\n    ylabel = \"Amplitude [μV]\",\n    xlabelsize = 16,\n    ylabelsize = 16,\n    xgridvisible = false,\n    ygridvisible = false,\n)\n\nfor coef in coefnames\n    estimate = filter(:coefname => ==(coef), coefs)\n\n    lines!(ax_A, estimate.time, estimate.estimate, label = coef)\nend\naxislegend(\"Coefficient\", framevisible = false)\nhidespines!(ax_A, :t, :r)\n\n# Plot B: Marginal effects\nplot_B = plot_erp!(\n    gb,\n    effects(Dict(:condition => [\"car\", \"face\"], :continuous => 0:0.5:5), m);\n    mapping = (; color = :continuous, linestyle = :condition, group = :continuous),\n    legend = (; valign = :top, halign = :right),\n    axis = (\n        title = \"Marginal effects\",\n        titlegap = 12,\n        xlabel = \"Time [s]\",\n        ylabel = \"Amplitude [μV]\",\n        xlabelsize = 16,\n        ylabelsize = 16,\n        xgridvisible = false,\n        ygridvisible = false,\n    ),\n)\n\n# Add letter labels to the plots\n# Adapted from: https://docs.makie.org/stable/tutorials/layout-tutorial/\nfor (label, layout) in zip([\"A\", \"B\"], [ga, gb])\n    Label(\n        layout[1, 1, TopLeft()],\n        label,\n        fontsize = 26,\n        font = :bold,\n        padding = (0, 5, 5, 0),\n        halign = :right,\n    )\nend current_figure() In subplot A, one can see the model coefficient estimates and as intended the first component is unaffected by the experimental design, there is a condition effect in the second component and an effect of the continuous variable on the third component. The relation between the levels of the continuous variable and the scaling of the third component is even clearer visible in subplot B which depicts the estimated marginal effects of the predictors which are obtained by evaluating the estimated function at specific values of the continuous variable. As shown in this example,  UnfoldSim.jl  and  Unfold.jl  can be easily combined to investigate the effects of certain features, e.g. the type of noise or its intensity on the analysis result and thereby assess the robustness of the analysis. This page was generated using  Literate.jl ."},{"id":486,"pagetitle":"Installing Julia & UnfoldSim.jl","title":"Installing Julia & UnfoldSim.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/installation/#Installing-Julia-and-UnfoldSim.jl","content":" Installing Julia & UnfoldSim.jl"},{"id":487,"pagetitle":"Installing Julia & UnfoldSim.jl","title":"Installing Julia","ref":"/UnfoldDocs/UnfoldSim.jl/stable/installation/#Installing-Julia","content":" Installing Julia The recommended way to install julia is  juliaup . TL;DR: If you don't want to read the explicit instructions, just copy the following command: Windows:  winget install julia -s msstore Mac/Linux:  curl -fsSL https://install.julialang.org | sh We further recommend to use  VSCode  and install the  Julia Extension ."},{"id":488,"pagetitle":"Installing Julia & UnfoldSim.jl","title":"Installing UnfoldSim.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/installation/#Installing-UnfoldSim.jl","content":" Installing UnfoldSim.jl The following instructions are intended for Julia beginners. More advanced Julia users can jump ahead to step 3."},{"id":489,"pagetitle":"Installing Julia & UnfoldSim.jl","title":"1. Start an interactive Julia session (\"REPL\")","ref":"/UnfoldDocs/UnfoldSim.jl/stable/installation/#1.-Start-an-interactive-Julia-session-(\"REPL\")","content":" 1. Start an interactive Julia session (\"REPL\") Option 1: Type  julia  in the command line. Option 2: In VSCode, press  Ctrl + Shift + P  to open the command palette and type in  Julia: Start REPL ."},{"id":490,"pagetitle":"Installing Julia & UnfoldSim.jl","title":"2. Activate your project environment","ref":"/UnfoldDocs/UnfoldSim.jl/stable/installation/#2.-Activate-your-project-environment","content":" 2. Activate your project environment Before installing UnfoldSim.jl make sure that you activated your project environment. Option 1:  cd(\"/path/to/your/project\")  and  ]activate . Option 2:  ]activate /path/to/your/project/ Hint After activating you should see  (environment) pkg>  (where  environment  is the name of your project folder). If you see  (@v1.11) pkg>  instead, you still have to activate your environment. Note that by typing  ]  you enter the Julia package manager. To get back to the Julia REPL, press backspace."},{"id":491,"pagetitle":"Installing Julia & UnfoldSim.jl","title":"3. Install the UnfoldSim.jl package","ref":"/UnfoldDocs/UnfoldSim.jl/stable/installation/#3.-Install-the-UnfoldSim.jl-package","content":" 3. Install the UnfoldSim.jl package If you are not in the package manager anymore, type  ] . Then type  add UnfoldSim . After the installation is finished you can use  using UnfoldSim  in the REPL to import the package."}]