[{"id":3,"pagetitle":"Unfold Documentation","title":"Unfold Documentation","ref":"/UnfoldDocs/Unfold.jl/stable/#Unfold-Documentation","content":" Unfold Documentation If you want to follow the  tutorials , best to start with the  mass-univariate approach , which should be familiar to you if you did ERPs before. Then the  overlap-correction tutorial ,  mixed mass univariate ,  mixed overlap (tricky!) . If you are then not satisfied, check out more advanced topics:  effects-interface (aka what to do after fitting) , or non-linear effects. In case you want to understand the tools better, check out our  explanations . Once you are familiar with the tools, check out further  how-to guides  for specific applications. In case you want to understand the toolbox better, we plan to offer  technical references . This includes Benchmarks & Explorations."},{"id":4,"pagetitle":"Unfold Documentation","title":"Quick start","ref":"/UnfoldDocs/Unfold.jl/stable/#Quick-start","content":" Quick start There are four main model types  Timeexpansion  No , Mixed  No   :  fit(UnfoldModel, [Any=>(f, -0.1:0.01:0.5)], evts, data_epoch) Timeexpansion  Yes , Mixed  No  :  fit(UnfoldModel, [Any=>(f, basisfunction)], evts, data) Timeexpansion  No , Mixed  Yes  :  fit(UnfoldModel, [Any=>(fLMM, -0.1:0.01:0.5)], evts, data_epoch) Timeexpansion  Yes , Mixed  Yes :  fit(UnfoldModel, [Any=>(fLMM, basisfunction)], evts, data) f = @formula 0 ~ 1 + condition\nfLMM = @formula 0 ~ 1 + condition + (1|subject) + (1|item)\nbasisfunction = firbasis(τ = (-0.1,0.5), sfreq = 100))"},{"id":7,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Alternative Solvers","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#custom_solvers","content":" Alternative Solvers A solver takes an Unfold-specified DesignMatrix and the data, and typically solves the equation system  y = Xb  (in the case of Linear Models). There are many different ways how one can approach this problem, depending if the matrix is sparse, if it is 2D or 3D, if one wants to use GPU etc. Most implemented solvers ultimately make use of  solver_main  for their main loop. See the  reference  tutorial for more information if that is interesting to you."},{"id":8,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Setup some data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#Setup-some-data","content":" Setup some data using Unfold\nusing UnfoldMakie, CairoMakie\nusing UnfoldSim\ndat, evts = UnfoldSim.predef_eeg(; noiselevel = 10, return_epoched = true)\n\nf = @formula 0 ~ 1 + condition + continuous\ndesignDict = Dict(Any => (f, range(0, 1, length = size(dat, 1))))"},{"id":9,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"GPU Solvers","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#GPU-Solvers","content":" GPU Solvers GPU solvers can significantly speed up your model fitting, with observed improvements of up to a factor of 30-100!"},{"id":10,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"fastest GPU solver","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#fastest-GPU-solver","content":" fastest GPU solver Empirically we found that solving  X'Xb = X'y  is the fastest way to solve for  b . To achieve this, you can run: using CUDA\ngpu_solver =(x, y) -> Unfold.solver_predefined(x, y; solver=:qr)\nm = Unfold.fit(UnfoldModel, designDict, evts, cu(dat), solver = gpu_solver) Where the  cu  is the magic that moves the data to the GPU. Internatlly, the solver function will move the matrix as well and pre-calculate some matrices (especially  X'X ,  X'  and allocate  X'y ). "},{"id":11,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"lsmr GPU solver","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#lsmr-GPU-solver","content":" lsmr GPU solver the  Krylov.lsmr  implementation directly solves  y = Xb , but allows for running on the GPU. using Krylov, CUDA # necessary to load the right package extension\ngpu_solver =(x, y) -> Unfold.solver_krylov(x, y; GPU = true)\nm = Unfold.fit(UnfoldModel, designDict, evts, dat, solver = gpu_solver) To test it, you will need to run it yourself as we cannot run it on the docs. If you require a different graphicscard vendor than NVIDA/CUDA, please create an issue. Currently, we are unable to test it due to lack of hardware."},{"id":12,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Robust Solvers","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#Robust-Solvers","content":" Robust Solvers Robust solvers automatically adjust for outlier trials, but they come at a significant computational cost. using RobustModels # necessary to load the Unfold package extension\nse_solver = (x, y) -> Unfold.solver_robust(x, y)\nm = Unfold.fit(UnfoldModel, designDict, evts, dat, solver = se_solver)\nresults = coeftable(m)\nplot_erp(results; stderror = true)"},{"id":13,"pagetitle":"Alternative Solvers (Robust, GPU, B2B)","title":"Back2Back regression","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/custom_solvers/#Back2Back-regression","content":" Back2Back regression b2b_solver = (x, y) -> Unfold.solver_b2b(x, y; ross_val_reps = 5)\ndat_3d = permutedims(repeat(dat, 1, 1, 20), [3 1 2])\nm = Unfold.fit(UnfoldModel, designDict, evts, dat_3d; solver = b2b_solver)\nresults = coeftable(m)\n\nplot_erp(results) These are the decoding results for  conditionA  while considering  conditionB , and vice versa. "},{"id":16,"pagetitle":"P-values for mixedModels","title":"How To get P-Values for Mass-Univariate LMM","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#lmm_pvalues","content":" How To get P-Values for Mass-Univariate LMM There are currently two ways to obtain p-values for LMMs: Wald's t-test and likelihood ratio tests (mass univariate only)."},{"id":17,"pagetitle":"P-values for mixedModels","title":"Setup","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Setup","content":" Setup using MixedModels, Unfold # we require to load MixedModels to load the PackageExtension\nusing DataFrames\nusing UnfoldSim\nusing CairoMakie\ndata_epoch, evts =\n    UnfoldSim.predef_2x2(; n_items = 52, n_subjects = 40, return_epoched = true)\ndata_epoch = reshape(data_epoch, size(data_epoch, 1), :) #\ntimes = range(0, 1, length = size(data_epoch, 1)) 0.0:0.010101010101010102:1.0"},{"id":18,"pagetitle":"P-values for mixedModels","title":"Define f0 & f1 and fit!","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Define-f0-and-f1-and-fit!","content":" Define f0 & f1 and fit! f0 = @formula 0 ~ 1 + A + (1 + A | subject);\nf1 = @formula 0 ~ 1 + A + B + (1 + A | subject); # could also differ in random effects\n\nm0 = fit(UnfoldModel,[Any=>(f0,times)],evts,data_epoch);\nm1 = fit(UnfoldModel,[Any=>(f1,times)],evts,data_epoch);"},{"id":19,"pagetitle":"P-values for mixedModels","title":"Likelihood ratio","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Likelihood-ratio","content":" Likelihood ratio uf_lrt = likelihoodratiotest(data_epoch, m0, m1)\nuf_lrt[1] model-dof deviance χ² χ²-dof P(>χ²) �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 6 8012 �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m B �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 7 8011 1 1 0.3996 As you can see, we have some likelihood ratio outcomes, exciting!"},{"id":20,"pagetitle":"P-values for mixedModels","title":"Extract p-values","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Extract-p-values","content":" Extract p-values pvalues(uf_lrt) 100-element Vector{Vector{Float64}}:\n [0.39964251754876706]\n [0.4019640858609401]\n [0.4074237173863722]\n [0.4070454519554564]\n [0.42228971014118033]\n [0.483155056260971]\n [0.6339437552710293]\n [NaN]\n [NaN]\n [NaN]\n ⋮\n [0.34292883003473407]\n [0.33515969561309156]\n [0.33325396532570495]\n [0.3428036624385943]\n [0.3567742512609538]\n [0.37049189795207205]\n [0.38051461402659575]\n [0.3883891630406846]\n [0.39851721772119286] We have extracted the p-values and now need to make them usable.     The solution can be found in the documentation under  ?pvalues . pvals_lrt = vcat(pvalues(uf_lrt)...)\nnchan = 1\nntime = length(times)\nreshape(pvals_lrt, ntime, nchan)' # note the last transpose via ' ! 1×100 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.399643  0.401964  0.407424  0.407045  …  0.380515  0.388389  0.398517 Perfecto, these are the LRT p-values of a model  condA  vs.  condA+condB  with same random effect structure."},{"id":21,"pagetitle":"P-values for mixedModels","title":"Walds T-Test","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Walds-T-Test","content":" Walds T-Test This method is easier to calculate but has limitations in accuracy and scope. It may also be less accurate due to the liberal estimation of degrees of freedom. Testing is limited in this case, as random effects cannot be tested and only single predictors can be used, which may not be appropriate for spline effects. It is important to note that this discussion is beyond the scope of this LMM package.  res = coeftable(m1)\n# only fixed effects: what is not in a ranef group is a fixef.\nres = res[isnothing.(res.group), :]\n# calculate t-value\nres[:, :tvalue] = res.estimate ./ res.stderror 300-element Vector{Float64}:\n  4.446708326696426\n  4.437580860011641\n  4.446435058073349\n  4.492672997803976\n  4.494599457419684\n  4.4880483252027075\n  4.439652303422133\n  4.45518635490581\n  4.623068236549389\n  4.663764726700654\n  ⋮\n  0.5870708293447756\n  0.43759939804174963\n  0.2172917074185397\n  0.025591530320948425\n -0.11195974844949615\n -0.28040792854804225\n -0.22668554132390997\n -0.2646530795209725\n -0.3492299276363734 We obtained Walds t, but how to translate them to a p-value? Determining the necessary degrees of freedom for the t-distribution is a complex issue with much debate surrounding it.  One approach is to use the number of subjects as an upper bound for the p-value (your df will be between  $n_{subject}$  and  $\\sum{n_{trials}}$ ). df = length(unique(evts.subject)) 40 Plug it into the t-distribution.  using Distributions\nres.pvalue = pdf.(TDist(df),res.tvalue) 300-element Vector{Float64}:\n 0.00010520592926163251\n 0.00010817494439425095\n 0.00010529365405567558\n 9.142141916777313e-5\n 9.088393516836884e-5\n 9.272440215982806e-5\n 0.00010749405443829126\n 0.00010251943544603832\n 6.122445474960627e-5\n 5.398423858898151e-5\n ⋮\n 0.33251660178615255\n 0.3594809847897533\n 0.38698410798874533\n 0.39632387743397085\n 0.39391857391788004\n 0.38081351375847516\n 0.38615884540577883\n 0.3824900521283194\n 0.37247026276880874"},{"id":22,"pagetitle":"P-values for mixedModels","title":"Comparison of methods","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/lmm_pvalues/#Comparison-of-methods","content":" Comparison of methods Cool! Let's compare both methods of p-value calculation! df = DataFrame(:walds => res[res.coefname.==\"B: b_tiny\", :pvalue], :lrt => pvals_lrt)\nf = Figure()\n\nscatter(f[1,1],times,res[res.coefname .== \"B: b_tiny\",:estimate],axis=(;xlabel=\"time\",title=\"coef: B:b_tiny\"))\nscatter(f[1,2],df.walds,df.lrt,axis=(;title=\"walds-t pvalue\",ylabel=\"LRT pvalue\"))\nscatter(f[2,1],times,df.walds,axis=(;title=\"walds-t pvalue\",xlabel=\"time\"))\nscatter(f[2,2],times,df.lrt,axis=(;title=\"lrt pvalue\",xlabel=\"time\"))\n\nf Look pretty similar! Note that the Walds-T is typically too liberal (LRT also, but to a lesser exted). Best is to use the forthcoming MixedModelsPermutations.jl or go the route via R and use KenwardRoger (data not yet published)"},{"id":25,"pagetitle":"Overlap: Multiple events","title":"How to model multiple events","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/multiple_events/#How-to-model-multiple-events","content":" How to model multiple events When dealing with overlapping data, it is often necessary to model multiple eventtypes (e.g. fixations, stimuli, responses)."},{"id":26,"pagetitle":"Overlap: Multiple events","title":"Load Example Data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/multiple_events/#Load-Example-Data","content":" Load Example Data using Unfold\nusing UnfoldMakie, CairoMakie\nusing DataFrames\nusing StatsModels\nusing MixedModels\n\ninclude(joinpath(dirname(pathof(Unfold)), \"../test/test_utilities.jl\")) # to load data\ndat, evts = loadtestdata(\"test_case_4b\");\n\nevts[1:5,:] 5×3 DataFrame Row latency type intercept Int64 String7 Int64 1 38 eventA 1 2 50 eventB 1 3 89 eventA 1 4 102 eventB 1 5 144 eventA 1 The  type  column of table  evts  contains two conditions:  eventA and eventB (if your eventstypes are specified in a different column, you need to define the keywordargument eventcolumn in the fit` command below)"},{"id":27,"pagetitle":"Overlap: Multiple events","title":"Specify formulas and basisfunctions","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/multiple_events/#Specify-formulas-and-basisfunctions","content":" Specify formulas and basisfunctions bf1 = firbasis(τ = (-0.4, 0.8), sfreq = 50)\nbf2 = firbasis(τ = (-0.2, 1.2), sfreq = 50) For each event, a basis function and formula must be specified. The same basis and formulas may be used. f  = @formula 0 ~ 1 FormulaTerm\nResponse:\n  0\nPredictors:\n  1 For each event, we must specify the formula and basis function to be used.  bfDict = [ \"eventA\" => (f, bf1),\n           \"eventB\" => (f, bf2) ] Finally, fitting & plotting works the same way as always m = Unfold.fit(\n    UnfoldModel,\n    bfDict,\n    evts,\n    dat,\n    solver = (x, y) -> Unfold.solver_default(x, y; stderror = true),\n    eventcolumn = \"type\",\n)\nresults = coeftable(m)\nplot_erp(results; stderror = true, mapping = (; col = :eventname))"},{"id":30,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Loading Data into Unfold","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Loading-Data-into-Unfold","content":" Loading Data into Unfold Unfold is generally agnostic to how you load your data. You only require a Matrix (channel x time) or 3D-Array(channel x time x epochs) and an event-dataframe."},{"id":31,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Setup","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Setup","content":" Setup using Unfold\nusing UnfoldMakie,CairoMakie\nusing PyMNE\nusing DataFrames"},{"id":32,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"MNE Demo Dataset","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#MNE-Demo-Dataset","content":" MNE Demo Dataset The easiest way to showcase this is to simply use a demo-dataset from MNE. limo_epochs = PyMNE.datasets.limo.load_data(subject=1,path=\"~/MNE/DATA\",update_path=false)\nlimo_epochs Now we can fit a simple  Unfold  model to it.  First extract the data & convert it to Julia/Unfold requirements data = limo_epochs.get_data(picks=\"B11\")\ndata  = permutedims(data,[2,3,1]) # get into ch x times x epochs\n\nfunction convert_pandas(df_pd)\n      df= DataFrame()\n    for col in df_pd.columns\n        df[!, col] = getproperty(df_pd, col).values\n    end\n    return df\nend\nevents = convert_pandas(limo_epochs.metadata)\nrename!(events,2=>:coherence) # negative signs in formulas are not good ;)\nevents.face = string.(events.face) # ugly names, but fast\n Next fit an Unfold Model uf = fit(UnfoldModel,[Any=>(@formula(0~face+coherence),Float64.(limo_epochs.times))],events,data)\nresults = coeftable(uf) plot_results(results)"},{"id":33,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Read some of your own data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Read-some-of-your-own-data","content":" Read some of your own data We can make use of all PyMNE importer functions to load the data. Try it for your own data! Get starting with Unfold in no-time! #eeglabdata = PyMNE.io.read_raw_eeglab(\"pathToEEGLabSet.set\")"},{"id":34,"pagetitle":"Import EEG with 🐍 PyMNE.jl","title":"Contribute?","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/pymne/#Contribute?","content":" Contribute? Some extra conversions are needed to import the data from PyMNE to Unfold (as shown above). We could try putting these in a wrapper function - do you want to tackle this challenge? Would be a great first contribution to the toolbox :-)"},{"id":37,"pagetitle":"Standard errors","title":"Standard Errors","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/standarderrors/#standard_errors","content":" Standard Errors"},{"id":38,"pagetitle":"Standard errors","title":"Setup some data","ref":"/UnfoldDocs/Unfold.jl/stable/HowTo/standarderrors/#Setup-some-data","content":" Setup some data using Unfold\nusing UnfoldMakie, CairoMakie\nusing UnfoldSim\ndat, evts = UnfoldSim.predef_eeg(; noiselevel = 10, return_epoched = true)\n\nf = @formula 0 ~ 1 + condition + continuous\ndesignDict = Dict(Any => (f, range(0, 1, length = size(dat, 1)))) It is possible to specify a solver that calculates the standard errors of the estimates for a single subject as it possible for  custom solvers . se_solver = (x, y) -> Unfold.solver_default(x, y, stderror = true)\nm = Unfold.fit(UnfoldModel, designDict, evts, dat, solver = se_solver)\nresults = coeftable(m)\nplot_erp(results; stderror = true) Warning In case of overlap-correction:  Use single-subject standard errors on your own risk. EEG data is autocorrelated, which means that standard errors are typically too small."},{"id":41,"pagetitle":"About basisfunctions","title":"Basis Functions","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#Basis-Functions","content":" Basis Functions This document will give you an explanation of basis functions. We start with basis functions for fMRI because they are very popular."},{"id":42,"pagetitle":"About basisfunctions","title":"HRF / BOLD","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#HRF-/-BOLD","content":" HRF / BOLD We want to define a basis function. There are currently only few basisfunctions implemented in Unfold.jl, but your imagination knows no borders! We first have a look at the BOLD-HRF basisfunction aka  Blood Oxygenation Level Dependent Hemodynamic Response Function : using Unfold, DSP\n\nTR = 1.5 # the sampling rate\nbold = hrfbasis(TR) # using default SPM parameters\neventonset = 1.3\nbold_kernel = e -> Unfold.kernel(bold, e)\nlines(bold_kernel(eventonset)[:,1]) # returns a matrix, thus [:, 1] This is the shape that is assumed to reflect the activity for an event. Generally, we would like to know how much to scale this response shape per condition, e.g. in  condA  we might scale it by 0.7, in  condB  by 1.2. But let's start at the beginning and first simulate an fMRI signal. Then you will also appreciate why we need to deconvolve it later."},{"id":43,"pagetitle":"About basisfunctions","title":"Convolving a response shape to get a \"recorded\" fMRI signal","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#Convolving-a-response-shape-to-get-a-\"recorded\"-fMRI-signal","content":" Convolving a response shape to get a \"recorded\" fMRI signal We start by convolving this HRF function with an impulse vector at event onsets. y = zeros(100) # signal length = 100\ny[[10, 30, 45]] .= 0.7 # 3 events at given for condition A\ny[[37]] .= 1.2 # 1 events at given for condition B\n\ny_conv = conv(y, bold_kernel(0)) # convolve!\nlines(y_conv[:,1]) Next, we would add some noise: using Random\ny_conv += randn(size(y_conv))\nlines(y_conv[:,1]) 🎉 - we did it, we simulated fMRI data. Now you can see that the conditions overlap in time. To get back to the original amplitude values, we need to specify a basis function and use Unfold to deconvolve the signals. Note Events can fall between TR (the sampling rate). Some packages subsample the time signal, but in  Unfold  we can call the  bold.kernel  function directly at a given event time, which allows us to use non-TR multiples."},{"id":44,"pagetitle":"About basisfunctions","title":"FIR Basis Function","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/basisfunctions/#FIR-Basis-Function","content":" FIR Basis Function Okay, let's have a look at a different basis function: The FIR basisfunction. FIR stands for  Finite-Impulse-Response  and is a term taken from the filtering literature. basisfunction = firbasis(τ=(-0.4,.8), sfreq=50, name=\"myFIRbasis\")\nfir_kernel = e -> Unfold.kernel(basisfunction, e)\nm = fir_kernel(0)\nf = Figure()\nf[1,1] = Axis(f)\nfor col = 1:size(m, 2)\n    lines!(m[:,col])\nend\ncurrent_figure() The first thing to notice is that it is not a single basisfunction, but a set of basisfunctions. So every condition is explained by several basis functions! To make it clear better show it in 2D: fir_kernel(0)[1:10,1:10] 10×10 SparseArrays.SparseMatrixCSC{Int64, Int64} with 10 stored entries:\n 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1 (all  .  are  0 's) The FIR basis set consists of multiple basis functions. That is, each event is now  time-expanded  to multiple predictors, each with a certain time delay to the event onset. This allows us to model any linear overlap shape, and doesn't force us to make assumptions about the convolution kernel, as we had to do in the BOLD case."},{"id":47,"pagetitle":"Development environment","title":"Install a dev-version of Unfold","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/development/#Install-a-dev-version-of-Unfold","content":" Install a dev-version of Unfold In order to see and change the tutorials, you have to install a local dev-version of Unfold via: ]dev --local Unfold This clones the  git#main  into  ./dev/Unfold"},{"id":48,"pagetitle":"Development environment","title":"Instantiating the documentation environment","ref":"/UnfoldDocs/Unfold.jl/stable/explanations/development/#Instantiating-the-documentation-environment","content":" Instantiating the documentation environment To generate documentation, we recommend to install LiveServer.jl - then you can do: using LiveServer\nservedocs(skip_dirs=joinpath(\"docs\",\"src\",\"generated\"),literate_dir=joinpath(\"docs\",\"literate\")) If you prefer a one-off: activate the   ./docs  folder (be sure to  ]instantiate  the first time!) run  include(\"docs/make.jl\")"},{"id":53,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"Marginal effects","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#effects","content":" Marginal effects Marginal effect plots  are useful for understanding model fits. If you are an EEG researcher, you can think of the coefficients as the 'difference waves' and the (marginal) effects as the 'modelled ERP evaluated at a certain predictor value combination'. In some way, we are fitting a model with coefficients, receiving intercepts and slopes, and then try to recover the 'classical' ERPs in their \"data-domain\", typically with some effect adjustment, overlap removal, or similar."},{"id":54,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"Setup things","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#Setup-things","content":" Setup things Setup some packages using Unfold\nusing DataFrames\nusing Random\nusing CSV\nusing UnfoldMakie\nusing UnfoldSim\nusing UnfoldMakie Generate data and fit a model with a 2-level categorical predictor and a continuous predictor without interaction. data, evts = UnfoldSim.predef_eeg(; noiselevel = 8)\n\nbasisfunction = firbasis(τ = (-0.1, 0.5), sfreq = 100; interpolate = false)\n\nf = @formula 0 ~ 1 + condition + continuous # 1\n\nm = fit(UnfoldModel, [Any => (f, basisfunction)], evts, data, eventcolumn = \"type\") Plot the results plot_erp(coeftable(m))\n\n#=\nThe coefficients are represented by three lines on a figure:\n- the intercept showing the reference category for a typical p1/n1/p3 ERP components;\n- the slope of continuous variables with 1µV range;\n- the effect of categorical variabe with 3µV range.\n=#"},{"id":55,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"Effects function","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#Effects-function","content":" Effects function In order to better understand the actual predicted ERP curves, often researchers had to do manual contrasts. Remember that a linear model is  y = X * b , which allows (after  b  was estimated) to input a so-called  contrast  vector for X. You might know this in the form of  [1, 0, -1, 1]  or similar form. However, for larger models, this method can be prone to errors. The  effects  function is a convenient way to specify contrast vectors by providing the actual levels of the experimental design. It can be used to calculate all possible combinations of multiple variables. If a predictor-variable is not specified here, the function will automatically set it to its typical value. This value is usually the  mean , but for categorical variables, it could be something else. The R package  emmeans  has a lot of discussion on this topic. eff = effects(Dict(:condition => [\"car\", \"face\"]), m)\nplot_erp(eff; mapping = (; color = :condition,)) We can also generate continuous predictions: eff = effects(Dict(:continuous => -5:0.5:5), m)\nplot_erp(\n    eff;\n    mapping = (; color = :continuous, group = :continuous => nonnumeric),\n    categorical_color = false,\n    categorical_group = false,\n) Or we can split our marginal effects by condition and calculate all combinations \"automagically\". eff = effects(Dict(:condition => [\"car\", \"face\"], :continuous => -5:2:5), m)\nplot_erp(eff; mapping = (; color = :condition, col = :continuous))"},{"id":56,"pagetitle":"Marginal effects (focus on non-linear predictors)","title":"What is typical anyway?","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/effects/#What-is-typical-anyway?","content":" What is typical anyway? The  effects  function includes an argument called  typical , which specifies the function applied to the marginalized covariates/factors. The default value is  mean , which is usually sufficient for analysis. However, for skewed distributions, it may be more appropriate to use the  mode , while for outliers, the  median  or  winsor  mean may be more appropriate. To illustrate, we will use the  maximum  function on the  continuous  predictor. eff_max = effects(Dict(:condition => [\"car\", \"face\"]), m; typical = maximum)\neff_max.typical .= :maximum\neff = effects(Dict(:condition => [\"car\", \"face\"]), m)\neff.typical .= :mean # mean is the default\n\nplot_erp(vcat(eff, eff_max); mapping = (; color = :condition, col = :typical)) This page was generated using  Literate.jl ."},{"id":59,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Using Unfold.jl from Python","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Using-Unfold.jl-from-Python","content":" Using Unfold.jl from Python it is straight forward to call Unfold from Python using  JuliaCall ."},{"id":60,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Quick start","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Quick-start","content":" Quick start Create a Python environment and install JuliaCall. pip install juliacall Create a Julia environment and install Unfold # Import the Julia package manager\nfrom juliacall import Pkg as jlPkg\n\n# Activate the environment in the current folder\njlPkg.activate(\".\")\n\n# Install Unfold (in the activated environment)\njlPkg.add(\"Unfold\") Import Julia's main module and Unfold # Import Julia's Main module\nfrom juliacall import Main as jl\n\n# Import Unfold\n# The function seval() can be used to evaluate a piece of Julia code given as a string\njl.seval(\"using Unfold\")\nUnfold = jl.Unfold # simplify name Now you can use all Unfold functions as for example dummy_model = Unfold.UnfoldLinearModel(jl.Dict())"},{"id":61,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Example: Unfold model fitting from Python","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Example:-Unfold-model-fitting-from-Python","content":" Example: Unfold model fitting from Python In this  notebook , you can find a more detailed example of how to use Unfold from Python to load data, fit an Unfold model and visualise the results in Python."},{"id":62,"pagetitle":"🐍 Calling Unfold.jl directly from Python","title":"Important limitations","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/juliacall_unfold/#Important-limitations","content":" Important limitations Python doesnt not offer the full expressions that are available in Julia. So there are some things you need to give special attention: @formula : we havent found a way to call macros yet, even though we think it should be possible. For now please use  f = jl.seval(\"@formula(0~1+my+cool+design)\") . Later versions might support something like  f = @formula(\"0~1+my+cool+design)\"  directly Specifying the design : Since Unfold 0.7 we officially switched to the [\"eventtypeA\"=>(formula,basisfunction),\n\"eventtypeB\"=>(otherformula,otherbasisfunction)] Array-based syntax, from a Dict-based syntax. Unfortunately,  =>  (a pair) is not supported in Python and one needs to do some rewriting: jl.convert(jl.Pair,(formula,basisfunction)) which makes the code less readable. We are thinking of ways to remedy this - but right now there is now way around. For now, it is also possible to use the old syntax e.g. in python {\"eventtypeA\"=>(formula,basisfunction),\"eventtypeB\"=>(otherformula,otherbasisfunction)} which is clearly easier to read :) UnfoldSim.design : we need a  Dict  with a  Symbol  , one has to do something like  condition_dict_jl = {convert(jl.Symbol,\"condA\"):[\"car\", \"face\"]}  to do so. We will [try to allow strings}(https://github.com/unfoldtoolbox/UnfoldSim.jl/issues/96) here as well, removing this constraint. When preprocessing your raw data through MNE Python, take the following into consideration: The  Raw object  contains the  first_samp  attribute which is an integer representing the number of time samples that passed between the onset of the hardware acquisition system and the time when data recording started. The Raw data doesn't include these time samples, meaning that the first sample is the beginning of the data aquisition. From the Raw object you can obtain an events array from the annotations through  mne.events from annotations() . The events array, however, does include first samp, meaning that the annotated events in events array don't match the Raw object anymore. Alternatively, it might be easier to convert the annotations to a pandas dataframe directly (`to data frame()`), or even better, load the \"* events.tsv\" from a BIDS dataset. In the latter case, all columns will be preserved, which MNE's read_annotation drops. This page was generated using  Literate.jl ."},{"id":67,"pagetitle":"Save and load Unfold models","title":"Save and load Unfold models","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#unfold_io","content":" Save and load Unfold models Unfold.jl allows storing Unfold models in a memory-efficient way using (compressed) .jld2 files."},{"id":68,"pagetitle":"Save and load Unfold models","title":"Simulate EEG data and fit an Unfold model","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Simulate-EEG-data-and-fit-an-Unfold-model","content":" Simulate EEG data and fit an Unfold model Click to expand"},{"id":69,"pagetitle":"Save and load Unfold models","title":"Simulate some example data using UnfoldSim.jl","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Simulate-some-example-data-using-UnfoldSim.jl","content":" Simulate some example data using UnfoldSim.jl using UnfoldSim\ndata, events = UnfoldSim.predef_eeg(; n_repeats = 10)\nfirst(events, 5) 5×3 DataFrame Row continuous condition latency Float64 String Int64 1 2.77778 car 62 2 -5.0 face 132 3 -1.66667 car 196 4 -5.0 car 249 5 5.0 car 303"},{"id":70,"pagetitle":"Save and load Unfold models","title":"Fit an Unfold model","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Fit-an-Unfold-model","content":" Fit an Unfold model using Unfold\nbasisfunction = firbasis(τ = (-0.5, 1.0), sfreq = 100, name = \"stimulus\")\nf = @formula 0 ~ 1 + condition + continuous\nbfDict = Dict(Any => (f, basisfunction))\nm = fit(UnfoldModel, bfDict, events, data); ┌ Warning:  using `Dict(:A=>(@formula,times/basisfunction))` is deprecated, please use `[:A=>(@formula,times/basisfunction)]` from now on\n └  @ Unfold ~/work/Unfold.jl/Unfold.jl/src/fit.jl:74"},{"id":71,"pagetitle":"Save and load Unfold models","title":"Save and load the fitted Unfold model","ref":"/UnfoldDocs/Unfold.jl/stable/generated/HowTo/unfold_io/#Save-and-load-the-fitted-Unfold-model","content":" Save and load the fitted Unfold model The following code saves the model in a compressed .jld2 file. The default option of the  save  function is  compress=false . For memory efficiency the designmatrix is set to missing. If needed, it can be reconstructed when loading the model. save_path = mktempdir(; cleanup = false) # create a temporary directory for the example\nsave(joinpath(save_path, \"m_compressed.jld2\"), m; compress = true); The  load  function allows to retrieve the model again. By default, the designmatrix is reconstructed. If it is not needed set  generate_Xs=false ` which improves time-efficiency. m_loaded = load(joinpath(save_path, \"m_compressed.jld2\"), UnfoldModel, generate_Xs = true); This page was generated using  Literate.jl ."},{"id":74,"pagetitle":"Non-Linear effects","title":"[Non-linear effects]](@id nonlinear)","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#[Non-linear-effects]](@id-nonlinear)","content":" [Non-linear effects]](@id nonlinear) using BSplineKit, Unfold\nusing CairoMakie\nusing DataFrames\nusing Random\nusing Colors\nusing Missings"},{"id":75,"pagetitle":"Non-Linear effects","title":"Generating a non-linear signal","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#Generating-a-non-linear-signal","content":" Generating a non-linear signal We start with generating data variables rng = MersenneTwister(2) # make repeatable\nn = 20 # number of datapoints\nevts = DataFrame(:x => rand(rng, n))\nsignal = -(3 * (evts.x .- 0.5)) .^ 2 .+ 0.5 .* rand(rng, n)\n\nplot(evts.x, signal) Looks perfectly non-linear. Great!"},{"id":76,"pagetitle":"Non-Linear effects","title":"Compare linear & non-linear fit","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#Compare-linear-and-non-linear-fit","content":" Compare linear & non-linear fit First, we have to reshape  signal  data to a 3d array, so it will fit to Unfold format:  1 channel x 1 timepoint x 20 datapoints. signal = reshape(signal, length(signal), 1, 1)\nsignal = permutedims(signal, [3, 2, 1])\nsize(signal) (1, 1, 20) Next we define three different models:  linear ,  4 splines  and  10 splines . Note difference in formulas: one  x , the other  spl(x, 4) . design_linear = [Any => (@formula(0 ~ 1 + x), [0])];\ndesign_spl3 = [Any => (@formula(0 ~ 1 + spl(x, 4)), [0])];\ndesign_spl10 = [Any => (@formula(0 ~ 1 + spl(x, 10)), [0])]; Next, fit the parameters. uf_linear = fit(UnfoldModel, design_linear, evts, signal);\nuf_spl3 = fit(UnfoldModel, design_spl3, evts, signal); Extract the fitted values using Unfold.effects. p_linear = Unfold.effects(Dict(:x => range(0, stop = 1, length = 100)), uf_linear);\np_spl3 = Unfold.effects(Dict(:x => range(0, stop = 1, length = 100)), uf_spl3);\np_spl10 = Unfold.effects(Dict(:x => range(0, stop = 1, length = 100)), uf_spl10);\nfirst(p_linear, 5) 5×5 DataFrame Row yhat channel x time eventname Float64 Int64 Float64 Int64 DataType 1 0.0328538 1 0.0 0 Any 2 0.0273313 1 0.010101 0 Any 3 0.0218088 1 0.020202 0 Any 4 0.0162863 1 0.030303 0 Any 5 0.0107638 1 0.040404 0 Any Plot them. pl = plot(evts.x, signal[1, 1, :])\nlines!(p_linear.x, p_linear.yhat)\nlines!(p_spl3.x, coalesce.(p_spl3.yhat, NaN))\nlines!(p_spl10.x, coalesce.(p_spl10.yhat, NaN))\npl We see here, that the linear effect (blue line) underfits the data, the yellow  spl(x, 10)  overfits it, but the green  spl(x, 4)  fits it perfectly."},{"id":77,"pagetitle":"Non-Linear effects","title":"Looking under the hood","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/nonlinear_effects/#Looking-under-the-hood","content":" Looking under the hood Let's have a brief look how the splines manage what they are managing. The most important bit to understand is, that we are replacing  x  by a set of coefficients  spl(x) . These new coefficients each tile the range of  x  (in our case, from [0-1]) in overlapping areas, while each will be fit by one coefficient. Because the ranges are overlapping, we get a smooth function. Maybe this becomes clear after looking at a  basisfunction : term_spl = Unfold.formulas(uf_spl10)[1].rhs.terms[2] spl(x, 10) This is the spline term. Note, this is a special type available in the BSplineKit.jl extension in Unfold.jl. It's abstract type is  AbstractSplineTerm  defined in Unfold.jl typeof(term_spl) UnfoldBSplineKitExt.BSplineTerm{StatsModels.ContinuousTerm{Float64}, Int64} const splFunction = Base.get_extension(Unfold, :UnfoldBSplineKitExt).splFunction\nsplFunction([0.2], term_spl) 1×10 Matrix{Float64}:\n 0.492619  0.438047  0.0670761  0.00225775  0.0  0.0  0.0  0.0  0.0  0.0 Each column of this 1-row matrix is a coefficient for our regression model. lines(disallowmissing(splFunction([0.2], term_spl))[1, :]) Note: We have to use  disallowmissing , because our splines return a  missing  whenever we ask it to return a value outside its defined range, e.g.: splFunction([-0.2], term_spl) 1×10 Matrix{Union{Missing, Float64}}:\n missing  missing  missing  missing  …  missing  missing  missing  missing Because it never has seen any data outside and can't extrapolate! Back to our main issue. Let's plot the whole basis set basisSet = splFunction(0.0:0.01:1, term_spl)\nbasisSet = disallowmissing(basisSet[.!any(ismissing.(basisSet), dims = 2)[:, 1], :]) # remove missings\nax = Axis(Figure()[1, 1])\n[lines!(ax, basisSet[:, k]) for k = 1:size(basisSet, 2)]\ncurrent_figure() Notice how we flipped the plot around, i.e. now on the x-axis we do not plot the coefficients, but the  x -values. Now each line is one basis-function of the spline. Unfold returns us one coefficient per basis-function β = coef(uf_spl10)[1, 1, :]\nβ = Float64.(disallowmissing(β)) 10-element Vector{Float64}:\n -0.43629459354570777\n -0.3477308181329035\n  0.4538614574712754\n -0.4065207930158754\n  0.7346158579524353\n  0.9252913204020701\n  0.27167896791779556\n -0.046335871160806175\n -0.5822988416277803\n -0.6202082891592833 But because we used an intercept, we have to do some remodelling in the  basisSet . X = hcat(ones(size(basisSet, 1)), basisSet[:, 1:5], basisSet[:, 7:end]) 71×10 Matrix{Float64}:\n 1.0  0.972634     0.027217  0.000148709  …  0.0         0.0       0.0\n 1.0  0.705645     0.274339  0.0196948       0.0         0.0       0.0\n 1.0  0.492619     0.438047  0.0670761       0.0         0.0       0.0\n 1.0  0.327462     0.530129  0.135118        0.0         0.0       0.0\n 1.0  0.204084     0.56237   0.216645        0.0         0.0       0.0\n 1.0  0.116392     0.546557  0.304483     …  0.0         0.0       0.0\n 1.0  0.0582934    0.494476  0.391456        0.0         0.0       0.0\n 1.0  0.0236969    0.417914  0.470391        0.0         0.0       0.0\n 1.0  0.00651001   0.328658  0.534112        0.0         0.0       0.0\n 1.0  0.000640778  0.238493  0.575444        0.0         0.0       0.0\n ⋮                                        ⋱                        \n 1.0  0.0          0.0       0.0             0.500742    0.335973  0.0\n 1.0  0.0          0.0       0.0             0.472071    0.412937  0.0\n 1.0  0.0          0.0       0.0             0.423651    0.500839  0.0\n 1.0  0.0          0.0       0.0          …  0.354694    0.596875  0.00252938\n 1.0  0.0          0.0       0.0             0.272257    0.677546  0.0249338\n 1.0  0.0          0.0       0.0             0.186241    0.711843  0.0899373\n 1.0  0.0          0.0       0.0             0.106554    0.668749  0.220272\n 1.0  0.0          0.0       0.0             0.0431012   0.517244  0.438668\n 1.0  0.0          0.0       0.0          …  0.00579053  0.226308  0.767859 Now we can weight the spline by the  basisfunction . weighted = (β .* X') 10×71 Matrix{Float64}:\n -0.436295    -0.436295    -0.436295    …  -0.436295     -0.436295\n -0.338215    -0.245375    -0.171299       -0.0          -0.0\n  0.0123527    0.124512     0.198813        0.0           0.0\n -6.04533e-5  -0.00800637  -0.0272678      -0.0          -0.0\n  1.39303e-7   0.00023577   0.00165858      0.0           0.0\n  0.0          0.0          0.0         …   0.0           0.0\n  0.0          0.0          0.0             0.000268113   1.15869e-5\n -0.0         -0.0         -0.0            -0.00199713   -0.000268309\n -0.0         -0.0         -0.0            -0.30119      -0.131779\n -0.0         -0.0         -0.0            -0.272066     -0.476232 Plotting them creates a nice looking plot! ax = Axis(Figure()[1, 1])\n[lines!(weighted[k, :]) for k = 1:10]\ncurrent_figure() Now sum them up. lines(sum(weighted, dims = 1)[1, :])\nplot!(X * β, color = \"gray\") #(same as matrixproduct X*β directly!)\ncurrent_figure() And this is how you can think about splines. This page was generated using  Literate.jl ."},{"id":80,"pagetitle":"Predictions","title":"The predict-family","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#The-predict-family","content":" The predict-family # Setup\nusing Unfold\nusing UnfoldSim\nusing CairoMakie\n\ndat, evts = UnfoldSim.predef_eeg(noiselevel = 5)\ndesign = [\n    \"car\" => (@formula(0 ~ 1 + continuous), firbasis(τ = (-0.5, 1), sfreq = 100)),\n    \"face\" => (@formula(0 ~ 1 + continuous), firbasis(τ = (-0.3, 0.5), sfreq = 100)),\n]\n\nm = fit(UnfoldModel, design, evts, dat; eventcolumn = :condition);"},{"id":81,"pagetitle":"Predictions","title":"Overview","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Overview","content":" Overview In a linear model  $EEG = Xβ + e$ , predictions boil down to finding  $\\hat{EEG} = Xβ$ , thus EEG data without any error term. Different types of predictions can be generated by modifying the  $X$  accordingly. Note We simulated only a single channel, all results generalize to the multi channel case"},{"id":82,"pagetitle":"Predictions","title":"Different types of predictions","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Different-types-of-predictions","content":" Different types of predictions"},{"id":83,"pagetitle":"Predictions","title":"Time-Continuous case","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Time-Continuous-case","content":" Time-Continuous case Let's start with the cases, where the EEG was not epoched before using Unfold, i.e. the EEG was analysed with e.g. FIR-deconvolution"},{"id":84,"pagetitle":"Predictions","title":"Continuous EEG","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Continuous-EEG","content":" Continuous EEG In the most simple case, we can predict the continuously modelled EEG - This returns  $EEG = Xβ$ p = predict(m) # same as predict(m, overlap = true)\nlines(p[1, 1:1000])"},{"id":85,"pagetitle":"Predictions","title":"No-overlap","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#No-overlap","content":" No-overlap We can also predict each epoch without any overlap - This results in one prediction Array per event (in our case we have two events \"car\" and \"face\", thus  size(p[1]) = 2 p = predict(m, overlap = false)\nsize(p) (2,) Each Array has the size (1, samples, epochs): size(p[1]) (1, 151, 1000) Visualizing the 1000 events series(range(-0.5, 1, step = 1 / 100), p[1][1, :, :]', solid_color = :orange)\nseries!(range(-0.3, 0.5, step = 1 / 100), p[2][1, :, :]', solid_color = :teal)\ncurrent_figure() Note At ~0.3s we can see a split between the predicted EEG single trials into 10 \"strands\" - this is the granularity of our continuous predictor. You could use  effects  to improve upon this granularity / customize it."},{"id":86,"pagetitle":"Predictions","title":"With-overlap, epoched","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#With-overlap,-epoched","content":" With-overlap, epoched Sometimes helpful is to add in the overlap we removed via the deconvolution. p = predict(m, epoch_to = [\"car\"], eventcolumn = :condition)\nseries(range(-0.5, 1, step = 1 / 100), p[1, :, 1:3]', solid_color = :orange)"},{"id":87,"pagetitle":"Predictions","title":"Partial-overlap","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/predict/#Partial-overlap","content":" Partial-overlap We can also include/exclude certain events with \"partial-overlap\", i.e. only overlap with kept events. p_car = predict(m, keep_basis = [\"car\"], eventcolumn = :condition)\np_face = predict(m, exclude_basis = [\"car\"], eventcolumn = :condition) # same as keep_basis=[\"face\"]\nf = lines(p_car[1, 1:1000])\nlines!(p_face[1, 1:1000])\nf In the plot, we see the two partial predictions for car and face. They are respectively \"0\" outside the basisfunction windows Note The above options can be combined as well, e.g. to get an  epoch_to ,  exclude_basis  version.  epoch_timewindow  can be specified as well. This page was generated using  Literate.jl ."},{"id":90,"pagetitle":"Window Length Effect","title":"Window length effects","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Window-length-effects","content":" Window length effects using Unfold, UnfoldSim\nusing CairoMakie, AlgebraOfGraphics, MakieThemes\nusing Random\nusing DataFrames, DataFramesMeta\nusing ColorSchemes, Colors Important For analyzing real-world EEG data we recommend that researchers should — a priori — make an educated guess about the length of the underlying EEG activity and select this as their EW. This also suggests to use event windows with different sizes between events (as is possible with Unfold). Further, as can be seen below, when choosing longer time-windows the overfit is only of moderate size, thus we additionally recommend to generally err on the longer side, to not miss any important activity.  For a more in depth explanation on this, you can read our 2023 CCN paper:  Skukies & Ehinger, 2023 set_theme!(theme_ggthemr(:fresh)) As opposed to classical averaged ERPs overlap corrected regression ERPs can be influenced by the chosen window length: Long estimation windows might capture all relevant event-related activity, but might introduce artifacts due to overfit, short estimation windows might not overfit, but also might not capture all (overlapping) activity, and thereby introduce bias. Thus a common question we get is, how to specify the length of the estimation windows."},{"id":91,"pagetitle":"Window Length Effect","title":"Init functions","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Init-functions","content":" Init functions First we need a function that simulates some continous data; conviently we can use UnfoldSim for this function gen_data(rng, noiselevel, sfreq)\n    noise = PinkNoise(; noiselevel = noiselevel)\n\n    dat, evts = UnfoldSim.predef_eeg(\n        rng;\n        sfreq = sfreq,\n        p1 = (p100(; sfreq = sfreq), @formula(0 ~ 1 + condition), [5, 0], Dict()),\n        n1 = (n170(; sfreq = sfreq), @formula(0 ~ 1 + condition), [5, 0], Dict()),\n        p3 = (p300(; sfreq = sfreq), @formula(0 ~ 1 + continuous), [5, 0], Dict()),\n        n_repeats = 20,\n        noise = noise,\n    )\n    return dat, evts\nend; Next a convience function to calculate the estimates function calc_time_models(evts, dat, tWinList, sfreq)\n    mList = []\n    for twindow in tWinList\n        m = fit(\n            UnfoldModel,\n            [Any => (@formula(0 ~ 1), firbasis(twindow, sfreq))],\n            evts,\n            dat,\n        )\n        res = coeftable(m)\n        res.tWin .= string.(Ref(twindow[2]))\n        push!(mList, res)\n    end\n    return vcat(mList...)\nend;"},{"id":92,"pagetitle":"Window Length Effect","title":"Init variables","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Init-variables","content":" Init variables tWinList = [(-0.1, x) for x in [3, 2.5, 2, 1.5, 1, 0.5]]\nnoiselevel = 8.5\nsfreq = 250;"},{"id":93,"pagetitle":"Window Length Effect","title":"Generate data and calculate estimates","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Generate-data-and-calculate-estimates","content":" Generate data and calculate estimates dat, evts = gen_data(MersenneTwister(2), noiselevel, sfreq);\n\nres = calc_time_models(evts, dat, tWinList, sfreq); We also append some additional information to the results dataframe For comparison lets also generate the ground truth of our data; this is a bit cumbersome and you don't have to care (too much) about it dat_gt, evts_gt = UnfoldSim.predef_eeg(;\n    p1 = (p100(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()),\n    sfreq = sfreq,\n    n1 = (n170(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()),\n    p3 = (p300(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()),\n    n_repeats = 1,\n    noiselevel = 0,\n    return_epoched = true,\n);\ntime_gt = range(0, length = length(dat_gt[:, 1]), step = 1 / sfreq)\nunique_event = unique(res.tWin)\ndf_gt = DataFrame(\n    tWin = reduce(vcat, fill.(unique_event, length(dat_gt[:, 1]))),\n    eventname = Any,\n    channel = repeat([1], length(dat_gt[:, 1]) * length(unique_event)),\n    coefname = reduce(\n        vcat,\n        fill(\"GroundTruth\", length(dat_gt[:, 1]) * length(unique_event)),\n    ),\n    estimate = repeat(dat_gt[:, 1], length(unique_event)),\n    group = reduce(vcat, fill(nothing, length(dat_gt[:, 1]) * length(unique_event))),\n    stderror = reduce(vcat, fill(nothing, length(dat_gt[:, 1]) * length(unique_event))),\n    time = repeat(time_gt, length(unique_event)),\n); And append ground truth to our results df res_gt = vcat(res, df_gt);"},{"id":94,"pagetitle":"Window Length Effect","title":"Plot results","ref":"/UnfoldDocs/Unfold.jl/stable/generated/explanations/window_length/#Plot-results","content":" Plot results Choose which data to plot h_t =\n    AlgebraOfGraphics.data(res) * mapping(\n        :time,\n        :estimate,\n        color = :tWin,\n        group = (:tWin, :coefname) => (x, y) -> string(x[2]) * y,\n    ); We use the following to plot some length indicator lines untWin = unique(res_gt.tWin)\nsegDF = DataFrame(\n    :x => hcat(repeat([-0.1], length(untWin)), parse.(Float64, untWin))[:],\n    :y => repeat(reverse(1:length(untWin)), outer = 2),\n)\nsegDF.tWin .= \"0.0\"\nsegDF.tWin .= segDF.x[reverse(segDF.y .+ 6)]\nsegDF.y = segDF.y .* 0.2 .+ 6; Layer for indicator lines h_l =\n    AlgebraOfGraphics.data(@subset(segDF, :tWin .!= \"3.0\")) *\n    mapping(:x, :y, color = :tWin, group = :tWin => x -> string.(x)); Ground truth Layer h_gt =\n    AlgebraOfGraphics.data(df_gt) *\n    mapping(:time, :estimate, group = (:tWin, :coefname) => (x, y) -> string(x) * y) *\n    visual(Lines, linewidth = 5, color = Colors.Gray(0.6)); Add all visuals together and draw h1 =\n    h_gt + visual(Lines, colormap = get(ColorSchemes.Blues, 0.3:0.01:1.2)) * (h_l + h_t) |>\n    x -> draw(x, axis = (; xlabel = \"time [s]\", ylabel = \"estimate [a.u.]\")); Add zero grid lines h1 = hlines!(current_axis(), [0], color = Colors.Gray(0.8));\nh2 = vlines!(current_axis(), [0], color = Colors.Gray(0.8));\ntranslate!(h1, 0, 0, -1);\ntranslate!(h2, 0, 0, -1); Plot figure current_figure() This page was generated using  Literate.jl ."},{"id":97,"pagetitle":"Solver/optimizer implementations","title":"Solver implementation","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Solver-implementation","content":" Solver implementation This document describes how the  solver_main  is implemented and how to add custom solvers. some setup using Unfold, UnfoldSim, CairoMakie\nusing LinearAlgebra: cholesky"},{"id":98,"pagetitle":"Solver/optimizer implementations","title":"Solver main","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Solver-main","content":" Solver main This function gis a eneral purpose solver-wrapper function. It calls   prepare_fun  and iterates over the first dimension of  data , repeatedly calling the  solver_fun . Without any bells and whistles (progress, history etc.) the function roughly looks like this: function _solver_min(X, data; prepare_fun, solver_fun!, stderror = false)\n    Ĥ, dataP, prepared = prepare_fun(X, data)\n    for ch = 1:size(dataP, 2)\n        for t = 1:size(dataP, 3)\n            ch == 1 || copyto!(view(Ĥ, ch, :, t), view(Ĥ, ch - 1, :, t))\n            solver_fun!(view(Ĥ, ch, :, t), view(dataP, :, ch, t), prepared...)\n        end\n    end\n    modelfit = stderror ? calculate_stderror(X, data, Ĥ) : nothing\n\n    return modelfit\n\nend _solver_min (generic function with 1 method) Before diving into the  prepare_fun  and  solver_fun!  functions, let's discuss first the inner loop  t=1:size(dataP,3) . This loop really only comes alife (that is  size(dataP,3)!=1 ) if a mass-univariate model is fitted, that is, when ndims(data)==3`. We still have it around for 2D, un-epoched data, to have exactly the same code in both cases."},{"id":99,"pagetitle":"Solver/optimizer implementations","title":"prepare_fun`","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#prepare_fun","content":" prepare_fun ` This function is the setup / prepare function. It is typically a chain of functions with similar input / output characteristica. The first fuction of the chain/pipeline should be a function taking  (X,data) and returning  (Ĥ::AbstractArray, dataP::AbstractArray, prepared::Tuple) . Ĥ  is used to save the beta/parameters inplace dataP  is the data in format ch x repeat x time (with size(time) = 1 if data initially was a Matrix/2D-array) prepared  is a tuple of all the other variables needed in the solver-step, e.g. the  pinv(X)  or  X'X  or simply  X The  prepare  function which is typiclly the first, just permutes the data & converts everything to GPU in case  data::CuArray . The next function in a pipeline then would take this  (Ĥ::AbstractArray, dataP::AbstractArray, prepared::Tuple)  inputs and process it further.`"},{"id":100,"pagetitle":"Solver/optimizer implementations","title":"solver_fun!","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#solver_fun!","content":" solver_fun! This function actually performs the fitting. It takes the inputs  (Ĥ::view(Matrix),data::view(Array),prepared::Tuple) Ĥ  is the current beta/parameters view, a vector/slice for one channel and one timepoint data  is similarly the current data view, a vector/slice for one channel and one timepoint prepared  is the tuple-output of the  prepare  function. The  solver_fun!  can output some history of the solver, e.g. a log for iterative solvers."},{"id":101,"pagetitle":"Solver/optimizer implementations","title":"Example (simple)","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Example-(simple)","content":" Example (simple) let's setup our own solver: _my_solver!(Ĥ, data, X) = Ĥ .= Matrix(X) \\ data _my_solver! (generic function with 1 method) let's simulate some data and see this in action data, evts = UnfoldSim.predef_eeg()\nm = fit(\n    UnfoldModel,\n    @formula(0 ~ 1 + condition),\n    evts,\n    data,\n    firbasis((-0.1, 0.5), 100);\n    solver = (x, y) ->\n        Unfold.solver_main(x, y; solver_fun! = _my_solver!, show_time = true),\n) Unfold�[38;2;239;83;80m-�[39mType: �[38;2;206;147;216m::UnfoldLinearModelContinuousTime�[39m{{Float64}} \n �[1m Any�[22m �[38;2;239;83;80m=�[39m�[38;2;239;83;80m>�[39m �[38;2;239;83;80mAny�[39m: timeexpand(�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m condition) for times �[38;2;239;83;80m[�[39m�[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.1�[39m, �[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.09�[39m ... �[38;2;144;202;249m0.5�[39m�[38;2;239;83;80m]�[39m \n \n�[1m�[32m✔�[22m�[39m model is fit.  size(coefs) (�[38;2;144;202;249m1�[39m, �[38;2;144;202;249m122�[39m) \n \nUseful functions: �[38;2;255;238;88m`design(uf)`�[39m, �[38;2;255;238;88m`designmatrix(uf)`�[39m, �[38;2;255;238;88m`coef(uf)`�[39m, �[38;2;255;238;88m`coeftable(uf)`�[39m Remember from this table the time for one solve (~700ms on my test-computer) this is the time per channel. series(coef(m))"},{"id":102,"pagetitle":"Solver/optimizer implementations","title":"Cholesky Example","ref":"/UnfoldDocs/Unfold.jl/stable/generated/references/solver/#Cholesky-Example","content":" Cholesky Example Note the following function is already implemented in Unfold.jl as well. See  ?Unfold.solver_predefined Given that the  prepare  function returns all necessary ingredients, this is a bit simple. So let's make it more complex for nicety, we need some unpacking wrappers _prepare_cholesky(all::Tuple) = _prepare_cholesky(all...)\n_prepare_cholesky(Ĥ, data, all::Tuple) = _prepare_cholesky(Ĥ, data, all...) _prepare_cholesky (generic function with 2 methods) this function effectively only pre-calculates the cholesky decomposition _prepare_cholesky(Ĥ, data, Xt, R_xx, R_xy) = (Ĥ, data, (Xt, cholesky(R_xx), R_xy)) _prepare_cholesky (generic function with 3 methods) now we have everything to put together our solver-pipeline _my_prepare =\n    (x, y) -> Unfold.prepare(collect(x), y) |> Unfold.prepare_XTX |> _prepare_cholesky #4 (generic function with 1 method) let's test (note we have to reshape the data) @time _my_prepare(modelmatrix(m), reshape(data, 1, :)) ([0.0 0.0 … 0.0 0.0], [0.31631798033146774; 0.40338935529989906; … ; -0.22230944464885682; -0.01320095208877194;;], ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0], LinearAlgebra.Cholesky{Float64, Matrix{Float64}}([44.721359549995796 0.0 … 1.1627553482998907 0.9167878707749137; 0.0 44.721359549995796 … 0.9391485505499116 1.1627553482998907; … ; 52.0 42.0 … 22.354427580020936 0.0008355409821590546; 41.0 52.0 … 0.0 22.354385443812227], 'U', 0), [5.0e-324, 0.0, 5.0e-324, 1.0e-323, 5.0e-324, 5.0e-324, 2.5e-323, 1.3e-322, 0.0, 2.0e-323  …  1.8e-322, 1.2731974873e-313, 1.73e-322, 1.83e-322, 5.0e-324, 1.8e-322, 1.9e-322, 6.902036085116e-310, 1.9e-322, 1.93e-322])) finally, we need a solver this is how we solve the single-channel equation function _my_cholesky!(beta, data, Xt, XtX_cholesky, R_xy)\n    @time Unfold.calc_Rxy!(R_xy, Xt, data)\n    @time beta .= XtX_cholesky \\ R_xy\nend\n\nm = fit(\n    UnfoldModel,\n    @formula(0 ~ 1 + condition),\n    evts,\n    data,\n    firbasis((-0.1, 0.5), 100);\n    solver = (x, y) -> Unfold.solver_main(\n        x,\n        y;\n        prepare_fun = _my_prepare,\n        solver_fun! = _my_cholesky!,\n        show_time = true,\n    ),\n) Unfold�[38;2;239;83;80m-�[39mType: �[38;2;206;147;216m::UnfoldLinearModelContinuousTime�[39m{{Float64}} \n �[1m Any�[22m �[38;2;239;83;80m=�[39m�[38;2;239;83;80m>�[39m �[38;2;239;83;80mAny�[39m: timeexpand(�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m condition) for times �[38;2;239;83;80m[�[39m�[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.1�[39m, �[38;2;239;83;80m-�[39m�[38;2;144;202;249m0.09�[39m ... �[38;2;144;202;249m0.5�[39m�[38;2;239;83;80m]�[39m \n \n�[1m�[32m✔�[22m�[39m model is fit.  size(coefs) (�[38;2;144;202;249m1�[39m, �[38;2;144;202;249m122�[39m) \n \nUseful functions: �[38;2;255;238;88m`design(uf)`�[39m, �[38;2;255;238;88m`designmatrix(uf)`�[39m, �[38;2;255;238;88m`coef(uf)`�[39m, �[38;2;255;238;88m`coeftable(uf)`�[39m This (on my test-computer) took only 97ms per channel, so it is ~7x faster per channel. series(coef(m)) This page was generated using  Literate.jl ."},{"id":105,"pagetitle":"Installing Julia + Unfold.jl","title":"Installation","ref":"/UnfoldDocs/Unfold.jl/stable/installation/#install_instruct","content":" Installation"},{"id":106,"pagetitle":"Installing Julia + Unfold.jl","title":"Installing Julia","ref":"/UnfoldDocs/Unfold.jl/stable/installation/#Installing-Julia","content":" Installing Julia The easiest way to install julia is using  juliaup TLDR;  Windows:  winget install julia -s msstore Mac/Linux:  curl -fsSL https://install.julialang.org | sh We further recommend to use VSCode. Make sure to install the Julia-Plugin, and install Revise.jl -  a tutorial with screenshots can be found here"},{"id":107,"pagetitle":"Installing Julia + Unfold.jl","title":"Installing Unfold.jl","ref":"/UnfoldDocs/Unfold.jl/stable/installation/#Installing-Unfold.jl","content":" Installing Unfold.jl You can enter the package manager (similar to conda) using  ]  in the REPL (\"julia-commandline\"). This should result in  (currentFolder) pkg>  (with  currentFolder  being the project you currently work in) Hint if you see  (@v1.9) pkg>  instead, you still have to activate your environment. This can be done using: cd(\"/path/to/your/project\")   and  ]activate . or alternatively  ]activate /path/to/your/project/ Now you can do  pkg> add Unfold and after some installation: julia> using Unfold  in the REPL"},{"id":110,"pagetitle":"Solver benchmarks","title":"Benchmarks","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Benchmarks","content":" Benchmarks We ran benchmarks on 2024-11-07 as described in  ./benchmark/cuda/solver_comparison.jl . Given that some were run on a GPU, we cannot run them on continuous-integration online. Important Allocations are only CPU allocations - GPU allocations were not counted.  Solvers other than  default_multi  are currently  NOT  multi-threaded Solvers other than  default_multi  and  krylov_gpu  solve  $X'Xb = X'y$  instead of  $Xb=y$  directly. They are likely less accurate, but should be faster for multi-channel data, as we can precalulate cholesky, qr or similar & the to-be-inverted matrix is much smaller."},{"id":111,"pagetitle":"Solver benchmarks","title":"Small Model","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Small-Model","content":" Small Model n_channels = 1,\nsfreq = 10,\nn_splines = 4,\nn_repeats = 10; gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float64 0.068 (1190, 130) 1 (0.2, 0.2) PosDefException(-1) false cholesky Float64 0.00056 0.00069 0.068 (1190, 130) 1 (0.2, 0.2) true intern Float64 0.00088 0.00017 0.068 (1190, 130) 1 (0.2, 0.2) false intern Float64 0.0011 0.00069 0.068 (1190, 130) 1 (0.2, 0.2) true qr Float64 0.0013 0.00019 0.068 (1190, 130) 1 (0.2, 0.2) false cg Float64 0.0015 0.00057 0.068 (1190, 130) 1 (0.2, 0.2) false default_multi Float64 0.0017 0.00016 0.068 (1190, 130) 1 (0.2, 0.2) false qr Float64 0.002 0.00076 0.068 (1190, 130) 1 (0.2, 0.2) true cg Float64 0.0054 0.00056 0.068 (1190, 130) 1 (0.2, 0.2) true pinv Float64 0.0054 0.00032 0.068 (1190, 130) 1 (0.2, 0.2) false pinv Float64 0.016 0.0016 0.068 (1190, 130) 1 (0.2, 0.2) true krylov_gpu Float64 0.032 0.0013 0.068 (1190, 130) 1 (0.2, 0.2)"},{"id":112,"pagetitle":"Solver benchmarks","title":"small-to-midsize: multi-channel","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#small-to-midsize:-multi-channel","content":" small-to-midsize: multi-channel n_channels = 128,\nsfreq = 100,\nn_splines = 4,\nn_repeats = 200;"},{"id":113,"pagetitle":"Solver benchmarks","title":"Float64","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Float64","content":" Float64 gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float64 0.0068 (239522, 1210) 128 (0.2, 0.2) PosDefException(-1) true qr Float64 0.38 0.25 0.0068 (239522, 1210) 128 (0.2, 0.2) true pinv Float64 0.42 0.26 0.0068 (239522, 1210) 128 (0.2, 0.2) true intern Float64 0.7 0.25 0.0068 (239522, 1210) 128 (0.2, 0.2) true cg Float64 1.2 0.32 0.0068 (239522, 1210) 128 (0.2, 0.2) false cholesky Float64 1.5 0.31 0.0068 (239522, 1210) 128 (0.2, 0.2) false qr Float64 1.7 0.31 0.0068 (239522, 1210) 128 (0.2, 0.2) false cg Float64 2.0 0.3 0.0068 (239522, 1210) 128 (0.2, 0.2) false pinv Float64 2.1 0.38 0.0068 (239522, 1210) 128 (0.2, 0.2) true krylov_gpu Float64 5.9 0.4 0.0068 (239522, 1210) 128 (0.2, 0.2) false default_multi Float64 13.0 1.2 0.0068 (239522, 1210) 128 (0.2, 0.2) false intern Float64 13.0 1.7 0.0068 (239522, 1210) 128 (0.2, 0.2)"},{"id":114,"pagetitle":"Solver benchmarks","title":"Float32","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#Float32","content":" Float32 gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float32 0.0068 (239522, 1210) 128 (0.2, 0.2) PosDefException(-1) true krylov_gpu Float32 0.0068 (239522, 1210) 128 (0.2, 0.2) true pinv Float32 0.39 0.25 0.0068 (239522, 1210) 128 (0.2, 0.2) true qr Float32 0.62 0.24 0.0068 (239522, 1210) 128 (0.2, 0.2) true intern Float32 0.69 0.24 0.0068 (239522, 1210) 128 (0.2, 0.2) true cg Float32 1.2 0.31 0.0068 (239522, 1210) 128 (0.2, 0.2) false cholesky Float32 1.2 0.17 0.0068 (239522, 1210) 128 (0.2, 0.2) false cg Float32 1.3 0.16 0.0068 (239522, 1210) 128 (0.2, 0.2) false qr Float32 1.4 0.17 0.0068 (239522, 1210) 128 (0.2, 0.2) false pinv Float32 1.6 0.21 0.0068 (239522, 1210) 128 (0.2, 0.2) false intern Float32 13.0 0.86 0.0068 (239522, 1210) 128 (0.2, 0.2) false default_multi Float32 13.0 0.97 0.0068 (239522, 1210) 128 (0.2, 0.2)"},{"id":115,"pagetitle":"Solver benchmarks","title":"large, realistic model","ref":"/UnfoldDocs/Unfold.jl/stable/references/benchmarks/#large,-realistic-model","content":" large, realistic model     n_channels = 128,\n    sfreq = 500,\n    n_splines = (4, 4),\n    n_repeats = 500, gpu method el_type time GB percent_X_filled sizeDesign n_channels overlap comment true cholesky Float64 0.0015 (3001479, 9616) 128 (0.2, 0.2) PosDefException(-1) false cholesky Float64 0.0015 (3001479, 9616) 128 (0.2, 0.2) PosDefException(2760) false intern Float64 0.0015 (3001479, 9616) 128 (0.2, 0.2) SingularException(9599) true cg Float64 9.3 3.6 0.0015 (3001479, 9616) 128 (0.2, 0.2) true qr Float64 11.0 3.5 0.0015 (3001479, 9616) 128 (0.2, 0.2) true intern Float64 13.0 3.5 0.0015 (3001479, 9616) 128 (0.2, 0.2) false qr Float64 80.0 6.3 0.0015 (3001479, 9616) 128 (0.2, 0.2) true pinv Float64 80.0 4.2 0.0015 (3001479, 9616) 128 (0.2, 0.2) true krylov_gpu Float64 107.0 3.9 0.0015 (3001479, 9616) 128 (0.2, 0.2) false default_multi Float64 500.0 15.0 0.0015 (3001479, 9616) 128 (0.2, 0.2) false pinv Float64 520.0 11.0 0.0015 (3001479, 9616) 128 (0.2, 0.2) false cg Float64 939.0 5.7 0.0015 (3001479, 9616) 128 (0.2, 0.2)"},{"id":118,"pagetitle":"Overview of package extensions","title":"Package-extensions","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#Package-extensions","content":" Package-extensions In  Julia 1.9 Package Extensions were introduced. Unfold.jl is making use of them in four ways. Prior to using some functionality, you have to add + load specific package(s) for the functionality to be available. The reason for this is, that if you don't need e.g. GPU-support, you also will not need to install it."},{"id":119,"pagetitle":"Overview of package extensions","title":"MixedModels","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#MixedModels","content":" MixedModels To use formulas like  @formula(0~1+condition+(1+condition|subject))  you have to load MixedModels. e.g. using MixedModels\nusing Unfold"},{"id":120,"pagetitle":"Overview of package extensions","title":"GPU: Krylov,CUDA","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#GPU:-Krylov,CUDA","content":" GPU: Krylov,CUDA To use gpu support as described in @Ref(custom_solvers) you have to: using Krylov,CUDA\nusing Unfold"},{"id":121,"pagetitle":"Overview of package extensions","title":"RobustSolvers.jl","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#RobustSolvers.jl","content":" RobustSolvers.jl To use robust (outlier-\"safe\") solvers support as described in @Ref(custom_solvers) you have to: using RobustSolvers\nusing Unfold"},{"id":122,"pagetitle":"Overview of package extensions","title":"Non-linear effects: BSplineKit.jl","ref":"/UnfoldDocs/Unfold.jl/stable/references/extensions/#Non-linear-effects:-BSplineKit.jl","content":" Non-linear effects: BSplineKit.jl Finally to use non-linear effects/splines like in  @formula 0~1+spl(continuous,5)  you have to use: using BSplineKit\nusing Unfold Note In principle you should be able to load the package after loading Unfold. But sometimes this doesnt work, a  Base.retry_load_extensions()  call might help in these situations."},{"id":125,"pagetitle":"API: Functions","title":"Effects.effects","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Effects.effects-Union{Tuple{T}, Tuple{AbstractDict, T}} where T<:UnfoldModel","content":" Effects.effects  —  Method effects(design::AbstractDict, model::UnfoldModel; typical = mean) Calculates marginal effects for all term combinations in  design . Implementation based on Effects.jl package; likely could repackage in UnfoldEffects.jl; somebody wants to do it? This would make it easier to cross-maintain it to changes/bug fixes in the Effects.jl package.  design  is a dictionary containing those predictors (as keys) with levels (as values), that you want to evaluate. The  typical  refers to the value, which other predictors that are not specified in the dictionary, should take on. For MixedModels, the returned effects are based on the \"typical\" subject, i.e. all random effects are put to 0. Example  julia> f = @formula 0 ~ categoricalA + continuousA + continuousB\n julia> uf = fit(UnfoldModel, (Any => (f, times)), data, events)\n julia> d = Dict(:categorical => [\"levelA\", \"levelB\"], :continuous => [-2, 0, 2])\n julia> effects(d, uf) will result in 6 predicted values: A/-2, A/0, A/2, B/-2, B/0, B/2. source"},{"id":126,"pagetitle":"API: Functions","title":"FileIO.load","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#FileIO.load-Tuple{Any, Type{<:UnfoldModel}}","content":" FileIO.load  —  Method FileIO.load(file, ::Type{<:UnfoldModel}; generate_Xs=true) Load UnfoldModel from a .jld2 file.  By default, the designmatrix is reconstructed. If it is not needed set  generate_Xs=false  which improves time-efficiency. source"},{"id":127,"pagetitle":"API: Functions","title":"FileIO.save","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#FileIO.save-Union{Tuple{T}, Tuple{Any, T}} where T<:UnfoldModel","content":" FileIO.save  —  Method FileIO.save(file, uf::T; compress=false) where {T<:UnfoldModel} Save UnfoldModel in a (by default uncompressed) .jld2 file. For memory efficiency the designmatrix is set to missing. If needed, it can be reconstructed when loading the model. source"},{"id":128,"pagetitle":"API: Functions","title":"StatsAPI.coefnames","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.coefnames-Tuple{Unfold.TimeExpandedTerm}","content":" StatsAPI.coefnames  —  Method coefnames(term)\n coefnames of a TimeExpandedTerm concatenates the basis-function name with the kronecker product of the term name and the basis-function colnames. Separator is ' : ' Some examples for a firbasis:         basis 313 : (Intercept) : 0.1         basis 313 : (Intercept) : 0.2         basis_313 : (Intercept) : 0.3         ... source"},{"id":129,"pagetitle":"API: Functions","title":"StatsAPI.fit","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{T}, StatsModels.FormulaTerm, DataFrames.AbstractDataFrame, AbstractArray, Union{Unfold.BasisFunction, AbstractArray}}} where T<:UnfoldModel","content":" StatsAPI.fit  —  Method fit(type::UnfoldModel,d::Vector{Pair},tbl::AbstractDataFrame,data::Array)\nfit(type::UnfoldModel,f::FormulaTerm,tbl::AbstractDataFrame,data::Array{T,3},times)\nfit(type::UnfoldModel,f::FormulaTerm,tbl::AbstractDataFrame,data::Array{T,2},basisfunction::BasisFunction) Generates Designmatrix & fits model, either mass-univariate (one model per epoched-timepoint) or time-expanded (modeling linear overlap). keyword arguments fit::Bool  (default:  true ) - fit the model after constructing the designmatrix. Setting this to  false  is sometimes helpful if you only want to inspect the designmatrix. contrasts::Dict : (default:  Dict() ) contrast to be applied to formula. Example:  Dict(:my_condition=>EffectsCoding()) . More information here: https://juliastats.org/StatsModels.jl/stable/contrasts/ eventcolumn::Union{Symbol,String}  (default  :event ) - the column in  tbl  to differentiate the basisfunctions as defined in  d::Vector{Pair} solver::function : (default:  solver_default ). The solver used for  y=Xb , e.g.  (X,y;kwargs...) -> solver_default(X,y;kwargs...) . There are faster & alternative solvers available, see  solver_predefined  for a list of options, see  solver benchmark  in the online documentation. To use the GPU, you can provide the data as a  CuArray  after  using CUDA . Please change the solver to e.g.  solver_predef(X,y;solver=:qr)  as lsmr+cuda => crash typically. It's worth though, speed increases >100x possible show_progress::Bool  (default  true ) - show progress via ProgressMeter - passed to  solver eventfields::Array: (optional, default [:latency] ) Array of symbols, representing column names in tbl`, which are passed to basisfunction event-wise. First field of array always defines eventonset in samples. If a  Vector[Pairs]  is provided, it has to have one of the following structures: For  deconvolution  analyses (use  Any=>(f,bf)  to match all rows of  tbl  in one basis functions). Assumes  data  is a continuous EEG stream, either a  Vector  or a  ch x time Matrix f1 = @formula(0~1+my_condition)\n[\n :A=>(f1,firbasis((-0.1,1),128), # sfreq = 128Hz\n :B=>(f2,firbasis((-3,2),128)\n] for  mass-univariate  analyses without deconvolution. Assumes  data  to be cut into epochs already (see  Unfold.epoch ). Follows  eeglab  standard  ch x time x trials : timesvector = range(-0.1,3,step=1/100)\n[\n :A=>(f1,timesvector),\n :B=>(f2,timesvector)\n] Notes The  type  can be specified directly as well e.g.  fit(type::UnfoldLinearModel)  instead of relying on the automatic inference The data is reshaped if it is missing one dimension to have the first dimension then  1  \"Channel\". Examples Mass Univariate Linear julia> data,evts = UnfoldSim.predef_eeg()\njulia> data_e,times = Unfold.epoch(data=data,tbl=evts,τ=(-1.,1.9),sfreq=100) # cut the data into epochs. data_e is now ch x times x epoch\n\njulia> f  = @formula 0~1+continuousA+continuousB \njulia> model = fit(UnfoldModel,f,evts,data_e,times)\n# or:\njulia> model = fit(UnfoldModel,[Any=>(f,times)],evts,data_e) Timexpanded Univariate Linear julia> basisfunction = firbasis(τ=(-1,1),sfreq=10)\njulia> model = fit(UnfoldModel,f,evts,data,basisfunction)\n# or\njulia> model = fit(UnfoldModel,[Any=>(f,basisfunction],evts,data) source"},{"id":130,"pagetitle":"API: Functions","title":"StatsAPI.modelmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.modelmatrix","content":" StatsAPI.modelmatrix  —  Function StatsModels.modelmatrix(uf::UnfoldLinearModelContinuousTime, basisfunction = true) Setting the optional second args to false, will return the modelmatrix without the timeexpansion / basisfunction applied. source"},{"id":131,"pagetitle":"API: Functions","title":"StatsAPI.modelmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.modelmatrix-Tuple{UnfoldLinearModel, Any}","content":" StatsAPI.modelmatrix  —  Method modelmatrix(uf::UnfoldLinearModel) returns the modelmatrix of the model. Concatenates them, except in the MassUnivariate cases, where a vector of modelmatrices is return Compare with  modelmatrices  which returns a vector of modelmatrices, one per event source"},{"id":132,"pagetitle":"API: Functions","title":"StatsAPI.predict","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsAPI.predict-Tuple{Any, Vector{<:StatsModels.FormulaTerm}, Vector{<:DataFrames.DataFrame}}","content":" StatsAPI.predict  —  Method function predict(\n    uf::UnfoldModel,\n    f::Vector{<:FormulaTerm},\n    evts::Vector{<:DataFrame};\n    overlap::Bool = true,\n    kwargs...\n) Returns a predicted (\"y_hat = X*b\")  Array .  uf  is an  <:UnfoldModel f  is a (vector of) formulas, typically  Unfold.formulas(uf) , but formulas can be modified e.g. by  effects . evts  is a (vector of) events, can be  Unfold.events(uf)  to return the (possibly continuous-time) predictions of the model. Can be a custom even kwargs: if  overlap = true  (default), overlap based on the  latency  column of  evts  will be simulated, or in the case of  !ContinuousTimeTrait  just X*coef is returned.  if  overlap = false , returns predictions without overlap (models with  ContinuousTimeTrait  (=> with basisfunction / deconvolution) only), via  predict_no_overlap if  keep_basis  or  exclude_basis  is defined, then  predict_partial_overlap  is called, which allows to selective introduce overlap based on specified (or excluded respective) events/basisfunctions epoch_to  and   epoch_timewindow : calculate (partial) overlap controlled predictions, but returns them at the specified  epoch_at  event, with the times  epoch_timewindow  (default is taken from the basisfunction) in samples. eventcolumn  can be specified as well if different from the default  event . Hint: all  kwargs  can be  Vector , or if e.g.  string  types are provided, will be put into a  length==1  vector. Output If  overlap=false , returns a 3D-Array If  overlap=true  and  epoch_to = nothing  (default), returns a 2D-array If  overlap=true  and  epoch_to != nothing , returns a 3D array source"},{"id":133,"pagetitle":"API: Functions","title":"StatsModels.modelcols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#StatsModels.modelcols-Tuple{Unfold.TimeExpandedTerm, Any}","content":" StatsModels.modelcols  —  Method modelcols(term, tbl)\n calculates the actual designmatrix for a timeexpandedterm. Multiple dispatch on StatsModels.modelcols source"},{"id":134,"pagetitle":"API: Functions","title":"Unfold._modelcols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold._modelcols-Tuple{StatsModels.FormulaTerm, Any}","content":" Unfold._modelcols  —  Method _modelcols(form::FormulaTerm, events) source"},{"id":135,"pagetitle":"API: Functions","title":"Unfold._modelcols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold._modelcols-Tuple{Vector, Vector}","content":" Unfold._modelcols  —  Method _modelcols(forms::Vector,events::Vector) A wrapper around StatsModels.modelcols that is only needed for easy multiple dispatch source"},{"id":136,"pagetitle":"API: Functions","title":"Unfold.apply_basisfunction","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.apply_basisfunction-Tuple{Any, Unfold.BasisFunction, Any, Any}","content":" Unfold.apply_basisfunction  —  Method apply_basisfunction(\n    form,\n    basisfunction,\n    eventfields,\n    eventname\n)\n timeexpand the rhs-term of the formula with the basisfunction source"},{"id":137,"pagetitle":"API: Functions","title":"Unfold.combine_yhat!","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.combine_yhat!-Union{Tuple{T}, Tuple{Vector{<:Array{T}}, Array{T}}} where T","content":" Unfold.combine_yhat!  —  Method combine_yhat(list,single) combines single into list, if either list or single contains missing, automatically casts the respective counter-part to allow missings as well source"},{"id":138,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{Any, Any, Any}","content":" Unfold.designmatrix  —  Method designmatrix(type, f, tbl; kwargs...) call without basis function, continue with basisfunction =  nothing source"},{"id":139,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{Type{<:UnfoldModel}, Union{Tuple, StatsModels.FormulaTerm}, Any, Any}","content":" Unfold.designmatrix  —  Method designmatrix(\n    unfoldmodeltype,\n    f,\n    tbl,\n    basisfunction;\n    contrasts,\n    eventname,\n    kwargs...\n)\n designmatrix(type, f, tbl; kwargs...) Return a  DesignMatrix  used to fit the models. Arguments type::UnfoldModel f::FormulaTerm: Formula to be used in this designmatrix tbl: Events (usually a data frame) to be modelled basisfunction::BasisFunction: basisfunction to be used in modeling (if specified) contrasts::Dict: (optional) contrast to be applied to formula eventfields::Array: (optional) Array of symbols which are passed to basisfunction event-wise.  First field of array always defines eventonset in samples. Default is [:latency] Examples julia>  designmatrix(UnfoldLinearModelContinuousTime,Dict(Any=>(f,basisfunction1),tbl) source"},{"id":140,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{Type{<:UnfoldModel}, Vector{<:Pair}, Any}","content":" Unfold.designmatrix  —  Method designmatrix(\n    T::Type{<:UnfoldModel},\n    design_array::Vector{<:Pair},\n    tbl;\n    eventcolumn = :event,\n    contrasts = Dict{Symbol,Any}(),\n    kwargs..., iteratively calls  designmatrix  for each event in the design_array, and returns a list of  <:AbstractDesignMatrix source"},{"id":141,"pagetitle":"API: Functions","title":"Unfold.designmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.designmatrix-Tuple{UnfoldModel, Any}","content":" Unfold.designmatrix  —  Method designmatrix(\n    uf::UnfoldModel,\n    tbl;\n    eventcolumn = :event,\n    contrasts = Dict{Symbol,Any}(),\n    kwargs..., Main function called from  fit(UnfoldModel...) , generates the designmatrix, returns a list of  <:AbstractDesignMatrix source"},{"id":142,"pagetitle":"API: Functions","title":"Unfold.drop_missing_epochs","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.drop_missing_epochs-Union{Tuple{T}, Tuple{Any, AbstractArray{T, 3}}} where T","content":" Unfold.drop_missing_epochs  —  Method [X,y] = drop_missing_epochs(X, y::Array) Helper function to remove epochs of  y  that contain missings. Drops them from both  X  and   y . Often used in combination with  Unfold.epoch X can be anything that has two dimensions (Matrix, DataFrame etc) source"},{"id":143,"pagetitle":"API: Functions","title":"Unfold.empty_modelmatrix","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.empty_modelmatrix-Tuple{AbstractDesignMatrix}","content":" Unfold.empty_modelmatrix  —  Method empty_modelmatrix(d::AbstractDesignMatrix) returns an empty modelmatrix of the type DesignMatrix type of  d source"},{"id":144,"pagetitle":"API: Functions","title":"Unfold.epoch","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.epoch-Union{Tuple{T}, Tuple{Vector{T}, Any, Any, Any}} where T<:Union{Missing, Number}","content":" Unfold.epoch  —  Method epoch(data::Array{T,1},evts::DataFrame,τ::Tuple/Vector,sfreq;kwargs..., Basic function to epoch data; all input also available as kwargs. Additional kwarg:  eventtime =:latency, which defines the column in  evts  that is used to cut the data (in samples). For uneven sample-times we use  round() ` source"},{"id":145,"pagetitle":"API: Functions","title":"Unfold.equalize_size","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.equalize_size-Union{Tuple{T}, Tuple{AbstractMatrix, AbstractMatrix{T}}} where T<:(Union{Missing, var\"#s133\"} where var\"#s133\"<:Number)","content":" Unfold.equalize_size  —  Method equalize_size(X, data)\n Equates the length of data and designmatrix by cutting the shorter one The reason we need this is because when generating the designmatrix, we do not know how long the data actually are. We only assume that event-latencies are synchronized with the data source"},{"id":146,"pagetitle":"API: Functions","title":"Unfold.firbasis","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.firbasis","content":" Unfold.firbasis  —  Function firbasis(τ, sfreq; ...)\nfirbasis(τ, sfreq, name; interpolate)\n Generate a sparse FIR basis around the  τ  timevector at sampling rate  sfreq . This is useful if you cannot make any assumptions on the shape of the event responses. If unrounded events are supplied, they are split between samples. E.g. event-latency = 1.2 will result in a \"0.8\" and a \"0.2\" entry. keyword arguments interpolate  (Bool, default false): if true, interpolates events between samples linearly. This results in  predict  functions to return a trailling 0 Examples Generate a FIR basis function from -0.1s to 0.3s at 100Hz julia>  f = firbasis([-0.1,0.3],100) Evaluate at an event occuring at sample 103.3 julia>  f(103.3) source"},{"id":147,"pagetitle":"API: Functions","title":"Unfold.firkernel","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.firkernel-Tuple{Any, Any}","content":" Unfold.firkernel  —  Method firkernel(e, times; interpolate)\n Calculate a sparse firbasis Examples julia>  f = firkernel(103.3,range(-0.1,step=0.01,stop=0.31)) source"},{"id":148,"pagetitle":"API: Functions","title":"Unfold.formulas","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.formulas-Tuple{Vector{<:Pair}}","content":" Unfold.formulas  —  Method formulas(design::Vector{<:Pair}) returns vector of formulas, no schema has been applied (those formulas never saw the data). Also no timeexpansion has been applied (in the case of timecontinuous models) source"},{"id":149,"pagetitle":"API: Functions","title":"Unfold.get_basis_colnames","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.get_basis_colnames-Tuple{AbstractArray{<:StatsModels.FormulaTerm}}","content":" Unfold.get_basis_colnames  —  Method get_basis_colnames(m)\nget_basis_colnames(formulas) returns list of colnames - e.g. times for firbasis. source"},{"id":150,"pagetitle":"API: Functions","title":"Unfold.get_basis_indices","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.get_basis_indices-Tuple{Any, Vector}","content":" Unfold.get_basis_indices  —  Method get_basis_indices(uf, basisnames::Vector) returns a boolean vector with length spanning all coefficients, which coefficient is defined by  basisnames  (vector of names) source"},{"id":151,"pagetitle":"API: Functions","title":"Unfold.get_basis_names","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.get_basis_names-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T}} where T<:UnfoldModel","content":" Unfold.get_basis_names  —  Method get_basisnames(model::UnfoldModel) Return the basisnames for all predictor terms as a vector. The returned vector contains the name of the event type/basis, repeated by their actual coefficient number (after StatsModels.apply_schema / timeexpansion). If a model has more than one event type (e.g. stimulus and fixation), the vectors are concatenated. source"},{"id":152,"pagetitle":"API: Functions","title":"Unfold.hrfbasis","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.hrfbasis-Tuple{Float64}","content":" Unfold.hrfbasis  —  Method hrfbasis(TR; parameters, name)\n Generate a Hemodynamic-Response-Functio (HRF) basis with inverse-samplingrate \"TR\" (=1/FS) Optional Parameters p:                                                            defaults                                                           {seconds}         p(1) - delay of response (relative to onset)          6         p(2) - delay of undershoot (relative to onset)       16         p(3) - dispersion of response                         1         p(4) - dispersion of undershoot                       1         p(5) - ratio of response to undershoot                6         p(6) - onset {seconds}                                0         p(7) - length of kernel {seconds}                    32 Examples Generate a HRF basis function object with Sampling rate 1/TR. And evaluate it at an event occuring at TR 103.3 with duration of 4.1 TRs julia>  f = hrfbasis(2.3)\njulia>  f(103.3,4.1)\n source"},{"id":153,"pagetitle":"API: Functions","title":"Unfold.hrfkernel","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.hrfkernel-Tuple{Any, Any, Any}","content":" Unfold.hrfkernel  —  Method hrfkernel(e, TR, p)\n Calculate a HRF kernel. Input e can be [onset duration] Examples julia>  f = hrfkernel(103.3,2.3,[6. 16. 1. 1. 6. 0. 32.]) source"},{"id":154,"pagetitle":"API: Functions","title":"Unfold.linearize","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.linearize-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}","content":" Unfold.linearize  —  Method linearize(x)\n Flatten a 1D array from of a 2D/3D array. Also drops the empty dimension source"},{"id":155,"pagetitle":"API: Functions","title":"Unfold.matrix_by_basisname","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.matrix_by_basisname-Tuple{AbstractMatrix, Any, Vector}","content":" Unfold.matrix_by_basisname  —  Method Returns a view of the Matrix  y , according to the indices of the timeexpanded  basisname source"},{"id":156,"pagetitle":"API: Functions","title":"Unfold.modelmatrices","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.modelmatrices-Tuple{AbstractDesignMatrix}","content":" Unfold.modelmatrices  —  Method modelmatrices(X::AbstractDesignMatrix)\nmodelmatrices(X::Vector{<:AbstractDesignMatrix})\nmodelmatrices(modelmatrix::AbstractMatrix) Returns the modelmatrices (also called designmatrices) separately for the events. This is similar to  StatsModels.modelcols , but merely access the precomputed designmatrix. If the designmatrix needs to be computed, please use  modelcols Compare to  modelmatrix  which further concatenates the designmatrices (in the ContinuousTime case). source"},{"id":157,"pagetitle":"API: Functions","title":"Unfold.predict_no_overlap","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.predict_no_overlap-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T, Any, Vector, Vector}} where T<:UnfoldModel","content":" Unfold.predict_no_overlap  —  Method predict_no_overlap(, uf, coefs, f, evts)\n in ContinuousTime case (typically the deconvolution model), we return idealized predictions without overlap between events. in the Not-ContinuousTime case (typically the MassUnivariate model), we return predictions for each event independently. In that case, the function is unfortunately a missnomer, as overlap cannot be removed from mass-univariate models. source"},{"id":158,"pagetitle":"API: Functions","title":"Unfold.predict_partial_overlap","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.predict_partial_overlap-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T, Any}} where T<:UnfoldModel","content":" Unfold.predict_partial_overlap  —  Method predict_partial_overlap(, uf, args; kwargs...)\n Returns predicted time-continuous values, but only for a subset of events. This is achieved by excluding the part of the designmatrix that belongs to the basisfunctions/events you do not want to have in your model. Typically called via  predict , for configuration, keyword-arguments and usage see there. One difference is, that we require the  coefs(uf::UnfoldModel)  already exctracted.  Due to the time-continuous nature, running it with a model not containing the  ContinuousTimeTrait  it will throw an error. source"},{"id":159,"pagetitle":"API: Functions","title":"Unfold.predicttable","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.predicttable","content":" Unfold.predicttable  —  Function predicttable(model<:UnfoldModel,events=Unfold.events(model),args...;kwargs...) Shortcut to call efficiently call (pseudocode)  result_to_table(predict(...)) . Returns a tidy DataFrame with the predicted results. Loops all input to  predict , but really only makes sense to use if you specify either: overlap = false  (the default) or  epoch_to = \"eventname\" . source"},{"id":160,"pagetitle":"API: Functions","title":"Unfold.prepare","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.prepare-Union{Tuple{T}, Tuple{Any, AbstractMatrix{<:Union{Missing, T}}}} where T<:Number","content":" Unfold.prepare  —  Method prepare(X, data)\n convert and permutedim input to follow the following output: Ĥ, Y, X = prepare(X, data) where  Ĥ  is used to save the beta,  Y  is the data in format ch x repeat x time (with size(time) = 1 if data is a Matrix), and  X . if data is a CuArray, everything is transformed to CuArrays as well (via UnfoldCUDAExt.jl, CUDA needs to be loaded) same datatype between X and data is enforced source"},{"id":161,"pagetitle":"API: Functions","title":"Unfold.prepare_XTX","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.prepare_XTX-Tuple{Tuple}","content":" Unfold.prepare_XTX  —  Method prepare_XTX(all)\n instead of solving y = Xb, we solve X'Xb = X'y. This function calculates X'X and instantiates X'y to be used in the solver-step, to facilitate X'y calculations later, X' is also calculated. source"},{"id":162,"pagetitle":"API: Functions","title":"Unfold.prepare_pinv","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.prepare_pinv-Tuple{Tuple}","content":" Unfold.prepare_pinv  —  Method prepare_pinv(all)\n calculates pinv of the designmatrix for later use in the solver-step. This is helpful in case you have many chanels source"},{"id":163,"pagetitle":"API: Functions","title":"Unfold.result_to_table","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.result_to_table-Tuple{Any, Any, Vector{<:DataFrames.DataFrame}}","content":" Unfold.result_to_table  —  Method result_to_table(model<:UnfoldModel, eff::AbstractArray, events::Vector{<:DataFrame})\nresult_to_table(\n    eff::AbstractArray,\n    events::Vector{<:DataFrame},\n    times::Vector{<:Vector{<:Number}},\n    eventnames::Vector)\nresult_to_table(\n    eff::Vector{<:AbstractArray},\n    events::Vector{<:DataFrame},\n    times::Vector,\n    eventnames::Vector,\n) Converts an array-result (prediction or coefficient) together with the events, to a tidy dataframe. To support multi-event models, we expect everything to be put into  Vectors  - this should be refactored at some point to be compatible with broadcasting, but it is not right now. args eff : Contains the array(s) to be converted to a tidy dataframe. Should be 3D, with channel x time x predictor  events : A vector of event-dataframes, each need to match  size(eff,3) times : A vector of time-vectors, each need to match  size(eff,2) eventnames : A vector of eventnames, either symbols or strings, should be a single entry per event source"},{"id":164,"pagetitle":"API: Functions","title":"Unfold.solver_default","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.solver_default-Tuple{Any, AbstractMatrix}","content":" Unfold.solver_default  —  Method solver_default(X, y; kwargs...)\n default solvers. If data is continuous (2D), we solve Xb = y via lsmr If data is epoched (3D) we solve Xb = y via pinv We highly recommend to check out  solver_predefined  for faster options by rather solving X'Xb = X'y via QR, cholesky, pinv or ``-solver. A benchmark is available in the online documentation. Please see  ?solver_main  for keyword arguments of the solver (like  stderror ,  multithreading ,  show_time ,  show_progress ) source"},{"id":165,"pagetitle":"API: Functions","title":"Unfold.solver_predefined","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.solver_predefined-Tuple{Any, AbstractMatrix}","content":" Unfold.solver_predefined  —  Method solver_predefined(X, y_in; solver, kwargs...)\n helper function that returns solver with appropriate prepare-pipelines and fitting solver-functions. X is a (typically sparse) designmatrix, y is a 2D or 3D array. solver  : one of  :cg ,  :pinv ,  :intern ,  :qr ,  :cholesky ,  :lsmr  (default) Only  lsmr  solves Xb = y via an iterative solver and should be more accurate in principle. The other predefined-solvers solve X'Xb = X'y which is often computationally much cheaper, and because X'X can be precalculated, it should be cheaper to apply. Testing this empirically is somewhat complicated, as depending on your sparsity structure (≈ your design) and the size of your data (sfreq & minutes) the best solver and the reached accuracy can change quite a bit. GPU All solvers except :lsmr support GPU calculations. For lsmr on the GPU try  solver_krylov  instead source"},{"id":166,"pagetitle":"API: Functions","title":"Unfold.spdiagm_diag","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.spdiagm_diag-Union{Tuple{T}, Tuple{Any, Vararg{Pair{<:Integer, T}}}} where T","content":" Unfold.spdiagm_diag  —  Method Speed improved version of spdiagm, takes a single float value instead of a vector, like a version of spdiagm that takes in a UniformScaling e.g.  sz = 5 ix = [1,3,10] spdiagm_diag(sz,(.-ix.=>1)...) source"},{"id":167,"pagetitle":"API: Functions","title":"Unfold.time_expand_allBasesSameCols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.time_expand_allBasesSameCols-Tuple{FIRBasis, Any, Any}","content":" Unfold.time_expand_allBasesSameCols  —  Method Helper function to decide whether all bases have the same number of columns per event source"},{"id":168,"pagetitle":"API: Functions","title":"Unfold.timeexpand_cols","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.timeexpand_cols-NTuple{4, Any}","content":" Unfold.timeexpand_cols  —  Method timeexpand_cols(basisfunction, bases, ncolsBasis, ncolsX)\n calculates in which rows the individual event-basisfunctions should go in Xdc see also timeexpand rows timeexpand vals source"},{"id":169,"pagetitle":"API: Functions","title":"Unfold.timeexpand_rows","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.timeexpand_rows-NTuple{4, Any}","content":" Unfold.timeexpand_rows  —  Method timeexpand_rows(onsets, bases, shift, ncolsX)\n calculates in which rows the individual event-basisfunctions should go in Xdc timeexpand rows timeexpand vals source"},{"id":170,"pagetitle":"API: Functions","title":"Unfold.times","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.times-Union{Tuple{T}, Tuple{Type{SimpleTraits.Not{Unfold.ContinuousTimeTrait{T}}}, T}} where T<:UnfoldModel","content":" Unfold.times  —  Method times(model<:UnfoldModel) returns arrays of time-vectors, one for each basisfunction / parallel-fitted-model (MassUnivarite case) source"},{"id":171,"pagetitle":"API: Functions","title":"Unfold.unfold_apply_schema","ref":"/UnfoldDocs/Unfold.jl/stable/references/functions/#Unfold.unfold_apply_schema-Tuple{Any, Any, Any}","content":" Unfold.unfold_apply_schema  —  Method wrapper to make apply_schema mixed models as extension possible Note: type is not necessary here, but for LMM it is for multiple dispatch reasons! source"},{"id":174,"pagetitle":"API: Types","title":"Unfold.AbstractModelFit","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.AbstractModelFit","content":" Unfold.AbstractModelFit  —  Type Abstract Type to report modelresults source"},{"id":175,"pagetitle":"API: Types","title":"Unfold.BasisFunction","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.BasisFunction","content":" Unfold.BasisFunction  —  Type See FIRBasis for an examples a BasisFunction should implement: kernel() # kernel(b::BasisFunction,sample) => returns the designmatrix for that event height() # number of samples in continuous time width()  # number of coefficient columns (e.g. HRF 1 to 3, FIR=height(),except if interpolate=true ) colnames() # unique names of expanded columns times() # vector of times along expanded columns, length = height() name() # name of basisfunction collabel() [default \"colname_basis\"] # name for coeftable shift_onset() [default 0] source"},{"id":176,"pagetitle":"API: Types","title":"Unfold.DesignMatrixLinearModel","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.DesignMatrixLinearModel","content":" Unfold.DesignMatrixLinearModel  —  Type DesignMatrix Type that keeps an Array of   formulas , designmatrices  modelmatrix  (Array or Array of Arrays in case of MixedModel) and  events -dataframe  source"},{"id":177,"pagetitle":"API: Types","title":"Unfold.FIRBasis","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.FIRBasis","content":" Unfold.FIRBasis  —  Type Defines a FIRBasisfunction which can be called for each event, defining the time-expanded basis kernel mutable struct FIRBasis <: Unfold.BasisFunction times : vector of times along rows of kernel-output (in seconds) name : name of the event, should be the actual eventName in  eventcolumn  of the dataframes later shift_onset : by how many samples do we need to shift the event onsets? This number is determined by how many 'negative' timepoints the basisfunction defines interpolate : should we linearly interpolate events not on full samples? (tipp: most users would you want to call firbasis, not generate it manually) Examples julia>  b = FIRBasis(range(0,1,length=10),\"basisA\",-1) source"},{"id":178,"pagetitle":"API: Types","title":"Unfold.LinearModelFit","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.LinearModelFit","content":" Unfold.LinearModelFit  —  Type Contains the results of linearmodels (continuous and not) source"},{"id":179,"pagetitle":"API: Types","title":"Unfold.TimeExpandedTerm","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.TimeExpandedTerm","content":" Unfold.TimeExpandedTerm  —  Type Object with a  term  and an applicable  BasisFunction  and a eventfield that are later passed to the basisfunction. struct TimeExpandedTerm{T<:StatsModels.AbstractTerm} <: StatsModels.AbstractTerm term : Term that the basis function is applied to. This is regularly called in other functions to get e.g. term-coefnames and timeexpand those basisfunction : Kernel that determines what should happen to the designmatrix of the term eventfields : Which fields of the event-table should be passed to the basisfunction.Important: The first entry has to be the event-latency in samples! Examples julia>  b = TimeExpandedTerm(term,kernel,[:latencyTR,:durationTR]) source"},{"id":180,"pagetitle":"API: Types","title":"Unfold.UnfoldLinearModel","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.UnfoldLinearModel","content":" Unfold.UnfoldLinearModel  —  Type Concrete type to implement an Mass-Univariate LinearModel.  .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix modelfit  is a  Any  container for the model results source"},{"id":181,"pagetitle":"API: Types","title":"Unfold.UnfoldLinearModelContinuousTime","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.UnfoldLinearModelContinuousTime","content":" Unfold.UnfoldLinearModelContinuousTime  —  Type Concrete type to implement an deconvolution LinearModel.  .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix modelfit  is a  Any  container for the model results source"},{"id":182,"pagetitle":"API: Types","title":"Unfold.UnfoldModel","ref":"/UnfoldDocs/Unfold.jl/stable/references/types/#Unfold.UnfoldModel","content":" Unfold.UnfoldModel  —  Type using Base: @deprecate_binding The main abstract model-type of the toolbox. E.g.  UnfoldLinearModel  is a concrete type of this source"},{"id":185,"pagetitle":"Mass univariate LM","title":"Mass Univariate Linear Models (no overlap correction)","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#lm_massunivariate","content":" Mass Univariate Linear Models (no overlap correction) In this notebook we will fit regression models to simulated EEG data. We will see that we need some type of overlap correction, as the events are close in time to each other, so that the respective brain responses overlap. If you want more detailed introduction to this topic check out  our paper ."},{"id":186,"pagetitle":"Mass univariate LM","title":"Setting up & loading the data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Setting-up-and-loading-the-data","content":" Setting up & loading the data using DataFrames\nusing Unfold\nusing UnfoldMakie, CairoMakie # for plotting\nusing UnfoldSim"},{"id":187,"pagetitle":"Mass univariate LM","title":"Load Data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Load-Data","content":" Load Data We'll start with some predefined simulated continuos EEG data. We have 2000 events, 1 channel and one condition with two levels data, evts = UnfoldSim.predef_eeg()"},{"id":188,"pagetitle":"Mass univariate LM","title":"Inspection","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Inspection","content":" Inspection The data has only little noise. The underlying signal pattern is a positive-negative-positive spike. times_cont = range(0,length=200,step=1/100) # we simulated with 100hz for 0.5 seconds\n\nf,ax,h = plot(times_cont,data[1:200])\nvlines!(evts[evts.latency .<= 200, :latency] ./ 100;color=:black) # show events, latency in samples!\nax.xlabel = \"time [s]\"\nax.ylabel = \"voltage [µV]\"\nf To inspect the event dataframe we use show(first(evts, 6), allcols = true) 6×3 DataFrame \n  Row  │  continuous  condition  latency  \n     │  Float64     String     Int64    \n─────┼────────────────────────────────\n   1 │   2.77778   car             62\n   2 │  -5.0       face           132\n   3 │  -1.66667   car            196\n   4 │  -5.0       car            249\n   5 │   5.0       car            303\n   6 │  -0.555556  car            366 Every row is an experimental event. Note that  :latency  refers to time in samples, (in BIDS-specification,   :onset  would typically refer to seconds)."},{"id":189,"pagetitle":"Mass univariate LM","title":"Traditional Mass Univariate Analysis","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#Traditional-Mass-Univariate-Analysis","content":" Traditional Mass Univariate Analysis To perform a mass univariate analysis, you must complete the following steps: Split data into epochs  Specify a formula  Fit a linear model to each time point & channel Visualize the results."},{"id":190,"pagetitle":"Mass univariate LM","title":"1. Split data into epochs","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#1.-Split-data-into-epochs","content":" 1. Split data into epochs Initially, you have data with a duration that represents the whole experimental trial. You need to cut the data into small regular epochs related to the some event, e.g. start of fixation. # Unfold supports multi-channel, so we could provide matrix ch x time, which we can create like this from a vector:\ndata_r = reshape(data, (1,:))\n# cut the data into epochs\ndata_epochs, times = Unfold.epoch(data = data, tbl = evts, τ = (-0.4, 0.8), sfreq = 100); # channel x timesteps x trials\nsize(data_epochs) (1, 121, 2000) τ  specifies the epoch size. sfreq  - sampling rate, converts  τ  to samples. typeof(data_epochs) Array{Union{Missing, Float64}, 3} Note In julia,  missing  is supported throughout the ecosystem. Thus, we can have partial trials and they will be incorporated / ignored at the respective functions. Helpful functions are the julia-base  disallowmissing  and the internal  Unfold.drop_missing_epochs  functions"},{"id":191,"pagetitle":"Mass univariate LM","title":"2. Specify a formula","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#2.-Specify-a-formula","content":" 2. Specify a formula Define a formula to be applied to each time point (and each channel) relative to the event.  condition  and  continuous  are the names of the event-describing columns in  evts  that we want to use for modelling. f = @formula 0 ~ 1 + condition + continuous # note the formulas left side is `0 ~ ` for technical reasons`"},{"id":192,"pagetitle":"Mass univariate LM","title":"3. Fit a linear model to each time point & channel","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#3.-Fit-a-linear-model-to-each-time-point-and-channel","content":" 3. Fit a linear model to each time point & channel Fit the \" UnfoldModel \" (the  fit  syntax is used throughout the Julia ecosystem, with the first element indicating what kind of model to fit) m = fit(UnfoldModel, f, evts, data_epochs, times); ┌ Warning:  Missings in data - we remove any trial from data and designmatrix\n └  @ Unfold ~/work/Unfold.jl/Unfold.jl/src/solver/prepare.jl:19 Alternative way to call this model is below. This syntax allows you to fit multiple events at once. For example, replacing  Any  with  :fixation =>...  will fit this model specifically to the fixation event type. m = fit(UnfoldModel, [Any=>(f, times)], evts, data_epochs); ┌ Warning:  Missings in data - we remove any trial from data and designmatrix\n └  @ Unfold ~/work/Unfold.jl/Unfold.jl/src/solver/prepare.jl:19 Inspect the fitted model: m Note these functions to discover the model:  design ,  designmatrix ,  modelfit  and most importantly,  coeftable .  Info There are of course further methods, e.g. `coef`, `ranef`, `Unfold.formula`, `modelmatrix` which might be helpful at some point, but not important now. Using  coeftable , we can get a  tidy  DataFrames, very useful for your further analysis. first(coeftable(m), 6) 6×7 DataFrame Row channel coefname estimate eventname group stderror time Int64 String Float64 DataType Nothing Nothing Float64 1 1 (Intercept) 0.923324 Any -0.4 2 1 (Intercept) 0.978652 Any -0.39 3 1 (Intercept) 1.11101 Any -0.38 4 1 (Intercept) 1.33857 Any -0.37 5 1 (Intercept) 1.6288 Any -0.36 6 1 (Intercept) 1.93554 Any -0.35"},{"id":193,"pagetitle":"Mass univariate LM","title":"4. Visualize the results","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_mu/#4.-Visualize-the-results","content":" 4. Visualize the results Tidy DataFrames are easy to visualize using e.g. AlgebraOfGraphics.jl. Function  plot_erp  from  UnfoldMakie makes it even easier.   results = coeftable(m)\nplot_erp(results) As you can see, there is a lot going on, even in the baseline period! This is because the signal was simulated with overlapping events. In the next tutorial you will learn how to fix this."},{"id":196,"pagetitle":"LM overlap correction","title":"Linear Model with Overlap Correction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#lm_overlap","content":" Linear Model with Overlap Correction Note We recommend you briefly go over the mass-univariate linear modelling tutorial In this notebook we will fit regression models to (simulated) EEG data. We will see that we need some type of overlap correction, as the events are close in time to each other, so that the respective brain responses overlap. If you want more detailed introduction to this topic check out  our paper ."},{"id":197,"pagetitle":"LM overlap correction","title":"Setting up & loading the data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#Setting-up-and-loading-the-data","content":" Setting up & loading the data using Unfold\nusing UnfoldSim\nusing UnfoldMakie,CairoMakie\nusing DataFrames\n\ndata, evts = UnfoldSim.predef_eeg()"},{"id":198,"pagetitle":"LM overlap correction","title":"Overlap Correction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#Overlap-Correction","content":" Overlap Correction For an overlap correction analysis we will do one additional step: define a temporal basisfunction. The steps are as following: specify a temporal basisfunction specify a formula fit a linear model for each channel (one for all timepoints!) visualize the results."},{"id":199,"pagetitle":"LM overlap correction","title":"Timeexpanded / Deconvolved ModelFit","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#Timeexpanded-/-Deconvolved-ModelFit","content":" Timeexpanded / Deconvolved ModelFit"},{"id":200,"pagetitle":"LM overlap correction","title":"1. specify a temporal basisfunction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#1.-specify-a-temporal-basisfunction","content":" 1. specify a temporal basisfunction By default, we would want to use a FIR basisfunction. See  Basis Functions  for more details. basisfunction = firbasis(τ=(-0.4,.8),sfreq=100)"},{"id":201,"pagetitle":"LM overlap correction","title":"2. specify a formula","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#2.-specify-a-formula","content":" 2. specify a formula We specify the same formula as before f  = @formula 0~1+condition+continuous"},{"id":202,"pagetitle":"LM overlap correction","title":"3. fit the linear model","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#3.-fit-the-linear-model","content":" 3. fit the linear model The formula and basisfunction is not enough on their own. We also need to specify which event and which formula matches - this is important in cases where there are multiple events with different formulas bf_vec = [Any=>(f,basisfunction)] Note The  Any  means to use all rows in  evts . In case you have multiple events, you'd want to specify multiple basisfunctions e.g.     bfDict = [\"stimulus\"=>(f1,basisfunction1),                 \"response\"=>(f2,basisfunction2)] You likely have to specify a further argument to  fit :  eventcolumn=\"type\"  with  type  being the column in  evts  that codes for the event (stimulus / response in this case) Now we are ready to fit a  UnfoldLinearModel . Not that instead of  times  as in the mass-univariate case, we have to provide the  BasisFunction  type now. m = fit(UnfoldModel,bf_vec,evts,data);"},{"id":203,"pagetitle":"LM overlap correction","title":"4. Visualize the model","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lm_overlap/#4.-Visualize-the-model","content":" 4. Visualize the model Similarly to the previous tutorial, we can visualize the model results = coeftable(m)\nplot_erp(results) Cool! All overlapping activity has been removed and we recovered the simulated underlying signal."},{"id":206,"pagetitle":"Mass univariate Mixed Model","title":"Mass Univariate Linear Mixed Models","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#lmm_massunivariate","content":" Mass Univariate Linear Mixed Models using Unfold\nusing UnfoldSim\nusing MixedModels # important to load to activate the UnfoldMixedModelsExtension\nusing UnfoldMakie, CairoMakie # plotting\nusing DataFrames\nusing CategoricalArrays Important You have to run  using MixedModels  before or after loading Unfold to activate the MixedModels abilities! This notebook is similar to the  Mass Univariate Linear Models (no overlap correction) tutorial , but fits mass-univariate  mixed  models - that is, one model over all subjects, instead of one model per subject. This allows to include item effects, for example."},{"id":207,"pagetitle":"Mass univariate Mixed Model","title":"Mass Univariate Mixed Models","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#Mass-Univariate-**Mixed**-Models","content":" Mass Univariate  Mixed  Models Again we have 4 steps: Split data into epochs  Specify a formula  Fit a linear model to each time point & channel Visualize the results."},{"id":208,"pagetitle":"Mass univariate Mixed Model","title":"1. Epoching","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#1.-Epoching","content":" 1. Epoching data, evts = UnfoldSim.predef_eeg(10; return_epoched = true) # simulate 10 subjects\ndata = reshape(data, 1, size(data, 1), :) # concatenate the data into a long EEG dataset\ntimes = range(0, length = size(data, 2), step = 1 / 100)\ntransform!(evts, :subject => categorical => :subject); # :subject must be categorical, otherwise MixedModels.jl complains The  events  dataFrame has an additional column (besides being much taller):  subject first(evts, 6) 6×5 DataFrame Row subject item continuous condition latency Cat… String Float64 String Int64 1 S01 I038 2.77778 face 62 2 S01 I067 1.66667 car 132 3 S01 I032 -3.88889 face 196 4 S01 I013 -2.77778 face 249 5 S01 I058 2.77778 face 303 6 S01 I094 -1.66667 face 366"},{"id":209,"pagetitle":"Mass univariate Mixed Model","title":"2. Formula specification","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#2.-Formula-specification","content":" 2. Formula specification We define the formula. Importantly, we need to specify a random effect. We use  zerocorr  to speed up the calculation. f = @formula 0 ~ 1 + condition * continuous + zerocorr(1 + condition * continuous | subject);"},{"id":210,"pagetitle":"Mass univariate Mixed Model","title":"3. Model fitting","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#3.-Model-fitting","content":" 3. Model fitting We can now run the LinearMixedModel at each time point. m = fit(UnfoldModel, f, evts, data, times) \n Progress:   4%|█▉                                       |  ETA: 0:00:11 \n   channel:  1 \n   time:     2 \n\n\n\n\n\n Progress: 100%|█████████████████████████████████████████| Time: 0:00:00 \n   channel:  1 \n   time:     45"},{"id":211,"pagetitle":"Mass univariate Mixed Model","title":"4. Visualization of results","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#4.-Visualization-of-results","content":" 4. Visualization of results Let's start with the  fixed  effects.  We see the condition effects and some residual overlap activity in the fixed effects. results = coeftable(m)\n\nres_fixef = results[isnothing.(results.group), :]\nplot_erp(res_fixef) And now comes the  random  effect: res_ranef = results[results.group .== :subject, :]\nplot_erp(res_ranef)"},{"id":212,"pagetitle":"Mass univariate Mixed Model","title":"Statistics","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_mu/#Statistics","content":" Statistics Check out the  LMM p-value tutorial"},{"id":215,"pagetitle":"LMM + overlap correction","title":"Overlap Correction with Linear Mixed Models","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#lmm_overlap","content":" Overlap Correction with Linear Mixed Models using Unfold\nusing UnfoldSim\n\nusing CategoricalArrays\nusing MixedModels\nusing UnfoldMakie, CairoMakie\nusing DataFrames This notebook is similar to the Linear Model with Overlap Correction tutorial, but fits  mixed  models with overlap correction Warning Limitation : This functionality is not ready for general use. There are still a lot of things to find out and tinker with. Don't use this if you haven't looked under the hood of the toolbox! Be aware of crashes / timeouts for non-trivial problems"},{"id":216,"pagetitle":"LMM + overlap correction","title":"Get some data","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#Get-some-data","content":" Get some data dat, evts = UnfoldSim.predef_2x2(; signalsize=20, n_items=16, n_subjects=16)\n\n# We also need to fix the latencies, they are now relative to 1:size(data, 1), but we want a continuous long EEG.\nsubj_idx = [parse(Int, split(string(s), 'S')[2]) for s in evts.subject]\nevts.latency .+= size(dat, 1) .* (subj_idx .- 1)\n\ndat = dat[:] # we need all data concatenated over subjects\nevts.subject  = categorical(Array(evts.subject))"},{"id":217,"pagetitle":"LMM + overlap correction","title":"Linear Mixed Model Continuous Time","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#Linear-**Mixed**-Model-Continuous-Time","content":" Linear  Mixed  Model Continuous Time Again we have 4 steps: Specify a temporal basisfunction Specify a formula Fit a linear model for each channel (one model for all timepoints!) Visualize the results."},{"id":218,"pagetitle":"LMM + overlap correction","title":"1. Specify a temporal basisfunction","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#1.-Specify-a-temporal-basisfunction","content":" 1. Specify a temporal basisfunction By default, we would want to use a FIR basis function. See  Basis Functions  for more details. basisfunction = firbasis(τ=(-0.4, .8), sfreq=20, name=\"stimulus\")"},{"id":219,"pagetitle":"LMM + overlap correction","title":"2. Specify the formula","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#2.-Specify-the-formula","content":" 2. Specify the formula Define the formula and specify a random effect.  Note We use  zerocorr  to prevent the model from computing all correlations between all timepoints and factors. f  = @formula 0 ~ 1 + A  *B + zerocorr(1 + A*B|subject); FormulaTerm\nResponse:\n  0\nPredictors:\n  1\n  A(unknown)\n  B(unknown)\n  A(unknown) & B(unknown)\n  (A,B,subject)->zerocorr((1 + A * B) | subject)"},{"id":220,"pagetitle":"LMM + overlap correction","title":"3. Fit the model","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#3.-Fit-the-model","content":" 3. Fit the model bfDict = Dict(Any=>(f, basisfunction))\n# Skipping this tutorial for now due to a significant error.\nm = fit(UnfoldModel, bfDict, evts, dat)\n\nresults = coeftable(m)\nfirst(results, 6) 6×7 DataFrame Row channel coefname estimate eventname group stderror time Int64 String Float64 Union… Union… Nothing Float64 1 1 (Intercept) 0.0728554 Any -0.4 2 1 (Intercept) 0.0941947 Any -0.35 3 1 (Intercept) 0.0694752 Any -0.3 4 1 (Intercept) 0.00866136 Any -0.25 5 1 (Intercept) -0.0422579 Any -0.2 6 1 (Intercept) -0.0524441 Any -0.15"},{"id":221,"pagetitle":"LMM + overlap correction","title":"4. Visualize results","ref":"/UnfoldDocs/Unfold.jl/stable/tutorials/lmm_overlap/#4.-Visualize-results","content":" 4. Visualize results plot_erp(results; mapping=(; col = :group))"},{"id":224,"pagetitle":"UnfoldMixedModels","title":"UnfoldMixedModels","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/#UnfoldMixedModels","content":" UnfoldMixedModels Documentation for  UnfoldMixedModels . Using this package, one can fit Linear Mixed Models in a mass-univariate way (for every time-point and channel); but also combined with overlap correction (experimental!) As  UnfoldMixedModels.jl  is like an  addon  to  Unfold.jl , we recommend checking out these tutorials first. using UnfoldMixedModels\nusing UnfoldSim\ndata, evts = UnfoldSim.predef_eeg(10;return_epoched=true) # 10 subjects\ndata = reshape(data,size(data,1),:) # concatenate subjects\n\ntimes = range(-0.1,0.5,size(data,1)) # arbitrary time-vector\n\nfLMM = @formula 0 ~ 1 + condition + (1|subject) + (1|item)\nfit(UnfoldModel, [Any=>(f, times)], evts, data)\nnothing #hide"},{"id":227,"pagetitle":"Contributing guidelines","title":"Contributing guidelines","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/90-contributing/#contributing","content":" Contributing guidelines First of all, thanks for the interest! We welcome all kinds of contribution, including, but not limited to code, documentation, examples, configuration, issue creating, etc. Be polite and respectful, and follow the code of conduct."},{"id":228,"pagetitle":"Contributing guidelines","title":"Bug reports and discussions","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/90-contributing/#Bug-reports-and-discussions","content":" Bug reports and discussions If you think you found a bug, feel free to open an  issue . Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please."},{"id":229,"pagetitle":"Contributing guidelines","title":"Working on an issue","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/90-contributing/#Working-on-an-issue","content":" Working on an issue If you found an issue that interests you, comment on that issue what your plans are. If the solution to the issue is clear, you can immediately create a pull request (see below). Otherwise, say what your proposed solution is and wait for a discussion around it. Tip Feel free to ping us after a few days if there are no responses. If your solution involves code (or something that requires running the package locally), check the  developer documentation . Otherwise, you can use the GitHub interface directly to create your pull request."},{"id":232,"pagetitle":"Developer documentation","title":"Developer documentation","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#dev_docs","content":" Developer documentation Contributing guidelines If you haven't, please read the  Contributing guidelines  first. If you want to make contributions to this package that involves code, then this guide is for you."},{"id":233,"pagetitle":"Developer documentation","title":"First time clone","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#First-time-clone","content":" First time clone If you have writing rights If you have writing rights, you don't have to fork. Instead, simply clone and skip ahead. Whenever  upstream  is mentioned, use  origin  instead. If this is the first time you work with this repository, follow the instructions below to clone the repository. Fork this repo Clone your repo (this will create a  git remote  called  origin ) Add this repo as a remote: git remote add upstream https://github.com/unfoldtoolbox/UnfoldMixedModels.jl This will ensure that you have two remotes in your git:  origin  and  upstream . You will create branches and push to  origin , and you will fetch and update your local  main  branch from  upstream ."},{"id":234,"pagetitle":"Developer documentation","title":"Linting and formatting","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Linting-and-formatting","content":" Linting and formatting Install a plugin on your editor to use  EditorConfig . This will ensure that your editor is configured with important formatting settings. We use  https://pre-commit.com  to run the linters and formatters. In particular, the Julia code is formatted using  JuliaFormatter.jl , so please install it globally first: julia> # Press ]\npkg> activate\npkg> add JuliaFormatter To install  pre-commit , we recommend using  pipx  as follows: # Install pipx following the link\npipx install pre-commit With  pre-commit  installed, activate it as a pre-commit hook: pre-commit install To run the linting and formatting manually, enter the command below: pre-commit run -a Now, you can only commit if all the pre-commit tests pass ."},{"id":235,"pagetitle":"Developer documentation","title":"Testing","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Testing","content":" Testing As with most Julia packages, you can just open Julia in the repository folder, activate the environment, and run  test : julia> # press ]\npkg> activate .\npkg> test"},{"id":236,"pagetitle":"Developer documentation","title":"Working on a new issue","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Working-on-a-new-issue","content":" Working on a new issue We try to keep a linear history in this repo, so it is important to keep your branches up-to-date. Fetch from the remote and fast-forward your local main git fetch upstream\ngit switch main\ngit merge --ff-only upstream/main Branch from  main  to address the issue (see below for naming) git switch -c 42-add-answer-universe Push the new local branch to your personal remote repository git push -u origin 42-add-answer-universe Create a pull request to merge your remote branch into the org main."},{"id":237,"pagetitle":"Developer documentation","title":"Branch naming","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Branch-naming","content":" Branch naming If there is an associated issue, add the issue number. If there is no associated issue,  and the changes are small , add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update. If the changes are not small and there is no associated issue, then create the issue first, so we can properly discuss the changes. Use dash separated imperative wording related to the issue (e.g.,  14-add-tests ,  15-fix-model ,  16-remove-obsolete-files )."},{"id":238,"pagetitle":"Developer documentation","title":"Commit message","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Commit-message","content":" Commit message Use imperative or present tense, for instance:  Add feature  or  Fix bug . Have informative titles. When necessary, add a body with details. If there are breaking changes, add the information to the commit message."},{"id":239,"pagetitle":"Developer documentation","title":"Before creating a pull request","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Before-creating-a-pull-request","content":" Before creating a pull request Atomic git commits Try to create \"atomic git commits\" (recommended reading:  The Utopic Git History ). Make sure the tests pass. Make sure the pre-commit tests pass. Fetch any  main  updates from upstream and rebase your branch, if necessary: git fetch upstream\ngit rebase upstream/main BRANCH_NAME Then you can open a pull request and work with the reviewer to address any issues."},{"id":240,"pagetitle":"Developer documentation","title":"Building and viewing the documentation locally","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/91-developer/#Building-and-viewing-the-documentation-locally","content":" Building and viewing the documentation locally Following the latest suggestions, we recommend using  LiveServer  to build the documentation. Here is how you do it: Run  julia --project=docs  to open Julia in the environment of the docs. If this is the first time building the docs Press  ]  to enter  pkg  mode Run  pkg> dev .  to use the development version of your package Press backspace to leave  pkg  mode Run  julia> using LiveServer Run  julia> servedocs()"},{"id":243,"pagetitle":"P-values for mixedModels","title":"How To get P-Values for Mass-Univariate LMM","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#lmm_pvalues","content":" How To get P-Values for Mass-Univariate LMM There are currently two ways to obtain p-values for LMMs: Wald's t-test and likelihood ratio tests (mass univariate only)."},{"id":244,"pagetitle":"P-values for mixedModels","title":"Setup","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Setup","content":" Setup using UnfoldMixedModels # we require to load MixedModels to load the PackageExtension\nusing DataFrames\nusing UnfoldSim\nusing CairoMakie\ndata_epoch, evts =\n    UnfoldSim.predef_2x2(; n_items = 52, n_subjects = 40, return_epoched = true)\ndata_epoch = reshape(data_epoch, size(data_epoch, 1), :) #\ntimes = range(0, 1, length = size(data_epoch, 1)) 0.0:0.010101010101010102:1.0"},{"id":245,"pagetitle":"P-values for mixedModels","title":"Define f0 & f1 and fit","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Define-f0-and-f1-and-fit","content":" Define f0 & f1 and fit f0 = @formula 0 ~ 1 + A + (1 + A | subject);\nf1 = @formula 0 ~ 1 + A + B + (1 + A | subject); # could also differ in random effects\n\nm0 = fit(UnfoldModel,[Any=>(f0,times)],evts,data_epoch);\nm1 = fit(UnfoldModel,[Any=>(f1,times)],evts,data_epoch);"},{"id":246,"pagetitle":"P-values for mixedModels","title":"Likelihood ratio","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Likelihood-ratio","content":" Likelihood ratio uf_lrt = likelihoodratiotest(data_epoch, m0, m1)\nuf_lrt[1] model-dof deviance χ² χ²-dof P(>χ²) �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 6 8012 �[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m+�[39m B �[38;2;239;83;80m+�[39m (�[38;2;144;202;249m1�[39m �[38;2;239;83;80m+�[39m A �[38;2;239;83;80m|�[39m subject) 7 8011 1 1 0.3996 As you can see, we have some likelihood ratio outcomes, exciting!"},{"id":247,"pagetitle":"P-values for mixedModels","title":"Extract p-values","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Extract-p-values","content":" Extract p-values pvalues(uf_lrt) 100-element Vector{Vector{Float64}}:\n [0.39964251754876706]\n [0.4019640858609401]\n [0.4074237173863722]\n [0.4070454519554564]\n [0.42228971014118033]\n [0.483155056260971]\n [0.6339437552710293]\n [NaN]\n [NaN]\n [NaN]\n ⋮\n [0.34292883003473407]\n [0.33515969561309156]\n [0.33325396532570495]\n [0.3428036624385943]\n [0.3567742512609538]\n [0.37049189795207205]\n [0.38051461402659575]\n [0.3883891630406846]\n [0.39851721772119286] We have extracted the p-values and now need to make them usable.     The solution can be found in the documentation under  ?pvalues . pvals_lrt = vcat(pvalues(uf_lrt)...)\nnchan = 1\nntime = length(times)\nreshape(pvals_lrt, ntime, nchan)' # note the last transpose via ' ! 1×100 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.399643  0.401964  0.407424  0.407045  …  0.380515  0.388389  0.398517 Perfecto, these are the LRT p-values of a model  condA  vs.  condA+condB  with same random effect structure."},{"id":248,"pagetitle":"P-values for mixedModels","title":"Walds T-Test","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Walds-T-Test","content":" Walds T-Test This method is easier to calculate but has limitations in accuracy and scope. It may also be less accurate due to the liberal estimation of degrees of freedom. Testing is limited in this case, as random effects cannot be tested and only single predictors can be used, which may not be appropriate for spline effects. It is important to note that this discussion is beyond the scope of this LMM package. res = coeftable(m1)\n# only fixed effects: what is not in a ranef group is a fixef.\nres = res[isnothing.(res.group), :]\n# calculate t-value\nres[:, :tvalue] = res.estimate ./ res.stderror 300-element Vector{Float64}:\n  4.446708326696426\n  4.437580860011641\n  4.446435058073349\n  4.492672997803976\n  4.494599457419684\n  4.4880483252027075\n  4.439652303422133\n  4.45518635490581\n  4.623068236549389\n  4.663764726700654\n  ⋮\n  0.5870708293447756\n  0.43759939804174963\n  0.2172917074185397\n  0.025591530320948425\n -0.11195974844949615\n -0.28040792854804225\n -0.22668554132390997\n -0.2646530795209725\n -0.3492299276363734 We obtained Walds t, but how to translate them to a p-value? Determining the necessary degrees of freedom for the t-distribution is a complex issue with much debate surrounding it. One approach is to use the number of subjects as an upper bound for the p-value (your df will be between  $n_{subject}$  and  $\\sum{n_{trials}}$ ). df = length(unique(evts.subject)) 40 Plug it into the t-distribution. using Distributions\nres.pvalue = pdf.(TDist(df),res.tvalue) 300-element Vector{Float64}:\n 0.00010520592926163251\n 0.00010817494439425095\n 0.00010529365405567558\n 9.142141916777313e-5\n 9.088393516836884e-5\n 9.272440215982806e-5\n 0.00010749405443829126\n 0.00010251943544603832\n 6.122445474960627e-5\n 5.398423858898151e-5\n ⋮\n 0.33251660178615255\n 0.3594809847897533\n 0.38698410798874533\n 0.39632387743397085\n 0.39391857391788004\n 0.38081351375847516\n 0.38615884540577883\n 0.3824900521283194\n 0.37247026276880874"},{"id":249,"pagetitle":"P-values for mixedModels","title":"Comparison of methods","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/howto/lmm_pvalues/#Comparison-of-methods","content":" Comparison of methods Cool! Let's compare both methods of p-value calculation! df = DataFrame(:walds => res[res.coefname.==\"B: b_tiny\", :pvalue], :lrt => pvals_lrt)\nf = Figure()\n\nscatter(f[1,1],times,res[res.coefname .== \"B: b_tiny\",:estimate],axis=(;xlabel=\"time\",title=\"coef: B:b_tiny\"))\nscatter(f[1,2],df.walds,df.lrt,axis=(;title=\"walds-t pvalue\",ylabel=\"LRT pvalue\"))\nscatter(f[2,1],times,df.walds,axis=(;title=\"walds-t pvalue\",xlabel=\"time\"))\nscatter(f[2,2],times,df.lrt,axis=(;title=\"lrt pvalue\",xlabel=\"time\"))\n\nf Look pretty similar! Note that the Walds-T is typically too liberal (LRT also, but to a lesser exted). Best is to use the forthcoming MixedModelsPermutations.jl or go the route via R and use KenwardRoger (data not yet published)"},{"id":252,"pagetitle":"API: Functions","title":"MixedModels.likelihoodratiotest","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#MixedModels.likelihoodratiotest-Tuple{AbstractArray, Vararg{UnfoldLinearMixedModel}}","content":" MixedModels.likelihoodratiotest  —  Method likelihoodratiotest(data, m)\n Calculate likelihoodratiotest source"},{"id":253,"pagetitle":"API: Functions","title":"StatsAPI.fit!","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#StatsAPI.fit!-Union{Tuple{T}, Tuple{Union{UnfoldLinearMixedModel, UnfoldLinearMixedModelContinuousTime}, AbstractArray{T}}} where T","content":" StatsAPI.fit!  —  Method fit!(uf::UnfoldModel,data::Union{<:AbstractArray{T,2},<:AbstractArray{T,3}}) where {T<:Union{Missing, <:Number}} Fit a DesignMatrix against a 2D/3D Array data along its last dimension Data is typically interpreted as channel x time (with basisfunctions) or channel x time x epoch (for mass univariate) show_progress  (default:true), deactivate the progressmeter Returns an UnfoldModel object Examples source"},{"id":254,"pagetitle":"API: Functions","title":"StatsModels.modelcols","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#StatsModels.modelcols-Tuple{Unfold.TimeExpandedTerm{<:Union{var\"#s1\", var\"#s118\"} where {var\"#s1\"<:RandomEffectsTerm, var\"#s118\"<:MixedModels.AbstractReTerm}}, Any}","content":" StatsModels.modelcols  —  Method modelcols(term, tbl)\n This function timeexpands the random effects and generates a ReMat object source"},{"id":255,"pagetitle":"API: Functions","title":"Unfold.make_estimate","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#Unfold.make_estimate-Tuple{Union{UnfoldLinearMixedModel, UnfoldLinearMixedModelContinuousTime}}","content":" Unfold.make_estimate  —  Method Unfold.make_estimate(m::Union{UnfoldLinearMixedModel,UnfoldLinearMixedModelContinuousTime}, ) extracts betas (and sigma's for mixed models) with string grouping indicator returns as a ch x beta, or ch x time x beta (for mass univariate) source"},{"id":256,"pagetitle":"API: Functions","title":"Unfold.modelmatrices","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#Unfold.modelmatrices-Tuple{Tuple}","content":" Unfold.modelmatrices  —  Method modelmatrices(modelmatrix::Tuple) in the case of a Tuple (MixedModels - FeMat/ReMat Tuple), returns only the FeMat part source"},{"id":257,"pagetitle":"API: Functions","title":"UnfoldMixedModels.LinearMixedModel_wrapper","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.LinearMixedModel_wrapper-Union{Tuple{TData}, Tuple{Any, AbstractVector{<:TData}, Any}} where TData<:Number","content":" UnfoldMixedModels.LinearMixedModel_wrapper  —  Method LinearMixedModel_wrapper(form, data, Xs; wts)\n Wrapper to generate a LinearMixedModel. Code taken from MixedModels.jl and slightly adapted. source"},{"id":258,"pagetitle":"API: Functions","title":"UnfoldMixedModels.fake_lmm","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.fake_lmm-Union{Tuple{N}, Tuple{AbstractArray{<:Number, N}, UnfoldLinearMixedModel, Int64}} where N","content":" UnfoldMixedModels.fake_lmm  —  Method fake_lmm(data, m, k)\n Returns a partial LMM model (non-functional due to lacking data) to be used in likelihoodratiotests.  k  to selcet which of the modelfit's to fake source"},{"id":259,"pagetitle":"API: Functions","title":"UnfoldMixedModels.get_timeexpanded_random_grouping","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.get_timeexpanded_random_grouping-Tuple{Any, Any, Any}","content":" UnfoldMixedModels.get_timeexpanded_random_grouping  —  Method get_timeexpanded_random_grouping(\n    tbl_group,\n    tbl_latencies,\n    basisfunction\n)\n Get the timeranges where the random grouping variable was applied source"},{"id":260,"pagetitle":"API: Functions","title":"UnfoldMixedModels.isa_lmm_formula","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.isa_lmm_formula-Tuple{typeof(zerocorr)}","content":" UnfoldMixedModels.isa_lmm_formula  —  Method isa_lmm_formula iterates over all parts of a formula until either a  MixedModels.zerocorr , or a  |  was found. Then returns true, else returns false. source"},{"id":261,"pagetitle":"API: Functions","title":"UnfoldMixedModels.pvalues","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.pvalues-Tuple{Vector{MixedModels.LikelihoodRatioTest}}","content":" UnfoldMixedModels.pvalues  —  Method pvalues(lrtvec)\n Unfold-Method: return pvalues of likelihoodratiotests, typically calculated: Examples julia> pvalues(likelihoodratiotest(m1,m2)) where m1/m2 are UnfoldLinearMixedModel's Tipp: if you only compare two models you can easily get a vector of p-values: julia> vcat(pvalues(likelihoodratiotest(m1,m2))...) Multiple channels are returned linearized at the moment, as we do not have access to the amount of channels after the LRT, you can do: julia> reshape(vcat(pvalues(likelihoodratiotest(m1,m2))...),ntimes,nchan)' source"},{"id":262,"pagetitle":"API: Functions","title":"UnfoldMixedModels.random_effect_groupings","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.random_effect_groupings-Tuple{StatsModels.AbstractTerm}","content":" UnfoldMixedModels.random_effect_groupings  —  Method random_effect_groupings(t::MixedModels.AbstractReTerm) Returns the random effect grouping term (rhs), similar to coefnames, which returns the left hand sides source"},{"id":263,"pagetitle":"API: Functions","title":"UnfoldMixedModels.reorder_tidyσs","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/functions/#UnfoldMixedModels.reorder_tidyσs-Tuple{Any, Any}","content":" UnfoldMixedModels.reorder_tidyσs  —  Method reorder_tidyσs(t, f) This function reorders a MixedModels.tidyσs output, according to the formula and not according to the largest RandomGrouping. source"},{"id":266,"pagetitle":"API: Types","title":"UnfoldMixedModels.UnfoldLinearMixedModel","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/types/#UnfoldMixedModels.UnfoldLinearMixedModel","content":" UnfoldMixedModels.UnfoldLinearMixedModel  —  Type Concrete type to implement an Mass-Univariate LinearMixedModel.  .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix modelfit  is a  Any  container for the model results source"},{"id":267,"pagetitle":"API: Types","title":"UnfoldMixedModels.UnfoldLinearMixedModelContinuousTime","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/references/types/#UnfoldMixedModels.UnfoldLinearMixedModelContinuousTime","content":" UnfoldMixedModels.UnfoldLinearMixedModelContinuousTime  —  Type Concrete type to implement an deconvolution LinearMixedModel. Warning  This is to be treated with care, not much testing went into it. .design  contains the formula + times dict  .designmatrix  contains a  DesignMatrix .modelfit  is a  Any  container for the model results source"},{"id":270,"pagetitle":"lmmERP (mass univariate)","title":"Mass Univariate Linear Mixed Models","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#lmm_massunivariate","content":" Mass Univariate Linear Mixed Models using UnfoldMixedModels\nusing UnfoldSim\n\nusing UnfoldMakie, CairoMakie # plotting\nusing DataFrames\nusing CategoricalArrays This notebook is similar to the  Unfold.jl Mass Univariate Linear Models (no overlap correction) tutorial , but fits mass-univariate  mixed  models - that is, one model over all subjects, instead of one model per subject. This allows to include item effects, for example."},{"id":271,"pagetitle":"lmmERP (mass univariate)","title":"Mass Univariate Mixed Models","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#Mass-Univariate-**Mixed**-Models","content":" Mass Univariate  Mixed  Models Again we have 4 steps: Split data into epochs Specify a formula Fit a linear model to each time point & channel Visualize the results."},{"id":272,"pagetitle":"lmmERP (mass univariate)","title":"1. Epoching","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#1.-Epoching","content":" 1. Epoching data, evts = UnfoldSim.predef_eeg(10; return_epoched = true) # simulate 10 subjects\ndata = reshape(data, 1, size(data, 1), :) # concatenate the data into a long EEG dataset\ntimes = range(0, length = size(data, 2), step = 1 / 100)\ntransform!(evts, :subject => categorical => :subject); # :subject must be categorical, otherwise MixedModels.jl complains The  events  dataFrame has an additional column (besides being much taller):  subject first(evts, 6) 6×5 DataFrame Row subject item continuous condition latency Cat… String Float64 String Int64 1 S01 I038 2.77778 face 62 2 S01 I067 1.66667 car 132 3 S01 I032 -3.88889 face 196 4 S01 I013 -2.77778 face 249 5 S01 I058 2.77778 face 303 6 S01 I094 -1.66667 face 366"},{"id":273,"pagetitle":"lmmERP (mass univariate)","title":"2. Formula specification","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#2.-Formula-specification","content":" 2. Formula specification We define the formula. Importantly, we need to specify a random effect. We use  zerocorr  to speed up the calculation. f = @formula 0 ~ 1 + condition * continuous + zerocorr(1 + condition * continuous | subject);"},{"id":274,"pagetitle":"lmmERP (mass univariate)","title":"3. Model fitting","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#3.-Model-fitting","content":" 3. Model fitting We can now run the LinearMixedModel at each time point. m = fit(UnfoldModel, f, evts, data, times) \nProgress:   4%|█▉                                       |  ETA: 0:00:12\n  channel:  1\n  time:     2\n\n\n\n\n\nProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\n  channel:  1\n  time:     45"},{"id":275,"pagetitle":"lmmERP (mass univariate)","title":"4. Visualization of results","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#4.-Visualization-of-results","content":" 4. Visualization of results Let's start with the  fixed  effects. We see the condition effects and some residual overlap activity in the fixed effects. results = coeftable(m)\n\nres_fixef = results[isnothing.(results.group), :]\nplot_erp(res_fixef) And now comes the  random  effect: res_ranef = results[results.group .== :subject, :]\nplot_erp(res_ranef)"},{"id":276,"pagetitle":"lmmERP (mass univariate)","title":"Statistics","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_mu/#Statistics","content":" Statistics Check out the  LMM p-value tutorial"},{"id":279,"pagetitle":"lmmERP (overlap correction)","title":"Overlap Correction with Linear Mixed Models","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#lmm_overlap","content":" Overlap Correction with Linear Mixed Models using UnfoldMixedModels\n\nusing UnfoldSim\n\nusing CategoricalArrays\nusing UnfoldMakie, CairoMakie\nusing DataFrames This notebook is similar to the Linear Model with Overlap Correction tutorial, but fits  mixed  models with overlap correction Warning Limitation : This functionality is not ready for general use. There are still a lot of things to find out and tinker with. Don't use this if you haven't looked under the hood of the toolbox! Be aware of crashes / timeouts for non-trivial problems"},{"id":280,"pagetitle":"lmmERP (overlap correction)","title":"Get some data","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#Get-some-data","content":" Get some data dat, evts = UnfoldSim.predef_2x2(; signalsize=20, n_items=16, n_subjects=16)\n\n# We also need to fix the latencies, they are now relative to 1:size(data, 1), but we want a continuous long EEG.\nsubj_idx = [parse(Int, split(string(s), 'S')[2]) for s in evts.subject]\nevts.latency .+= size(dat, 1) .* (subj_idx .- 1)\n\ndat = dat[:] # we need all data concatenated over subjects\nevts.subject  = categorical(Array(evts.subject))"},{"id":281,"pagetitle":"lmmERP (overlap correction)","title":"Linear Mixed Model Continuous Time","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#Linear-**Mixed**-Model-Continuous-Time","content":" Linear  Mixed  Model Continuous Time Again we have 4 steps: Specify a temporal basisfunction Specify a formula Fit a linear model for each channel (one model for all timepoints!) Visualize the results."},{"id":282,"pagetitle":"lmmERP (overlap correction)","title":"1. Specify a temporal basisfunction","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#1.-Specify-a-temporal-basisfunction","content":" 1. Specify a temporal basisfunction By default, we would want to use a FIR basis function. basisfunction = firbasis(τ=(-0.4, .8), sfreq=20, name=\"stimulus\")"},{"id":283,"pagetitle":"lmmERP (overlap correction)","title":"2. Specify the formula","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#2.-Specify-the-formula","content":" 2. Specify the formula Define the formula and specify a random effect. Note We use  zerocorr  to prevent the model from computing all correlations between all timepoints and factors. f  = @formula 0 ~ 1 + A  *B + zerocorr(1 + A*B|subject); FormulaTerm\nResponse:\n  0\nPredictors:\n  1\n  A(unknown)\n  B(unknown)\n  A(unknown) & B(unknown)\n  (A,B,subject)->zerocorr((1 + A * B) | subject)"},{"id":284,"pagetitle":"lmmERP (overlap correction)","title":"3. Fit the model","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#3.-Fit-the-model","content":" 3. Fit the model bfDict = [Any=>(f, basisfunction)]\n# Skipping this tutorial for now due to a significant error.\nm = fit(UnfoldModel, bfDict, evts, dat)\n\nresults = coeftable(m)\nfirst(results, 6) 6×7 DataFrame Row channel coefname estimate eventname group stderror time Int64 String Float64 Union… Union… Nothing Float64 1 1 (Intercept) 0.0728554 Any -0.4 2 1 (Intercept) 0.0941947 Any -0.35 3 1 (Intercept) 0.0694752 Any -0.3 4 1 (Intercept) 0.00866136 Any -0.25 5 1 (Intercept) -0.0422579 Any -0.2 6 1 (Intercept) -0.0524441 Any -0.15"},{"id":285,"pagetitle":"lmmERP (overlap correction)","title":"4. Visualize results","ref":"/UnfoldDocs/UnfoldMixedModels.jl/stable/tutorials/lmm_overlap/#4.-Visualize-results","content":" 4. Visualize results plot_erp(results; mapping=(; col = :group))"},{"id":288,"pagetitle":"Home","title":"UnfoldSim.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#UnfoldSim.jl","content":" UnfoldSim.jl Documentation for  UnfoldSim.jl : a Julia package for simulating multivariate timeseries data with a special focus on EEG data."},{"id":289,"pagetitle":"Home","title":"Start simulating time series data","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Start-simulating-time-series-data","content":" Start simulating time series data We offer some predefined (EEG) signals, check them out! For instance a P1/N170/P300 complex (containing three typical ERP components). using UnfoldSim\nusing CairoMakie # plotting\n\ndata, evts = UnfoldSim.predef_eeg(; n_repeats = 1, noiselevel = 0.8)\n\nlines(data; color = \"black\")\nvlines!(evts.latency; color = [\"orange\", \"teal\"][1 .+ (evts.condition.==\"car\")])\n\ncurrent_figure()"},{"id":290,"pagetitle":"Home","title":"Or simulate epoched data directly","ref":"/UnfoldDocs/UnfoldSim.jl/stable/#Or-simulate-epoched-data-directly","content":" Or simulate epoched data directly data, evts = UnfoldSim.predef_eeg(; n_repeats = 20, noiselevel = 0.8, return_epoched = true)\nheatmap(data[:, sortperm(evts, [:condition, :continuous])])"},{"id":293,"pagetitle":"API / Docstrings","title":"UnfoldSim.AutoRegressiveNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.AutoRegressiveNoise","content":" UnfoldSim.AutoRegressiveNoise  —  Type AutoRegressiveNoise <: AbstractNoise Not implemented source"},{"id":294,"pagetitle":"API / Docstrings","title":"UnfoldSim.ExponentialNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.ExponentialNoise","content":" UnfoldSim.ExponentialNoise  —  Type ExponentialNoise <: AbstractNoise Noise with exponential decay in AR spectrum. noiselevel  is used to scale the noise Warning With the current implementation we try to get exponential decay over the whole autoregressive (AR) spectrum, which is N samples (the total number of samples in the signal) long. This involves the inversion of a Cholesky matrix of size NxN matrix, which will need lots of RAM for non-trivial problems. source"},{"id":295,"pagetitle":"API / Docstrings","title":"UnfoldSim.LinearModelComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.LinearModelComponent","content":" UnfoldSim.LinearModelComponent  —  Type A multiple regression component for one subject basis : an object, if accessed, provides a 'basis-function', e.g.  hanning(40) , this defines the response at a single event. It will be weighted by the model-prediction formula : StatsModels Formula-Object   @formula 0~1+cond  (left side must be 0) β  Vector of betas, must fit the formula contrasts : Dict. Default is empty, e.g.  Dict(:condA=>EffectsCoding()) All arguments can be named, in that case  contrasts  is optional Works best with  SingleSubjectDesign LinearModelComponent(;\n    basis=hanning(40),\n    formula=@formula(0~1+cond),\n    β = [1.,2.],\n    contrasts=Dict(:cond=>EffectsCoding())\n)\n source"},{"id":296,"pagetitle":"API / Docstrings","title":"UnfoldSim.LogNormalOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.LogNormalOnset","content":" UnfoldSim.LogNormalOnset  —  Type @with_kw struct LogNormalOnset <: AbstractOnset Log-normal inter-event distances using the  Distributions.jl  truncated LogNormal distribution. Be careful with large  μ  and  σ  values, as they are on logscale. σ>8 can quickly give you out-of-memory sized signals! source"},{"id":297,"pagetitle":"API / Docstrings","title":"UnfoldSim.MixedModelComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.MixedModelComponent","content":" UnfoldSim.MixedModelComponent  —  Type A component that adds a hierarchical relation between parameters according to a LMM defined via MixedModels.jl basis : an object, if accessed, provides a 'basis-function', e.g.  hanning(40) , this defines the response at a single event. It will be weighted by the model-prediction formula : Formula-Object in the style of MixedModels.jl e.g.  @formula 0~1+cond + (1|subject)  - left-handside is ignored β  Vector of betas, must fit the formula σs  Dict of random effect variances, e.g.  Dict(:subject=>[0.5,0.4])  or to specify correlationmatrix  Dict(:subject=>[0.5,0.4,I(2,2)],...) . Technically, this will be passed to MixedModels.jl  create_re  function, which creates the θ matrices. contrasts : Dict in the style of MixedModels.jl. Default is empty. All arguments can be named, in that case  contrasts  is optional Works best with  MultiSubjectDesign MixedModelComponent(;\n    basis=hanning(40),\n    formula=@formula(0~1+cond+(1+cond|subject)),\n    β = [1.,2.],\n    σs= Dict(:subject=>[0.5,0.4]),\n    contrasts=Dict(:cond=>EffectsCoding())\n)\n source"},{"id":298,"pagetitle":"API / Docstrings","title":"UnfoldSim.MultiSubjectDesign","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.MultiSubjectDesign","content":" UnfoldSim.MultiSubjectDesign  —  Type MultiSubjectDesign <: AbstractDesign A type for specifying the experimental design for multiple subjects (based on the given random-effects structure). Fields n_subjects ::Int -> number of subjects n_items ::Int -> number of items (sometimes ≈trials) subjects_between  = Dict{Symbol,Vector} -> effects between subjects, e.g. young vs old  items_between  = Dict{Symbol,Vector} -> effects between items, e.g. natural vs artificial images, (but shown to all subjects if not specified also in  subjects_between ) both_within  = Dict{Symbol,Vector}\t-> effects completly crossed event_order_function  =  x->x ; # can be used to sort, or e.g.  x->shuffle(MersenneTwister(42),x)  - be sure to fix/update the rng accordingly!! Tip: Check the resulting dataframe using  generate_events(design) Example # declaring same condition both sub-between and item-between results in a full between subject/item design\ndesign = MultiSubjectDesign(;\n\t\tn_items = 10,\n\t\tn_subjects = 30,\n\t\tsubjects_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n\t\titems_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n\t\t); See also  SingleSubjectDesign ,  RepeatDesign source"},{"id":299,"pagetitle":"API / Docstrings","title":"UnfoldSim.MultichannelComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.MultichannelComponent","content":" UnfoldSim.MultichannelComponent  —  Type Wrapper for an  AbstractComponent  to project it to multiple target-channels via  projection . optional adds  noise  to the source prior to projection. source"},{"id":300,"pagetitle":"API / Docstrings","title":"UnfoldSim.NoNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.NoNoise","content":" UnfoldSim.NoNoise  —  Type NoNoise <: AbstractNoise Return zeros instead of noise. source"},{"id":301,"pagetitle":"API / Docstrings","title":"UnfoldSim.NoOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.NoOnset","content":" UnfoldSim.NoOnset  —  Type struct NoOnset <: AbstractOnset end In the case that the user directly wants no overlap to be simulated (=> epoched data). source"},{"id":302,"pagetitle":"API / Docstrings","title":"UnfoldSim.PinkNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.PinkNoise","content":" UnfoldSim.PinkNoise  —  Type PinkNoise <: AbstractNoise Generate Pink Noise using the SignalAnalysis.jl implementation. noiselevel  is used to scale the noise source"},{"id":303,"pagetitle":"API / Docstrings","title":"UnfoldSim.RealisticNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.RealisticNoise","content":" UnfoldSim.RealisticNoise  —  Type RealisticNoise <: AbstractNoise Not implemented - planned to use Artifacts.jl to provide real EEG data to add. source"},{"id":304,"pagetitle":"API / Docstrings","title":"UnfoldSim.RedNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.RedNoise","content":" UnfoldSim.RedNoise  —  Type RedNoise <: AbstractNoise Generate Red Noise using the SignalAnalysis.jl implementation. noiselevel  is used to scale the noise source"},{"id":305,"pagetitle":"API / Docstrings","title":"UnfoldSim.RepeatDesign","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.RepeatDesign","content":" UnfoldSim.RepeatDesign  —  Type RepeatDesign{T} <: AbstractDesign Repeat a design DataFrame multiple times to mimick repeatedly recorded trials. designOnce = MultiSubjectDesign(;\n\t\tn_items=2,\n\t\tn_subjects = 2,\n\t\tsubjects_between =Dict(:cond=>[\"levelA\",\"levelB\"]),\n\t\titems_between =Dict(:cond=>[\"levelA\",\"levelB\"]),\n\t\t);\n\ndesign = RepeatDesign(designOnce,4); See also  SingleSubjectDesign ,  MultiSubjectDesign source"},{"id":306,"pagetitle":"API / Docstrings","title":"UnfoldSim.SingleSubjectDesign","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.SingleSubjectDesign","content":" UnfoldSim.SingleSubjectDesign  —  Type SingleSubjectDesign <: AbstractDesign A type for specifying the experimental for a single subject (based on the given conditions). Fields conditions = Dict{Symbol,Vector} of conditions, e.g.  Dict(:A=>[\"a_small\",\"a_big\"],:B=>[\"b_tiny\",\"b_large\"]) event_order_function  = x->x; # can be used to sort, or x->shuffle(MersenneTwister(42),x) - be sure to fix/update the rng accordingly!! Number of trials / rows in  generate_events(design)  depend on the full factorial of your  conditions . To increase the number of repetitions simply use  RepeatDesign(SingleSubjectDesign(...),5) If conditions are omitted (or set to  nothing ), a single trial is simulated with a column  :dummy  and content  :dummy  - this is for convenience. Tip: Check the resulting dataframe using  generate_events(design) Example design = SingleSubjectDesign(;\n    conditions = Dict(\n        :stimulus_type => [\"natural\", \"artificial\"],\n        :contrast_level => range(0, 1, length = 5),\n); See also  MultiSubjectDesign ,  RepeatDesign source"},{"id":307,"pagetitle":"API / Docstrings","title":"UnfoldSim.UniformOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.UniformOnset","content":" UnfoldSim.UniformOnset  —  Type struct UniformOnset <: AbstractOnset Provide a Uniform Distribution of the inter-event-distances.  width   is the width of the uniform distribution (=> the jitter). Since the lower bound is 0,  width  is also the upper bound.  offset  is the minimal distance. The maximal distance is  offset + width . source"},{"id":308,"pagetitle":"API / Docstrings","title":"UnfoldSim.WhiteNoise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.WhiteNoise","content":" UnfoldSim.WhiteNoise  —  Type WhiteNoise <: WhiteNoise\nnoiselevel = 1\nimfilter = 0 Generate White Noise using  randn  - thus Gaussian noise.  noiselevel  is used to scale the noise Using  imfilter  > 0 it is possible to smooth the noise using Image.imfilter. source"},{"id":309,"pagetitle":"API / Docstrings","title":"Base.size","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#Base.size-Tuple{MultiSubjectDesign}","content":" Base.size  —  Method Returns dimension of experiment design source"},{"id":310,"pagetitle":"API / Docstrings","title":"DSP.Windows.hanning","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#DSP.Windows.hanning-Tuple{Any, Any, Any}","content":" DSP.Windows.hanning  —  Method generate a hanning window duration: in s offset: in s, defines hanning peak sfreq: sampling rate in Hz source"},{"id":311,"pagetitle":"API / Docstrings","title":"UnfoldSim.PuRF","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.PuRF-Tuple{}","content":" UnfoldSim.PuRF  —  Method PuRF() Default generator for PuRF Pupil Response Function. source"},{"id":312,"pagetitle":"API / Docstrings","title":"UnfoldSim.add_noise!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.add_noise!-Tuple{Any, AbstractNoise, Any}","content":" UnfoldSim.add_noise!  —  Method add_noise!(rng, noisetype::AbstractNoise, signal) Generate and add noise to a data matrix. Assumes that the signal can be linearized, that is, that the noise is stationary source"},{"id":313,"pagetitle":"API / Docstrings","title":"UnfoldSim.add_responses!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.add_responses!-Tuple{Any, Vector, Vararg{Any, 4}}","content":" UnfoldSim.add_responses!  —  Method add_responses!(signal, responses::Vector, e, s, tvec, erpvec)\nadd_responses!(signal, responses::Matrix, e, s, tvec, erpvec)\nadd_responses!(signal, responses::AbstractArray, e, s, tvec, erpvec) Helper function to add inplace the responses to the signal, but for both 2D (1 channel) and 3D (X channel case). source"},{"id":314,"pagetitle":"API / Docstrings","title":"UnfoldSim.closest_src","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.closest_src-Tuple{AbstractVector{<:AbstractVector}, Any}","content":" UnfoldSim.closest_src  —  Method closest_src(coords_list::AbstractVector{<:AbstractVector}, pos)\nclosest_src(coords::Vector{<:Real}, pos) Takes an array of 'm' target coordinate vector (size 3) (or vector of vectors) and a matrix (n-by-3) of all available positions, and returns an array of size 'm' containing the indices of the respective items in 'pos' that are nearest to each of the target coordinates. source"},{"id":315,"pagetitle":"API / Docstrings","title":"UnfoldSim.closest_src","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.closest_src-Tuple{Hartmut, String}","content":" UnfoldSim.closest_src  —  Method closest_src(head::Hartmut,label::String) Returns src- ix  of the Headmodel  Hartmut  which is closest to the average of the  label . Important We use the average in eucledean space, but the cortex is a curved surface. In most cases they will not overlap. Ideally we would calculate the average on the surface, but this is a bit more complex to do (you'd need to calculate the vertices etc.) hartmut = headmodel()\npos = closest_src(hartmut=>\"Left Middle Temporal Gyrus, posterior division\") source"},{"id":316,"pagetitle":"API / Docstrings","title":"UnfoldSim.convert","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.convert-NTuple{4, Any}","content":" UnfoldSim.convert  —  Method Obsolete - # TODO: Transfer function to Unfold.jl Function to convert output similar to unfold (data, events) source"},{"id":317,"pagetitle":"API / Docstrings","title":"UnfoldSim.create_continuous_signal","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.create_continuous_signal-Tuple{Any, Any, Any}","content":" UnfoldSim.create_continuous_signal  —  Method create_continuous_signal(rng, responses, simulation) Based on the responses and simulation parameters, simulate onset latencies and add together a continuous signal. source"},{"id":318,"pagetitle":"API / Docstrings","title":"UnfoldSim.epoch","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.epoch-Tuple{AbstractVector, Vararg{Any}}","content":" UnfoldSim.epoch  —  Method epoch(data::AbstractVector, args...; kwargs...)\nepoch(\n    data::AbstractArray{T,2},\n    events,\n    τ::Tuple{Number,Number},\n    sfreq;\n    eventtime::Symbol = :latency,\n) where {T<:Union{Missing,Number}} Helper function to epoch data. Adapted from Unfold.jl: https://github.com/unfoldtoolbox/Unfold.jl/blob/b3a21c2bb7e93d2f45ec64b0197f4663a6d7939a/src/utilities.jl#L40 source"},{"id":319,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events-Tuple{MultiSubjectDesign}","content":" UnfoldSim.generate_events  —  Method generate_events(design::MultiSubjectDesign) Generate full factorial Dataframe according to MixedModelsSim.jl 's  simdat_crossed  function. Note: n_items = you can think of it as  trials  or better, as  stimuli . Note: No condition can be named  dv  which is used internally in MixedModelsSim / MixedModels as a dummy left-side Afterwards applies  design.event_order_function `.  Could be used to duplicate trials, sort, subselect etc. Finally it sorts by  :subject julia> d = MultiSubjectDesign(;n subjects = 10,n items=20,both within= Dict(:A=>nlevels(5),:B=>nlevels(2))) julia> generate events(d) source"},{"id":320,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events-Tuple{RepeatDesign}","content":" UnfoldSim.generate_events  —  Method UnfoldSim.generate_events(design::RepeatDesign{T}) In a repeated design, iteratively calls the underlying {T} Design and concatenates. In case of MultiSubjectDesign, sorts by subject. source"},{"id":321,"pagetitle":"API / Docstrings","title":"UnfoldSim.generate_events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.generate_events-Tuple{SingleSubjectDesign}","content":" UnfoldSim.generate_events  —  Method Generates full-factorial DataFrame of design.conditions Afterwards applies design.event order function. If conditions is  nothing , a single trial is simulated with a column  :dummy  and content  :dummy  - this is for convenience. julia> d = SingleSubjectDesign(;conditions= Dict(:A=>nlevels(5),:B=>nlevels(2))) julia> generate_events(d) source"},{"id":322,"pagetitle":"API / Docstrings","title":"UnfoldSim.hartmut_citation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.hartmut_citation-Tuple{}","content":" UnfoldSim.hartmut_citation  —  Method Returns citation-string for HArtMuT source"},{"id":323,"pagetitle":"API / Docstrings","title":"UnfoldSim.headmodel","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.headmodel-Tuple{}","content":" UnfoldSim.headmodel  —  Method Load a headmodel, using Artifacts.jl automatically downloads the required files Currently only  type=\"hartmut\"  is implemented source"},{"id":324,"pagetitle":"API / Docstrings","title":"UnfoldSim.hrf","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.hrf-Tuple{}","content":" UnfoldSim.hrf  —  Method Generate a HRF kernel.  TR = 1/sfreq default parameters taken from SPM Code adapted from Unfold.jl source"},{"id":325,"pagetitle":"API / Docstrings","title":"UnfoldSim.leadfield","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.leadfield-Tuple{Hartmut}","content":" UnfoldSim.leadfield  —  Method Returns the leadfield source"},{"id":326,"pagetitle":"API / Docstrings","title":"UnfoldSim.magnitude","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.magnitude-Tuple{AbstractHeadmodel}","content":" UnfoldSim.magnitude  —  Method Extracts magnitude of the orientation-including leadfield. By default uses the orientation specified in the headmodel Fallback: along the third dimension using  norm  - the maximal projection source"},{"id":327,"pagetitle":"API / Docstrings","title":"UnfoldSim.magnitude","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.magnitude-Tuple{Hartmut}","content":" UnfoldSim.magnitude  —  Method magnitude(headmodel::Hartmut; type = \"perpendicular\") = Extract magnitude of 3-orientation-leadfield,   type  (default: \"perpendicular\") => uses the provided source-point orientations - otherwise falls back to  norm . source"},{"id":328,"pagetitle":"API / Docstrings","title":"UnfoldSim.magnitude","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.magnitude-Union{Tuple{AbstractArray{T, 3}}, Tuple{T}} where T<:Real","content":" UnfoldSim.magnitude  —  Method magnitude(lf::AbstractArray{T,3}) where {T<:Real} If orientation is not specified, returns the maximal magnitude (norm of leadfield). source"},{"id":329,"pagetitle":"API / Docstrings","title":"UnfoldSim.magnitude","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.magnitude-Union{Tuple{T}, Tuple{AbstractArray{T, 3}, AbstractMatrix{T}}} where T<:Real","content":" UnfoldSim.magnitude  —  Method magnitude(lf::AbstractArray{T,3}, orientation::AbstractArray{T,2}) where {T<:Real} Return the magnitude along an orientation of the leadfield. source"},{"id":330,"pagetitle":"API / Docstrings","title":"UnfoldSim.maxlength","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.maxlength-Tuple{Vector{<:AbstractComponent}}","content":" UnfoldSim.maxlength  —  Method maxlength(c::Vector{<:AbstractComponent}) = maximum(length.(c)) maximum of individual component lengths source"},{"id":331,"pagetitle":"API / Docstrings","title":"UnfoldSim.n170","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n170-Tuple{}","content":" UnfoldSim.n170  —  Method n170(;sfreq=100) Generator for Hanning window, negative (!) peak at 170ms, width 150ms, at kwargs  sfreq  (default 100). Returns a vector. source"},{"id":332,"pagetitle":"API / Docstrings","title":"UnfoldSim.n400","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n400-Tuple{}","content":" UnfoldSim.n400  —  Method n400(;sfreq=100) Generator for Hanning window, negative (!) peak at 400ms, width 400ms, at kwargs  sfreq  (default 100). Returns a vector. source"},{"id":333,"pagetitle":"API / Docstrings","title":"UnfoldSim.n_channels","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n_channels-Tuple{AbstractComponent}","content":" UnfoldSim.n_channels  —  Method n_channels(c::AbstractComponent) Return the number of channels. By default = 1. source"},{"id":334,"pagetitle":"API / Docstrings","title":"UnfoldSim.n_channels","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n_channels-Tuple{MultichannelComponent}","content":" UnfoldSim.n_channels  —  Method n_channels(c::MultichannelComponent) For  MultichannelComponent  return the length of the projection vector. source"},{"id":335,"pagetitle":"API / Docstrings","title":"UnfoldSim.n_channels","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.n_channels-Tuple{Vector{<:AbstractComponent}}","content":" UnfoldSim.n_channels  —  Method For a vector of  MultichannelComponent s, return the first but asserts all are of equal length. source"},{"id":336,"pagetitle":"API / Docstrings","title":"UnfoldSim.p100","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.p100-Tuple{}","content":" UnfoldSim.p100  —  Method p100(;sfreq=100) Generator for Hanning window, peak at 100ms, width 100ms, at kwargs  sfreq  (default 100). Returns a vector. source"},{"id":337,"pagetitle":"API / Docstrings","title":"UnfoldSim.p300","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.p300-Tuple{}","content":" UnfoldSim.p300  —  Method p300(;sfreq=100) Generator for Hanning window, peak at 300ms, width 300ms, at kwargs  sfreq  (default 100). Returns a vector. source"},{"id":338,"pagetitle":"API / Docstrings","title":"UnfoldSim.pad_array","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.pad_array-Tuple{Vector, Tuple, Any}","content":" UnfoldSim.pad_array  —  Method Pads array with specified value, length pad_array(arr, len, val) source"},{"id":339,"pagetitle":"API / Docstrings","title":"UnfoldSim.predef_2x2","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.predef_2x2-Tuple{Random.AbstractRNG}","content":" UnfoldSim.predef_2x2  —  Method predef_2x2(rng::AbstractRNG; kwargs...) The most used  kwargs  is:  return_epoched = true  which returns already epoched data. If you want epoched data without overlap, specify  onset = NoOnset()  and  return_epoched = true Design n_items = 100 , n_subjects = 1 , conditions = Dict(:A => [\"a_small\",\"a_big\"], :B => [\"b_tiny\",\"b_large\"]) , event_order_function = x -> shuffle(deepcopy(rng), x) , Component / Signal signalsize = 100 , # Length of simulated hanning window basis = hanning(signalsize) , # The actual \"function\",  signalsize  is only used here β = [1, -0.5, .5, +1] , # The parameters σs = Dict(:subject => [1, 0.5, 0.5, 0.5],:item => [1]) , # Only in n_subjects >= 2 case, specifies the random effects contrasts = Dict(:A => EffectsCoding(), :B => EffectsCoding())  # Effect coding by default formula = n_subjects == 1 ? @formula(0 ~ 1 + A*B) : @formula(dv ~ 1 + A*B + (A*B|subject) + (1|item)) , Onset overlap = (0.5,0.2) , onset = UniformOnset(; offset = signalsize * overlap[1], width = signalsize * overlap[2]) , # Put offset to 1 for no overlap. put width to 0 for no jitter Noise noiselevel = 0.2 , noise = PinkNoise(; noiselevel = noiselevel) , Be careful if you modify n items with n subjects = 1, n_items has to be a multiple of 4 (or your equivalent conditions factorial, e.g. all combinations length) source"},{"id":340,"pagetitle":"API / Docstrings","title":"UnfoldSim.predef_eeg","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.predef_eeg-Tuple{Any}","content":" UnfoldSim.predef_eeg  —  Method predef_eeg(; kwargs...)\npredef_eeg(rng; kwargs...)\npredef_eeg(rng, n_subjects; kwargs...) Generate a P1/N1/P3 complex. In case  n_subjects  is defined -  MixedModelComponents  are generated, else  LinearModelComponents . The most used  kwargs  is:  return_epoched=true  which returns already epoched data. If you want epoched data without overlap, specify  onset = NoOnset()  and  return_epoched = true Default parameters: Design n_repeats = 100 , event_order_function = x -> shuffle(deepcopy(rng), x) , # random trial order conditions = Dict(...) , Component / Signal sfreq = 100 , p1 = (p100(; sfreq = sfreq), @formula(0 ~ 1), [5], Dict()) , # P1 amp 5, no effects n1 = (n170(; sfreq = sfreq), @formula(0 ~ 1 + condition), [5,-3], Dict()) , # N1 amp 5, dummy-coded condition effect (levels \"car\", \"face\") of -3 p3 = (p300(; sfreq = sfreq), @formula(0 ~ 1 + continuous), [5,1], Dict()) , # P3 amp 5, continuous effect range [-5,5] with slope 1 Onset overlap = (0.5,0.2) , # offset + width/length of Uniform noise. put offset to 1 for no overlap. put width to 0 for no jitter onset = UniformOnset(; offset = sfreq * 0.5 * overlap[1], width = sfreq * 0.5 * overlap[2]) ,  Noise noiselevel = 0.2 , noise = PinkNoise(; noiselevel = noiselevel) , source"},{"id":341,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate","content":" UnfoldSim.simulate  —  Function simulate(\n[rng::AbstractRNG,]\ndesign::AbstractDesign,\nsignal,\nonset::AbstractOnset,\nnoise::AbstractNoise = NoNoise();\nreturn_epoched=false,\n) Main simulation function, given  Design , [Array of]  Component ,  Onset  and optional [ Noise ], returns continuous or epoched signal. optional return_epoched  (Bool, default:  false ):  Skip the Onset-calculation and conversion to continuous data and return the epoched data directly (see also remarks below). Return Depending on the design, the components and on  return_epoched , the output can be a 1-D, 2-D, 3-D or 4-D Array. For example, a 4-D Array would have the dimensions  channels x time x trials x subjects Notes Some remarks to how the noise is added: If  return_epoched = true  and  onset =NoOnset()  the noise is added to the epoched data matrix If  onset  is not  NoOnset , a continuous signal is created and the noise is added to this i.e. this means that the noise won't be the same as in the  onset = NoOnset()  case even if  return_epoched = true . The case  return_epoched = false  and  onset = NoOnset()  is not possible and therefore covered by an assert statement source"},{"id":342,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_and_add!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_and_add!-Tuple{AbstractMatrix, Any, Any, Any}","content":" UnfoldSim.simulate_and_add!  —  Method simulate_and_add!(epoch_data::AbstractMatrix, c, simulation, rng)\nsimulate_and_add!(epoch_data::AbstractArray, c, simulation, rng) Helper function to call  simulate_component  and add it to a provided Array. source"},{"id":343,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, AbstractComponent, Simulation}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::AbstractComponent, simulation::Simulation) By default call  simulate_component  with  (::Abstractcomponent,::AbstractDesign)  instead of the whole simulation. This allows users to provide a hook to do something completely different :) source"},{"id":344,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, LinearModelComponent, AbstractDesign}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::AbstractComponent, simulation::Simulation) Generate a linear model design matrix, weight it by c.β and multiply the result with the given basis vector. julia> c = UnfoldSim.LinearModelComponent([0,1,1,0],@formula(0~1+cond),[1,2],Dict()) julia> design = MultiSubjectDesign(;n subjects=2,n items=50,items between=(;:cond=>[\"A\",\"B\"])) julia> simulate component(StableRNG(1),c,design) source"},{"id":345,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, MixedModelComponent, AbstractDesign}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng, c::MixedModelComponent, design::AbstractDesign) Generates a MixedModel and simulates data according to c.β and c.σs. A trick is used to remove the Normal-Noise from the MixedModel which might lead to rare numerical instabilities. Practically, we upscale the σs by factor 10000, and provide a σ=0.0001. Internally this results in a normalization where the response scale is 10000 times larger than the noise. Currently, it is not possible to use a different basis for fixed and random effects, but a code-stub exists (it is slow though). return_parameters  (Bool,false) - can be used to return the per-event parameters used to weight the basis function. Sometimes useful to see what is simulated julia> design = MultiSubjectDesign(;n subjects=2,n items=50,items_between=(;:cond=>[\"A\",\"B\"])) julia> c = UnfoldSim.MixedModelComponent([0.,1,1,0],@formula(0~1+cond+(1|subject)),[1,2],Dict(:subject=>[2],),Dict()) julia> simulate(StableRNG(1),c,design) source"},{"id":346,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_component-Tuple{Any, MultichannelComponent, AbstractDesign}","content":" UnfoldSim.simulate_component  —  Method simulate_component(rng,c::MultichannelComponent,design::AbstractDesign) Return the projection of a component from source to \"sensor\" space. source"},{"id":347,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_noise-Tuple{Any, NoNoise, Int64}","content":" UnfoldSim.simulate_noise  —  Method simulate_noise(rng, t::NoNoise, n::Int) Return zeros instead of noise. source"},{"id":348,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_noise-Tuple{Any, Union{PinkNoise, RedNoise}, Int64}","content":" UnfoldSim.simulate_noise  —  Method simulate_noise(rng, t::Union{PinkNoise,RedNoise}, n::Int) Generate Pink or Red Noise using the  SignalAnalysis.jl  implementation. source"},{"id":349,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_onsets","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_onsets-Tuple{Any, AbstractOnset, Simulation}","content":" UnfoldSim.simulate_onsets  —  Method simulate_onsets(rng, onset::AbstractOnset, simulation::Simulation) Call  simulate_interonset_distances  to generate distances between events and then add them up to generate the actual latencies in samples. main call from  simulation source"},{"id":350,"pagetitle":"API / Docstrings","title":"UnfoldSim.simulate_responses","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.simulate_responses-Tuple{Any, Vector{<:AbstractComponent}, Simulation}","content":" UnfoldSim.simulate_responses  —  Method simulate_responses(\n    rng,\n    components::Vector{<:AbstractComponent},\n    simulation::Simulation) Simulate multiple component responses and accumulates them on a per-event basis. source"},{"id":351,"pagetitle":"API / Docstrings","title":"UnfoldSim.weight_σs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/api/#UnfoldSim.weight_σs-Tuple{Dict, Float64, Float64}","content":" UnfoldSim.weight_σs  —  Method Weights a σs Dict for MixedModels.jl by a Float64 Finally sales it by σ_lmm, as a trick to simulate noise-free LMMs I anticipate a function      function weight_σs(σs::Dict,b_σs::Dict,σ_lmm::Float64)  where each σs entry can be weighted individually source"},{"id":354,"pagetitle":"Generate multi channel data","title":"Generate multi channel data","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Generate-multi-channel-data","content":" Generate multi channel data Here you will learn how to simulate EEG data for multiple channels/electrodes. The idea is to specify a signal on source level and then use a head model or a manual projection matrix to project the source signal to a number of electrodes."},{"id":355,"pagetitle":"Generate multi channel data","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing UnfoldMakie\nusing CairoMakie\nusing DataFrames\nusing Random"},{"id":356,"pagetitle":"Generate multi channel data","title":"Specifying a design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Specifying-a-design","content":" Specifying a design We are using a one-level design for testing here. design = SingleSubjectDesign(conditions = Dict(:condA => [\"levelA\"])) SingleSubjectDesign\n  conditions: Dict{Symbol, Vector}\n  event_order_function: #10 (function of type UnfoldSim.var\"#10#14\")\n Next we generate two simple components at two different times without any formula attached (we have a single condition anyway) c = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1), β = [1]);\nc2 = LinearModelComponent(; basis = p300(), formula = @formula(0 ~ 1), β = [1]);"},{"id":357,"pagetitle":"Generate multi channel data","title":"The multichannel component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#The-multichannel-component","content":" The multichannel component Next, similar to the nested design above, we can nest the component in a  MultichannelComponent . We could either provide the projection matrix manually, e.g.: mc = UnfoldSim.MultichannelComponent(c, [1, 2, -1, 3, 5, 2.3, 1]) MultichannelComponent\n  component: LinearModelComponent\n  projection: Array{Float64}((7,)) [1.0, 2.0, -1.0, 3.0, 5.0, 2.3, 1.0]\n  noise: NoNoise NoNoise()\n or maybe more convenient: use the pair-syntax: Headmodel=>Label which makes use of a headmodel (HaRTmuT is currently easily available in UnfoldSim) hart = headmodel(type = \"hartmut\")\nmc = UnfoldSim.MultichannelComponent(c, hart => \"Left Postcentral Gyrus\")\nmc2 = UnfoldSim.MultichannelComponent(c2, hart => \"Right Occipital Pole\") MultichannelComponent\n  component: LinearModelComponent\n  projection: Array{Float64}((227,)) [-0.03461859471337842, -0.04321094803502425, 0.0037088347968313525, -0.014722528968861278, -0.0234889834534478, 0.02731807504242923, 0.038863688452528036, 0.1190531258070562, -0.09956890221613562, -0.0867729334438599  …  0.37435404409695094, -0.020863789022627935, 0.25627478723535513, -0.05777985212119245, 0.37104376432271147, -0.19446620423767172, 0.2590764703721097, -0.12923837607416555, 0.1732886690359311, 0.4703016561960567]\n  noise: NoNoise NoNoise()\n Hint You could also specify a noise-specific component which is applied prior to projection & summing with other components. finally we need to define the onsets of the signal onset = UniformOnset(; width = 20, offset = 4);"},{"id":358,"pagetitle":"Generate multi channel data","title":"Simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Simulation","content":" Simulation Now as usual we simulate data. Inspecting data shows our result is now indeed ~230 Electrodes large! Nice! data, events =\n    simulate(MersenneTwister(1), design, [mc, mc2], onset, PinkNoise(noiselevel = 0.05))\nsize(data) (227, 61) Hint The noise declared in the  simulate  function is added after mixing to channels, each channel receives independent noise. It is also possible to add noise to each individual component+source prior to projection. This would introduce correlated noise."},{"id":359,"pagetitle":"Generate multi channel data","title":"Plotting","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/multichannel/#Plotting","content":" Plotting Let's plot using Butterfly & Topoplot first we convert the electrodes to positions usable in TopoPlots.jl pos3d = hart.electrodes[\"pos\"];\npos2d = to_positions(pos3d')\npos2d = [Point2f(p[1] + 0.5, p[2] + 0.5) for p in pos2d]; now plot! f = Figure()\ndf = DataFrame(\n    :estimate => data[:],\n    :channel => repeat(1:size(data, 1), outer = size(data, 2)),\n    :time => repeat(1:size(data, 2), inner = size(data, 1)),\n)\nplot_butterfly!(f[1, 1:2], df; positions = pos2d)\nplot_topoplot!(\n    f[2, 1],\n    df[df.time.==28, :];\n    positions = pos2d,\n    visual = (; enlarge = 0.5, label_scatter = false),\n    axis = (; limits = ((0, 1), (0, 0.9))),\n)\nplot_topoplot!(\n    f[2, 2],\n    df[df.time.==48, :];\n    positions = pos2d,\n    visual = (; enlarge = 0.5, label_scatter = false),\n    axis = (; limits = ((0, 1), (0, 0.9))),\n)\nf This page was generated using  Literate.jl ."},{"id":362,"pagetitle":"Define a new component (with variable duration and shift)","title":"Define a new component (with variable duration and shift)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Define-a-new-component-(with-variable-duration-and-shift)","content":" Define a new component (with variable duration and shift) We want a new component that changes its duration and shift depending on a column in the event design. This is somewhat already implemented in the HRF + Pupil bases."},{"id":363,"pagetitle":"Define a new component (with variable duration and shift)","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Setup","content":" Setup Click to expand using UnfoldSim\nusing Unfold\nusing Random\nusing DSP\nusing CairoMakie, UnfoldMakie\n\nsfreq = 100;"},{"id":364,"pagetitle":"Define a new component (with variable duration and shift)","title":"Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Design","content":" Design Let's generate a design with two columns, shift + duration design = UnfoldSim.SingleSubjectDesign(;\n    conditions = Dict(\n        :shift => rand(100) .* sfreq / 5,\n        :duration => 20 .+ rand(100) .* sfreq / 5,\n    ),\n) SingleSubjectDesign\n  conditions: Dict{Symbol, Vector}\n  event_order_function: #10 (function of type UnfoldSim.var\"#10#14\")\n"},{"id":365,"pagetitle":"Define a new component (with variable duration and shift)","title":"Implement a new AbstractComponent","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Implement-a-new-AbstractComponent","content":" Implement a new AbstractComponent We also need a new  AbstractComponent struct TimeVaryingComponent <: AbstractComponent\n    basisfunction::Any\n    maxlength::Any\nend We have to define the length of a component Base.length(c::TimeVaryingComponent) = length(c.maxlength) While we could have put the TimeVaryingComponent.basisfunction directly into the simulate function, I thought this is a bit more modular function UnfoldSim.simulate(rng, c::TimeVaryingComponent, design::AbstractDesign)\n    evts = generate_events(design)\n    return c.basisfunction(evts, c.maxlength)\nend finally, the actual function that does the shifting + duration function basis_shiftduration(evts, maxlength)\n    basis = hanning.(Int.(round.(evts.duration))) ## hanning as long as duration\n    if \"shift\" ∈ names(evts)\n        basis = pad_array.(basis, Int.(round.(.-evts.shift)), 0) ## shift by adding 0 in front\n    end\n    # we should make sure that all bases have maxlength by appending / truncating\n    difftomax = maxlength .- length.(basis)\n    if any(difftomax .< 0)\n        @warn \"basis longer than max length in at least one case. either increase maxlength or redefine function. Trying to truncate the basis\"\n        basis[difftomax.>0] = pad_array.(basis[difftomax.>0], difftomax[difftomax.>0], 0)\n        return [b[1:maxlength] for b in basis]\n    else\n        return pad_array.(basis, difftomax, 0)\n    end\nend basis_shiftduration (generic function with 1 method)"},{"id":366,"pagetitle":"Define a new component (with variable duration and shift)","title":"Simulate data with the new component type","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newComponent/#Simulate-data-with-the-new-component-type","content":" Simulate data with the new component type erp = UnfoldSim.simulate(\n    MersenneTwister(1),\n    TimeVaryingComponent(basis_shiftduration, 50),\n    design,\n)\nplot_erpimage(hcat(erp...), sortvalues = generate_events(design).shift) This page was generated using  Literate.jl ."},{"id":369,"pagetitle":"Define a new (imbalanced) design","title":"Define a new (imbalanced) design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#Define-a-new-(imbalanced)-design","content":" Define a new (imbalanced) design A design specifies how much data is generated, and how the event-table(s) should be generated. Already implemented examples are  MultiSubjectDesign  and  SingleSubjectDesign . We need 3 things for a new design: a  struct<:AbstractDesign , a  size  and a  generate  function."},{"id":370,"pagetitle":"Define a new (imbalanced) design","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#Setup","content":" Setup Click to expand using UnfoldSim\nusing StableRNGs\nusing DataFrames\nusing Parameters"},{"id":371,"pagetitle":"Define a new (imbalanced) design","title":"1) type","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#1)-type","content":" 1)  type We need a  ImbalanceSubjectDesign  struct. You are free to implement it as you wish, as long as the other two functions are implemented @with_kw struct ImbalanceSubjectDesign <: UnfoldSim.AbstractDesign\n    nTrials::Int\n    balance::Float64 = 0.5 # default balanced\nend;"},{"id":372,"pagetitle":"Define a new (imbalanced) design","title":"2) size","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#2)-size","content":" 2)  size we need a  size(design::ImbalanceSubjectDesign)  function to tell how many events we will have. This is used at different places, e.g. in the Default onset implementation # note the trailing , to make it a Tuple\nsize(design::ImbalanceSubjectDesign) = (design.nTrials,);"},{"id":373,"pagetitle":"Define a new (imbalanced) design","title":"3) generate","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/newDesign/#3)-generate","content":" 3)  generate We need a type  generate_events(design::ImbalanceSubjectDesign)  function. This function should return the actual table as a  DataFrame function generate_events(design::ImbalanceSubjectDesign)\n    nA = Int(round.(design.nTrials .* design.balance))\n    nB = Int(round.(design.nTrials .* (1 - design.balance)))\n    @assert nA + nB ≈ design.nTrials\n    levels = vcat(repeat([\"levelA\"], nA), repeat([\"levelB\"], nB))\n    return DataFrame(Dict(:condition => levels))\nend; Finally, we can test the function and see whether it returns a Design-DataFrame as we requested design = ImbalanceSubjectDesign(; nTrials = 6, balance = 0.2)\ngenerate_events(design) 6×1 DataFrame Row condition String 1 levelA 2 levelB 3 levelB 4 levelB 5 levelB 6 levelB Important It is the users task to ensure that each run is reproducible. So if you have a random process (e.g. shuffling), be sure to   safe a RNG object in your struct and use it in your generate function. This page was generated using  Literate.jl ."},{"id":376,"pagetitle":"Use existing experimental designs & onsets in the simulation","title":"Use existing experimental designs & onsets in the simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/predefinedData/#Use-existing-experimental-designs-and-onsets-in-the-simulation","content":" Use existing experimental designs & onsets in the simulation Let's say you want to use the events data frame (containing the levels of the experimental variables and the event onsets (latencies)) from a previous study in your simulation."},{"id":377,"pagetitle":"Use existing experimental designs & onsets in the simulation","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/predefinedData/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing DataFrames\nusing Random\nusing CairoMakie # for plotting From a previous study, we (somehow, e.g. by using  pyMNE.jl ) imported an event data frame like this: my_events = DataFrame(:condition => [:A, :B, :B, :A, :A], :latency => [7, 13, 22, 35, 41]) 5×2 DataFrame Row condition latency Symbol Int64 1 A 7 2 B 13 3 B 22 4 A 35 5 A 41 To use exactly these values, we can generate a new  AbstractDesign , which will always return this event dataframe struct MyManualDesign <: AbstractDesign\n    my_events::Any\nend\nUnfoldSim.generate_events(d::MyManualDesign) = deepcopy(d.my_events) ## generate function which is called internally in UnfoldSim\nUnfoldSim.size(d::MyManualDesign) = size(d.my_events, 1); ## necessary function to tell what the dimensionality of the experimental design is Note Note the  UnfoldSim.generate_events  which tells Julia to \"overload\" the  generate_events  function as defined in UnfoldSim. Next we generate a  MyManualDesign mydesign = MyManualDesign(my_events); We could already use this \"solo\" and simulate some data, for example: signal = LinearModelComponent(;\n    basis = [1, 1, 0.5, 0, 0],\n    formula = @formula(0 ~ 1 + condition),\n    β = [1, 0.5],\n);\n\ndata, events =\n    simulate(MersenneTwister(1), mydesign, signal, UniformOnset(; width = 10, offset = 5))\nlines(data) # plotting\nvlines!(my_events.latency; linestyle = :dash)\ncurrent_figure() Looks good, but the events don't match our custom onsets yet."},{"id":378,"pagetitle":"Use existing experimental designs & onsets in the simulation","title":"Custom Timings","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/predefinedData/#Custom-Timings","content":" Custom Timings Finally, we want to use our custom timings as well. For this we define a new  AbstractOnset . Again, it simply returns our manually provided latencies struct MyManualOnset <: AbstractOnset end\nUnfoldSim.simulate_onsets(rng, onset::MyManualOnset, simulation::Simulation) =\n    generate_events(simulation.design).latency Hint This is a bit of a trick, it relies that  MyManualOnset  is always used in combination with  MyManualDesign . You could of course repeat the structure from  MyManualDesign  also for  MyManualOnset  and have an explicit field in the structure containing the onsets. And that's it data, events = simulate(MersenneTwister(1), mydesign, signal, MyManualOnset())\nlines(data) # plotting\nvlines!(my_events.latency, linestyle = :dash)\ncurrent_figure() now everything matches, lovely! This page was generated using  Literate.jl ."},{"id":381,"pagetitle":"Get multiple trials with identical subject/item combinations","title":"Get multiple trials with identical subject/item combinations","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/HowTo/repeatTrials/#howto_repeat_design","content":" Get multiple trials with identical subject/item combinations Sometimes we want to repeat a design, that is, have multiple trials with identical values, but it is not always straight forward to implement. For instance, there is no way to easily modify  MultiSubjectDesign  to have multiple identical subject/item combinations, without doing awkward repetitions of condition-levels or something. If you struggle with this problem  RepeatDesign  is an easy tool for you: using UnfoldSim\n\ndesignOnce = MultiSubjectDesign(;\n    n_items = 2,\n    n_subjects = 2,\n    subjects_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n    items_between = Dict(:cond => [\"levelA\", \"levelB\"]),\n);\n\ndesign = RepeatDesign(designOnce, 4);\ngenerate_events(design) 8×3 DataFrame Row subject cond item String String String 1 S1 levelA I1 2 S1 levelA I1 3 S1 levelA I1 4 S1 levelA I1 5 S2 levelB I2 6 S2 levelB I2 7 S2 levelB I2 8 S2 levelB I2 As you can see, the design was simply repeated. Note If you implemented your own  AbstractDesign , you need to define the size function accordingly. E.g.:    Base.size(design::RepeatDesign{SingleSubjectDesign}) = size(design.design).*design.repeat This page was generated using  Literate.jl ."},{"id":384,"pagetitle":"Overview: Basis function (component) types","title":"Overview: Basis function (component) types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#Overview:-Basis-function-(component)-types","content":" Overview: Basis function (component) types There are several basis types directly implemented. They can be easily used for the  components . Note You can use any arbitrary shape defined by yourself! We often make use of  hanning(50)  from the DSP.jl package."},{"id":385,"pagetitle":"Overview: Basis function (component) types","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing CairoMakie\nusing DSP\nusing StableRNGs"},{"id":386,"pagetitle":"Overview: Basis function (component) types","title":"EEG","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#EEG","content":" EEG By default, the EEG bases assume a sampling rate of 100, which can easily be changed by e.g. p100(; sfreq=300) f = Figure()\nax = f[1, 1] = Axis(f)\nfor b in [p100, n170, p300, n400]\n    lines!(ax, b(), label = string(b))\n    scatter!(ax, b(), label = string(b))\nend\naxislegend(ax, merge = true)\nf"},{"id":387,"pagetitle":"Overview: Basis function (component) types","title":"fMRI","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#fMRI","content":" fMRI default hrf TR is 1. Get to know all your favourite shapes! ##--\nf = Figure()\nplotConfig = (\n    :peak => 1:3:10,\n    :post_undershoot => 10:5:30,\n    :amplitude => 2:5,\n    :shift => 0:3:10,\n    :peak_width => 0.1:0.5:1.5,\n    :post_undershoot_width => 0.1:0.5:1.5,\n)\n\nfor (ix, pl) in enumerate(plotConfig)\n    col = (ix - 1) % 3 + 1\n    row = Int(ceil(ix / 3))\n\n    ax = f[row, col] = Axis(f)\n    cfg = collect(pl)\n    for k in cfg[2]\n        lines!(ax, UnfoldSim.hrf(; TR = 0.1, (cfg[1] => k,)...), label = string(k))\n    end\n\n    axislegend(string(cfg[1]); merge = true)\nend\nf"},{"id":388,"pagetitle":"Overview: Basis function (component) types","title":"Pupil","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/basistypes/#Pupil","content":" Pupil We use the simplified PuRF from Hoeks & Levelt, 1993. Note that https://www.science.org/doi/10.1126/sciadv.abi9979 show some evidence in their supplementary material, that the convolution model is not fully applicable. f = Figure()\nplotConfig = (:n => 5:3:15, :tmax => 0.5:0.2:1.1)\n\nfor (ix, pl) in enumerate(plotConfig)\n    ax = f[1, ix] = Axis(f)\n    cfg = collect(pl)\n    for k in cfg[2]\n        lines!(ax, UnfoldSim.PuRF(; (cfg[1] => k,)...), label = string(k))\n    end\n\n    axislegend(string(cfg[1]); merge = true)\nend\nf This page was generated using  Literate.jl ."},{"id":391,"pagetitle":"Overview: Experimental design types","title":"Overview: Experimental design types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Overview:-Experimental-design-types","content":" Overview: Experimental design types The experimental design specifies the experimental conditions and other variables that are supposed to have an influence on the simulated data. Currently, there are three types of designs implemented:  SingleSubjectDesign ,  MultiSubjectDesign  and  RepeatDesign ."},{"id":392,"pagetitle":"Overview: Experimental design types","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Random"},{"id":393,"pagetitle":"Overview: Experimental design types","title":"Single-subject designs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Single-subject-designs","content":" Single-subject designs As the name suggests, the  SingleSubjectDesign  type can be used to specify the experimental design for a single subject. Using the  conditions  arguments, the user can specify all relevant conditions or predictors and their levels or value range. The current implementation assumes a full factorial design (also called fully crossed design) in which each level of a factor occurs with each level of the other factors. Moreover, in the current implementation, there is exactly one instance of each of these factor combinations. Example: design_single = SingleSubjectDesign(;\n    conditions = Dict(\n        :stimulus_type => [\"natural\", \"artificial\"],\n        :contrast_level => range(0, 1, length = 3),\n    ),\n); In order to inspect the design, we can use the  generate_events  function to create an event table based on the design we specified. generate_events(design_single) 6×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 natural 2 0.5 natural 3 1.0 natural 4 0.0 artificial 5 0.5 artificial 6 1.0 artificial To change the order of the trials e.g. to sort or shuffle them, one can use the  event_order_function  argument. Example: Randomize the order of trials design_single_shuffled = SingleSubjectDesign(;\n    conditions = Dict(\n        :stimulus_type => [\"natural\", \"artificial\"],\n        :contrast_level => range(0, 1, length = 3),\n    ),\n    event_order_function = x -> shuffle(MersenneTwister(42), x),\n); Click to expand event table  generate_events(design_single_shuffled) 6×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 artificial 2 1.0 natural 3 0.0 natural 4 0.5 natural 5 0.5 artificial 6 1.0 artificial"},{"id":394,"pagetitle":"Overview: Experimental design types","title":"Multi-subject designs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Multi-subject-designs","content":" Multi-subject designs The  MultiSubjectDesign  type can be used to simulate data for an experiment with multiple subjects. Internally, it uses the  MixedModelsSim.jl package . One needs to specify the number of subjects  n_subjects  and the number of items  n_items  i.e. stimuli. In addition, one needs to decide for every experimental factor whether it should be between- or within-subject (and item). Note For factors that are not listed in  items_between  it is assumed that they vary within-item (accordingly for  subjects_between ). design_multi = MultiSubjectDesign(\n    n_subjects = 6,\n    n_items = 4,\n    items_between = Dict(:colour => [\"red\", \"blue\"]),\n    subjects_between = Dict(:age_group => [\"young\", \"old\"]),\n    both_within = Dict(:luminance => range(0, 1, length = 3)),\n); Click to expand event table  generate_events(design_multi) 72×5 DataFrame Row subject age_group item colour luminance String String String String Float64 1 S1 young I1 red 0.0 2 S1 young I2 blue 0.0 3 S1 young I3 red 0.0 4 S1 young I4 blue 0.0 5 S1 young I1 red 0.5 6 S1 young I2 blue 0.5 7 S1 young I3 red 0.5 8 S1 young I4 blue 0.5 9 S1 young I1 red 1.0 10 S1 young I2 blue 1.0 11 S1 young I3 red 1.0 12 S1 young I4 blue 1.0 13 S2 old I1 red 0.0 14 S2 old I2 blue 0.0 15 S2 old I3 red 0.0 16 S2 old I4 blue 0.0 17 S2 old I1 red 0.5 18 S2 old I2 blue 0.5 19 S2 old I3 red 0.5 20 S2 old I4 blue 0.5 21 S2 old I1 red 1.0 22 S2 old I2 blue 1.0 23 S2 old I3 red 1.0 24 S2 old I4 blue 1.0 25 S3 young I1 red 0.0 26 S3 young I2 blue 0.0 27 S3 young I3 red 0.0 28 S3 young I4 blue 0.0 29 S3 young I1 red 0.5 30 S3 young I2 blue 0.5 31 S3 young I3 red 0.5 32 S3 young I4 blue 0.5 33 S3 young I1 red 1.0 34 S3 young I2 blue 1.0 35 S3 young I3 red 1.0 36 S3 young I4 blue 1.0 37 S4 old I1 red 0.0 38 S4 old I2 blue 0.0 39 S4 old I3 red 0.0 40 S4 old I4 blue 0.0 41 S4 old I1 red 0.5 42 S4 old I2 blue 0.5 43 S4 old I3 red 0.5 44 S4 old I4 blue 0.5 45 S4 old I1 red 1.0 46 S4 old I2 blue 1.0 47 S4 old I3 red 1.0 48 S4 old I4 blue 1.0 49 S5 young I1 red 0.0 50 S5 young I2 blue 0.0 51 S5 young I3 red 0.0 52 S5 young I4 blue 0.0 53 S5 young I1 red 0.5 54 S5 young I2 blue 0.5 55 S5 young I3 red 0.5 56 S5 young I4 blue 0.5 57 S5 young I1 red 1.0 58 S5 young I2 blue 1.0 59 S5 young I3 red 1.0 60 S5 young I4 blue 1.0 61 S6 old I1 red 0.0 62 S6 old I2 blue 0.0 63 S6 old I3 red 0.0 64 S6 old I4 blue 0.0 65 S6 old I1 red 0.5 66 S6 old I2 blue 0.5 67 S6 old I3 red 0.5 68 S6 old I4 blue 0.5 69 S6 old I1 red 1.0 70 S6 old I2 blue 1.0 71 S6 old I3 red 1.0 72 S6 old I4 blue 1.0 As with the  SingleSubjectDesign  one can use the  event_order_function  argument to determine the order of events/trials. Important The number of subjects/items has to be a divisor of the number of factor level combinations, i.e. it is assumed that the design is balanced which means that there is an equal number of observations for all possible factor level combinations."},{"id":395,"pagetitle":"Overview: Experimental design types","title":"Repeat designs","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/designtypes/#Repeat-designs","content":" Repeat designs The  RepeatDesign  type is a functionality to encapsulate single- or multi-subject designs. It allows to repeat a generated event table multiple times. In other words, the  RepeatDesign  type allows to have multiple instances of the same item/subject/factor level combination. Example: Assume, we have the following single-subject design from above: Click to expand event table  generate_events(design_single) 6×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 natural 2 0.5 natural 3 1.0 natural 4 0.0 artificial 5 0.5 artificial 6 1.0 artificial But instead of having only one instance of the factor combinations e.g.  stimulus_type :  natural  and  contrast_level :  0 , we will repeat the design three times such that there are three occurrences of each combination. design_repeated = RepeatDesign(design_single, 3);\ngenerate_events(design_repeated) 18×2 DataFrame Row contrast_level stimulus_type Float64 String 1 0.0 natural 2 0.5 natural 3 1.0 natural 4 0.0 artificial 5 0.5 artificial 6 1.0 artificial 7 0.0 natural 8 0.5 natural 9 1.0 natural 10 0.0 artificial 11 0.5 artificial 12 1.0 artificial 13 0.0 natural 14 0.5 natural 15 1.0 natural 16 0.0 artificial 17 0.5 artificial 18 1.0 artificial Here  one can find another example of how to repeat design entries for multi-subject designs. This page was generated using  Literate.jl ."},{"id":398,"pagetitle":"Overview: Noise types","title":"Overview: Noise types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/noisetypes/#Overview:-Noise-types","content":" Overview: Noise types There are different types of noise signals which differ in their power spectra. If you are not familiar with different types/colors of noise yet, have a look at the colors of noise Wikipedia page . There are several noise types directly implemented in UnfoldSim.jl. Here is a comparison: using UnfoldSim\nusing CairoMakie\nusing DSP\nusing StableRNGs\nimport StatsBase.autocor\n\nf = Figure()\nax_sig =\n    f[1, 1:3] =\n        Axis(f; title = \"1.000 samples of noise\", xlabel = \"Time\", ylabel = \"Amplitude\")\nax_spec =\n    f[2, 1:2] = Axis(\n        f;\n        title = \"Welch Periodogram\",\n        xlabel = \"Normalized frequency\",\n        ylabel = \"log(Power)\",\n    )\nax_auto =\n    f[2, 3:4] = Axis(\n        f;\n        title = \"Autocorrelogram (every 10th lag)\",\n        xlabel = \"Lag\",\n        ylabel = \"Autocorrelation\",\n    )\nfor n in [PinkNoise RedNoise WhiteNoise NoNoise ExponentialNoise]\n\n    # generate\n    noisevec = simulate_noise(StableRNG(1), n(), 10000)\n\n    # plot 1000 samples\n    lines!(ax_sig, noisevec[1:1000]; label = string(n))\n\n    # calc spectrum\n    perio = welch_pgram(noisevec)\n\n    # plot spectrum\n    lines!(ax_spec, freq(perio), log10.(power(perio)))\n\n    lags = 0:10:500\n    autocor_vec = autocor(noisevec, lags)\n    lines!(ax_auto, lags, autocor_vec)\n\nend\nf[1, 4] = Legend(f, ax_sig, \"Noise type\", tellheight = true)\nf Hint We recommed for smaller signals the  ExponentialNoise , maybe with a removed DC offset or a HighPass filter. For long signals, this Noise requires lots of memory though. maybe Pinknoise is a better choice then. This page was generated using  Literate.jl ."},{"id":401,"pagetitle":"Overview: Onset types","title":"Overview: Onset types","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#Overview:-Onset-types","content":" Overview: Onset types The onset types determine the distances between event onsets in the continuous EEG signal. The distances are sampled from a certain probability distribution. Currently, there are two types of onset distributions implemented:  UniformOnset  and  LogNormalOnset ."},{"id":402,"pagetitle":"Overview: Onset types","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing CairoMakie\nusing Random\n\n# Define a simple design and repeat it 10000.\n# This will result in 20000 events i.e. event onsets.\ndesign =\n    SingleSubjectDesign(conditions = Dict(:cond => [\"A\", \"B\"])) |>\n    x -> RepeatDesign(x, 10000);"},{"id":403,"pagetitle":"Overview: Onset types","title":"UniformOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#UniformOnset","content":" UniformOnset The  UniformOnset  is based on a uniform distribution and has two parameters:  width  and  offset . Example: onset_uniform = UniformOnset(; width = 50, offset = 0); The  width  parameter defines the upper bound of the interval of the uniform distribution (its lower bound is 0) i.e. all values between 0 and  width  are equally probable. The  offset  parameter determines the minimal distance between two events and its value is added to the value sampled from the uniform distribution i.e. it shifts the distribution. Its default value is  0 , i.e. no offset. In the figure below, it is illustrated how the onset distribution changes when changing one of its parameters. Click to show the code for the figure above let\n    f = Figure()\n\n    # Define parameter combinations\n    parameters = [(((50, 0), (80, 0)), \"width\"), (((50, 0), (50, 20)), \"offset\")]\n\n    axes_list = Array{Any}(undef, length(parameters))\n\n    # Create a subplot for each parameter i.e. one for width and one for offset\n    for (index, (combinations, label)) in enumerate(parameters)\n        ax = Axis(f[index, 1], title = \"Parameter: $label\")\n        axes_list[index] = ax\n\n        # Go through all parameter combinations and plot a histogram of the sampled onsets\n        for (width, offset) in combinations\n            onsets = UnfoldSim.simulate_interonset_distances(\n                MersenneTwister(42),\n                UniformOnset(; width = width, offset = offset),\n                design,\n            )\n\n            hist!(ax, onsets, bins = range(0, 100, step = 1), label = \"($width, $offset)\")\n\n            if label == \"offset\" && offset != 0\n                vlines!(offset, color = \"black\")\n            end\n        end\n        hideydecorations!(ax)\n        hidespines!(ax, :t, :r)\n        axislegend(\n            ax,\n            framevisible = false,\n            labelsize = 12,\n            markersize = 5,\n            patchsize = (10, 10),\n        )\n    end\n    axes_list[end].xlabel = \"Time between events [samples]\"\n    linkyaxes!(axes_list...)\nend"},{"id":404,"pagetitle":"Overview: Onset types","title":"LogNormalOnset","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#LogNormalOnset","content":" LogNormalOnset The  LogNormalOnset  is based on a log-normal distribution and has four parameters:  μ ,  σ ,  offset  and  truncate_upper . Example: onset_lognormal = LogNormalOnset(; μ = 3, σ = 0.25, offset = 0, truncate_upper = nothing); The parameters  μ  and  σ  are the location and scale parameter of the log-normal distribution. However, they are not identical to its mean and standard deviation. If a variable  $X$  is log-normally distributed then  $Y = ln(X)$  is normally distributed with mean  μ  and standard deviation  σ [1] . The  offset  parameter determines the minimal distance between two events and its value is added to the value sampled from the log-normal distribution i.e. it shifts the distribution. Its default value is  0 , i.e. no offset. The  truncate_upper  parameter allows to truncate the distribution at a certain sample value. Its default value is  nothing , i.e. no truncation. In the figure below, it is illustrated how the onset distribution changes when changing one of its parameters. Click to show the code for the figure above let\n    f = Figure(size = (600, 800))\n\n    # Define parameter combinations\n    parameters = [\n        (((3, 0.25, 0, nothing), (2.5, 0.25, 0, nothing)), \"μ\"),\n        (((3, 0.25, 0, nothing), (3, 0.35, 0, nothing)), \"σ\"),\n        (((3, 0.25, 0, nothing), (3, 0.25, 30, nothing)), \"offset\"),\n        (((3, 0.25, 0, nothing), (3, 0.25, 0, 25)), \"truncate_upper\"),\n    ]\n\n    axes_list = Array{Any}(undef, length(parameters))\n\n    # Create a subplot for each parameter i.e. one for μ, one for σ etc\n    for (index, (combinations, label)) in enumerate(parameters)\n        ax = Axis(f[index, 1], title = \"Parameter: $label\")\n        axes_list[index] = ax\n\n        # Go through all parameter combinations and plot a histogram of the sampled onsets\n        for (μ, σ, offset, truncate_upper) in combinations\n            onsets = UnfoldSim.simulate_interonset_distances(\n                MersenneTwister(42),\n                LogNormalOnset(;\n                    μ = μ,\n                    σ = σ,\n                    offset = offset,\n                    truncate_upper = truncate_upper,\n                ),\n                design,\n            )\n\n            hist!(\n                ax,\n                onsets,\n                bins = range(0, 100, step = 1),\n                label = \"($μ,$σ,$offset,$truncate_upper)\",\n            )\n\n            if label == \"offset\" && offset !== 0\n                vlines!(offset, color = \"black\")\n            elseif label == \"truncate_upper\" && truncate_upper !== nothing\n                vlines!(truncate_upper, color = \"black\")\n            end\n        end\n        hideydecorations!(ax)\n        hidespines!(ax, :t, :r)\n        axislegend(\n            ax,\n            framevisible = false,\n            labelsize = 12,\n            markersize = 5,\n            patchsize = (10, 10),\n        )\n    end\n    axes_list[end].xlabel = \"Time between events [samples]\"\n    linkyaxes!(axes_list...)\nend"},{"id":405,"pagetitle":"Overview: Onset types","title":"Overlap of subsequent events","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/onsettypes/#Overlap-of-subsequent-events","content":" Overlap of subsequent events Note The overlap of subsequent events can be indirectly controlled by setting the  offset  parameter relative to the length of the component basis.   Assuming that  signal  is a component e.g.  LinearModelComponent , if  offset  >  length(signal.basis)  -> no overlap if  offset  <  length(signal.basis)  -> there might be overlap, depending on the other parameters of the onset distribution This page was generated using  Literate.jl . 1 Wikipedia contributors. (2023, December 5). Log-normal distribution. In Wikipedia, The Free Encyclopedia. Retrieved 12:27, December 7, 2023, from https://en.wikipedia.org/w/index.php?title=Log-normal_distribution&oldid=1188400077#"},{"id":408,"pagetitle":"Overview of functionality","title":"Overview of functionality","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Overview-of-functionality","content":" Overview of functionality A UnfoldSim simulation has four ingredients: Design, Component, Onset and Noise. Here we provide a short overview of the implemented types."},{"id":409,"pagetitle":"Overview of functionality","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing InteractiveUtils"},{"id":410,"pagetitle":"Overview of functionality","title":"Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Design","content":" Design Designs define the experimental design. They can be nested, e.g.  RepeatDesign(SingleSubjectDesign,10)  would repeat the generated design-dataframe 10x. subtypes(AbstractDesign) 3-element Vector{Any}:\n MultiSubjectDesign\n RepeatDesign\n SingleSubjectDesign"},{"id":411,"pagetitle":"Overview of functionality","title":"Component","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Component","content":" Component Components define a signal. Some components can be nested, e.g.  LinearModelComponent|>MultichannelComponent , see the multi-channel tutorial for more information. subtypes(AbstractComponent) 3-element Vector{Any}:\n LinearModelComponent\n MixedModelComponent\n MultichannelComponent"},{"id":412,"pagetitle":"Overview of functionality","title":"Onsets","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Onsets","content":" Onsets Onsets define the distance between events in the continuous signal. subtypes(AbstractOnset) 3-element Vector{Any}:\n LogNormalOnset\n NoOnset\n UniformOnset"},{"id":413,"pagetitle":"Overview of functionality","title":"Noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/reference/overview/#Noise","content":" Noise Choose the noise you need! subtypes(AbstractNoise) 7-element Vector{Any}:\n ExponentialNoise\n NoNoise\n PinkNoise\n RedNoise\n UnfoldSim.AutoRegressiveNoise\n UnfoldSim.RealisticNoise\n WhiteNoise This page was generated using  Literate.jl ."},{"id":416,"pagetitle":"Multi-subject simulation","title":"Multi-subject simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Multi-subject-simulation","content":" Multi-subject simulation In this tutorial, you will learn how to simulate data for multiple subjects. In particular, you will learn how to specify fixed and random effects and what their influence on the simulated data looks like."},{"id":417,"pagetitle":"Multi-subject simulation","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Unfold\nusing CairoMakie\nusing UnfoldMakie\nusing DataFrames Similar to the single subject case, multi-subject simulation depends on: Design  (typically a  MultiSubjectDesign ) Components  (typically a  MixedModelComponent ) Onset  (any) Noise  (any)"},{"id":418,"pagetitle":"Multi-subject simulation","title":"Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Design","content":" Design Our first design should be 20 subjects, with 4 items each. Any individual image is shown only either as large or small, thus we choose  items_between . design = MultiSubjectDesign(\n    n_subjects = 20,\n    n_items = 4,\n    items_between = Dict(:condition => [\"large\", \"small\"]),\n) MultiSubjectDesign\n  n_subjects: Int64 20\n  n_items: Int64 4\n  subjects_between: Dict{Symbol, Vector}\n  items_between: Dict{Symbol, Vector}\n  both_within: Dict{Symbol, Vector}\n  event_order_function: #3 (function of type UnfoldSim.var\"#3#7\")\n"},{"id":419,"pagetitle":"Multi-subject simulation","title":"Between, within?","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Between,-within?","content":" Between, within? In the beginning, the distinction between  between-items ,  between-subjects  and  within-subjects ,  within-items  and  both-between ,  both-within  feels daunting. We base our terminology on  MixedModelsSim  which uses the following definitions: subjects_between  -> effects between subjects, e.g. young vs old items_between  -> effects between items, e.g. natural vs artificial images, (but shown to all subjects if not specified in subjects_between as well) both_within  -> effects completly crossed, e.g. word vs. scramble, where the \"original\" word is the item, and shown to all subjects"},{"id":420,"pagetitle":"Multi-subject simulation","title":"Components","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Components","content":" Components For multi-subject, similar to the  LinearModelComponent  specified before, we have to define the fixed effect  β , the model parameters that are applied to all subjects. β = [1, 2] # 1 = intercept, 2 = difference between large and small 2-element Vector{Int64}:\n 1\n 2 In addition, we have to provide random effects  σs , which define the spread (and  correlation) of the subjects around the fixed effects, foreach parameter σs = Dict(\n    :subject => [0.5, 1], # we have more spread in the condition-effect\n    :item => [1], # the item-variability is higher than the subject-variability\n) Dict{Symbol, Vector} with 2 entries:\n  :item    => [1]\n  :subject => [0.5, 1.0] now we are ready to assemble the parts signal = MixedModelComponent(;\n    basis = UnfoldSim.hanning(50),\n    formula = @formula(0 ~ 1 + condition + (1 + condition | subject) + (1 | item)),\n    β = β,\n    σs = σs,\n    contrasts = Dict(:condition => EffectsCoding()), # we highly recommend specifying your contrasts, by Default its Dummy/ReferenceCoding with alphabetically sorted levels (relying 100% on StatsModels.jl)\n) MixedModelComponent\n  basis: Array{Float64}((50,)) [0.0, 0.004104993088376974, 0.016352568480485274, 0.03654162132698918, 0.0643406479383053, 0.09929318906602175, 0.14082532495113625, 0.18825509907063326, 0.24080371584473748, 0.2976083284388031  …  0.2976083284388031, 0.24080371584473748, 0.18825509907063326, 0.14082532495113625, 0.09929318906602175, 0.0643406479383053, 0.03654162132698918, 0.016352568480485274, 0.004104993088376974, 0.0]\n  formula: StatsModels.FormulaTerm{StatsModels.ConstantTerm{Int64}, Tuple{StatsModels.ConstantTerm{Int64}, StatsModels.Term, StatsModels.FunctionTerm{typeof(|), Vector{StatsModels.AbstractTerm}}, StatsModels.FunctionTerm{typeof(|), Vector{StatsModels.AbstractTerm}}}}\n  β: Array{Int64}((2,)) [1, 2]\n  σs: Dict{Symbol, Vector}\n  contrasts: Dict{Symbol, EffectsCoding}\n and simulate! data, evts = simulate(design, signal, NoOnset(), NoNoise(), return_epoched = true); ┌ Warning:  No random generator defined, used the default (`Random.MersenneTwister(1)`) with a fixed seed. This will always return the same results and the user is strongly encouraged to provide their own random generator!\n └  @ UnfoldSim ~/work/UnfoldSim.jl/UnfoldSim.jl/src/simulation.jl:11 We get data with 50 samples (our  basis  from above), with  4  items and 20 subjects. We get items and subjects separately because we chose no-overlap (via  NoOnset ) and  return_epoched = true `. size(data)\n\nfirst(evts, 5) 5×3 DataFrame Row subject item condition String String String 1 S01 I1 large 2 S01 I2 small 3 S01 I3 large 4 S01 I4 small 5 S02 I1 large Finally, let's plot the data f = Figure()\n\nfor k = 1:4\n    series(\n        f[1, k],\n        data[:, k, :]',\n        solid_color = :black,\n        axis = (; limits = ((0, 50), (-5, 6))),\n    )\n    Label(f[1, k, Top()], text = \"Item:\" * evts[k, :item] * \", c:\" * evts[k, :condition])\nend\nf Some remarks on interpreting the plot: The β main-effect of small (#2 and #4) vs. large (#1 and #3) is clearly visible. The variability between subjects, is the variability between the individual curves. The item effect shows up e.g. that #2 vs. #4 column show different values."},{"id":421,"pagetitle":"Multi-subject simulation","title":"Continuous Signals / Overlap","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Continuous-Signals-/-Overlap","content":" Continuous Signals / Overlap Let's continue our tutorial and simulate overlapping signals instead. We replace the  NoOnset  with an  UniformOnset  with 20 to 70 samples between subsequent events.  We further remove the  return_epoched , because we want to have continuous data for now. data, evts = simulate(design, signal, UniformOnset(offset = 20, width = 50), NoNoise());\nsize(data) (275, 20) with the first dimension being continuous data, and the latter still the subjects. series(data', solid_color = :black) Each line is one subject, and it looks a bit unstructured, because the event-onsets are of course random for each subject. Note All subjects have the same sequence of trials, if you need to change this, specify a  event_order_function  in the  MultiSubjectDesign ."},{"id":422,"pagetitle":"Multi-subject simulation","title":"Analyzing these data with Unfold.jl","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/multisubject/#Analyzing-these-data-with-Unfold.jl","content":" Analyzing these data with Unfold.jl We will analyze these data using the  Unfold.jl  toolbox. While preliminary support for deconvolution (overlap correction) for mixed models is available, here we will not make use of it, but rather apply a MixedModel to each timepoint, following the Mass-univariate approach. data, evts = simulate(\n    design,\n    signal,\n    UniformOnset(offset = 20, width = 50),\n    NoNoise();\n    return_epoched = true,\n);\nsize(data) (50, 4, 20) For Unfold.jl, we have to reshape the data, so that all subjects are concatenated. data = reshape(data, size(data, 1), :)\ntimes = range(0, 1, length = size(data, 1))\nm = fit(\n    UnfoldModel,\n    @formula(0 ~ 1 + condition + (1 | item) + (1 + condition | subject)),\n    evts,\n    data,\n    times,\n)\nplot_erp(coeftable(m), mapping = (; col = :group)) The first column shows the fixed effects, the latter the item and subject random effects as they evolve across time This page was generated using  Literate.jl ."},{"id":425,"pagetitle":"Power analysis","title":"Power analysis","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/poweranalysis/#Power-analysis","content":" Power analysis For a power analysis, we will repeatedly simulate data, and check whether we can find a significant effect. We perform the power analysis on epoched data."},{"id":426,"pagetitle":"Power analysis","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/poweranalysis/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Statistics\nusing HypothesisTests\nusing DataFrames\nusing Random"},{"id":427,"pagetitle":"Power analysis","title":"Simulation loop","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/poweranalysis/#Simulation-loop","content":" Simulation loop pvals = fill(NaN, 100)\n@time for seed in eachindex(pvals)\n    # Simulate data of 30 subjects\n    data, evts = UnfoldSim.predef_2x2(\n        MersenneTwister(seed);\n        n_subjects = 20, ## 30 subjects\n        overlap = (1, 0), ## deactivate overlap\n        noiselevel = 10,  ## add more noise to make it more challenging\n        return_epoched = true, ## saves us the epoching step\n    )\n\n\n    # take the mean over a pre-specified timewindow\n    evts.y = dropdims(mean(data[40:60, :, :], dims = 1), dims = (1))[:]\n\n    # extract the two levels of condition A\n    evts_reduced = combine(groupby(evts, [:subject, :A]), :y => mean)\n    y_big = evts_reduced[evts_reduced.A.==\"a_big\", :y_mean]\n    y_small = evts_reduced[evts_reduced.A.==\"a_small\", :y_mean]\n\n    # calculate a one-sided t-test\n    pvals[seed] = pvalue(OneSampleTTest(y_big, y_small))\nend  11.008197 seconds (22.49 M allocations: 3.041 GiB, 3.75% gc time, 85.36% compilation time: 14% of which was recompilation) Let's calculate the power power = mean(pvals .< 0.05) * 100 61.0 This page was generated using  Literate.jl ."},{"id":430,"pagetitle":"Quickstart","title":"Quickstart","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Quickstart","content":" Quickstart To get started with data simulation, the user needs to provide four ingredients: an experimental design, defining which conditions and how many events/\"trials\" exist an event basis function, defining the simulated event-related response for every event (e.g. the ERP shape in EEG) an inter-onset event distribution, defining the distances in time of the event sequence a noise specification, defining the type of noise signal that is added to the simulated signal (e.g. pink noise) Tip Use  subtypes(AbstractNoise)  (or  subtypes(AbstractComponent)  etc.) to find already implemented building blocks."},{"id":431,"pagetitle":"Quickstart","title":"Specify the simulation ingredients","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Specify-the-simulation-ingredients","content":" Specify the simulation ingredients"},{"id":432,"pagetitle":"Quickstart","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing Random # to get an RNG\nusing CairoMakie # for plotting"},{"id":433,"pagetitle":"Quickstart","title":"Experimental Design","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Experimental-Design","content":" Experimental Design Define a 1 x 2 design with 20 trials. That is, one condition ( cond_A ) with two levels. design =\n    SingleSubjectDesign(; conditions = Dict(:cond_A => [\"level_A\", \"level_B\"])) |>\n    x -> RepeatDesign(x, 10);"},{"id":434,"pagetitle":"Quickstart","title":"Event basis function (Component)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Event-basis-function-(Component)","content":" Event basis function (Component) Define a simple component and ground truth simulation formula. Akin to ERP components, we call one simulation signal a component. Note You could easily specify multiple components by providing a vector of components, which are automatically added at the same onsets. This procedure simplifies to generate some response that is independent of simulated condition, whereas other depends on it. signal = LinearModelComponent(;\n    basis = [0, 0, 0, 0.5, 1, 1, 0.5, 0, 0],\n    formula = @formula(0 ~ 1 + cond_A),\n    β = [1, 0.5],\n);"},{"id":435,"pagetitle":"Quickstart","title":"Onsets and Noise","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Onsets-and-Noise","content":" Onsets and Noise We will start with a uniform (but overlapping,  offset  <  length(signal.basis) ) inter-onset distribution. onset = UniformOnset(; width = 20, offset = 4); And we will use some noise noise = PinkNoise(; noiselevel = 0.2);"},{"id":436,"pagetitle":"Quickstart","title":"Combine & Generate","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Combine-and-Generate","content":" Combine & Generate Finally, we will combine all ingredients and simulate some data. data, events = simulate(MersenneTwister(1), design, signal, onset, noise); data  is a  n-sample  Vector (but could be a Matrix for e.g.  MultiSubjectDesign  or epoched data). events  is a DataFrame that contains a column  latency  with the onsets of events (in samples)."},{"id":437,"pagetitle":"Quickstart","title":"Plot them!","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/quickstart/#Plot-them!","content":" Plot them! lines(data; color = \"black\")\nvlines!(events.latency; color = [\"orange\", \"teal\"][1 .+ (events.cond_A.==\"level_B\")])\n\ncurrent_axis().title = \"Simulated data\"\ncurrent_axis().xlabel = \"Time [samples]\"\ncurrent_axis().ylabel = \"Amplitude [μV]\"\n\ncurrent_figure() This page was generated using  Literate.jl ."},{"id":440,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Simulate event-related potentials (ERPs)","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Simulate-event-related-potentials-(ERPs)","content":" Simulate event-related potentials (ERPs) One subfield of EEG research focuses on so-called event-related potentials (ERPs) which are defined as brain responses time-locked to a certain event e.g. stimulus onset. The waveform of an ERP usually consists of multiple ERP components which denote the peaks and troughs of the waveform. ERP components are characterized (and named) by their timing relative to the event, their polarity (positive or negative) and their scalp topography. For example, the N170 describes a negative deflection which occurrs roughly 170 ms after the onset of (certain) visual stimuli. Often, researchers are interested how a component (e.g. its amplitude or timing) changes depending on certain experimental factors. For example, N170 has been shown to be related to face processing and its amplitude is modulated by whether the stimulus is a face or an object e.g. a car. ( Source ) Here we will learn how to simulate a typical ERP complex with P100, N170, P300."},{"id":441,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Setup","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Setup","content":" Setup Click to expand # Load required packages\nusing UnfoldSim\nusing CairoMakie\nusing Random\nusing Unfold\nusing UnfoldMakie"},{"id":442,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Simulation","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Simulation","content":" Simulation Let's grab a  SingleSubjectDesign  and add a continuous predictor design =\n    SingleSubjectDesign(;\n        conditions = Dict(\n            :condition => [\"car\", \"face\"],\n            :continuous => range(0, 5, length = 10),\n        ),\n    ) |> x -> RepeatDesign(x, 100); Let's make use of the prespecified basis functions, but use different formulas + parameters for each! p100  is unaffected by our design and has amplitude of 5 p1 = LinearModelComponent(; basis = p100(), formula = @formula(0 ~ 1), β = [5]); n170  has a condition effect, faces are more negative than cars n1 = LinearModelComponent(;\n    basis = n170(),\n    formula = @formula(0 ~ 1 + condition),\n    β = [5, 3],\n); p300  has a continuous effect, higher continuous values will result in larger P300's. We include both a linear and a quadratic effect of the continuous variable. p3 = LinearModelComponent(;\n    basis = p300(),\n    formula = @formula(0 ~ 1 + continuous + continuous^2),\n    β = [5, 1, 0.2],\n); Now we can simply combine the components and simulate components = [p1, n1, p3]\ndata, evts = simulate(\n    MersenneTwister(1),\n    design,\n    components,\n    UniformOnset(; width = 0, offset = 1000),\n    PinkNoise(),\n);"},{"id":443,"pagetitle":"Simulate event-related potentials (ERPs)","title":"Analysis","ref":"/UnfoldDocs/UnfoldSim.jl/stable/generated/tutorials/simulateERP/#Analysis","content":" Analysis Let's check that everything worked out well, by using Unfold m = fit(\n    UnfoldModel,\n    Dict(\n        Any => (\n            @formula(0 ~ 1 + condition + spl(continuous, 4)),\n            firbasis(τ = [-0.1, 1], sfreq = 100, name = \"basis\"),\n        ),\n    ),\n    evts,\n    data,\n); ┌ Warning:  using `Dict(:A=>(@formula,times/basisfunction))` is deprecated, please use `[:A=>(@formula,times/basisfunction)]` from now on\n └  @ Unfold ~/.julia/packages/Unfold/2IzOY/src/fit.jl:53 first the \"pure\" beta/linear regression parameters plot_erp(\n    coeftable(m);\n    axis = (\n        title = \"Estimated regression parameters\",\n        xlabel = \"Time [s]\",\n        ylabel = \"Amplitude [μV]\",\n    ),\n) and now beautifully visualized as marginal betas / predicted ERPs f = plot_erp(\n    effects(Dict(:condition => [\"car\", \"face\"], :continuous => 0:0.5:5), m);\n    axis = (\n        title = \"Predicted event-related potential (ERP)\",\n        xlabel = \"Time [s]\",\n        ylabel = \"Amplitude [μV]\",\n    ),\n    mapping = (:color => :continuous, linestyle = :condition, group = :continuous),\n    legend = (; valign = :top, halign = :right, tellwidth = false),\n    categorical_color = false,\n);\n\n# Workaround to separate legend and colorbar (will be fixed in a future UnfoldMakie version)\nlegend = f.content[2]\nf[:, 1] = legend\ncurrent_figure() This page was generated using  Literate.jl ."}]